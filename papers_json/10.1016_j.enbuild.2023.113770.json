{"full-text-retrieval-response": {
    "scopus-eid": "2-s2.0-85178414713",
    "originalText": "serial JL 271089 291210 291731 291800 291881 31 Energy and Buildings ENERGYBUILDINGS 2023-11-27 2023-11-27 2023-11-28 2023-11-28 2023-12-28T11:01:14 1-s2.0-S0378778823010009 S0378-7788(23)01000-9 S0378778823010009 10.1016/j.enbuild.2023.113770 S300 S300.1 FULL-TEXT 1-s2.0-S0378778823X00231 2023-12-28T11:20:55.404436Z 0 0 20240115 2024 2023-11-27T16:09:06.647563Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authlast grantnumber grantsponsor grantsponsorid orcid primabst ref 0378-7788 03787788 true 303 303 C Volume 303 57 113770 113770 113770 20240115 15 January 2024 2024-01-15 2024 Special Issue on Occupant-centric control strategies for building systems article fla © 2023 Elsevier B.V. All rights reserved. ENHANCINGHVACENERGYMANAGEMENTTHROUGHMULTIZONEOCCUPANTCENTRICAPPROACHAMULTIAGENTDEEPREINFORCEMENTLEARNINGSOLUTION LIU X 1 Introduction 2 Problem formulation and methodology 2.1 Overview of approach 2.2 Occupant behavior modeling 2.2.1 Occupant presence 2.2.2 Metabolic rate 2.2.3 Clothing behaviors 2.3 Stochasticity in occupant behavior model 2.4 States, actions and rewards of reinforcement learning 2.5 Multi-agent deep reinforcement learning 3 Simulation result 3.1 Simulation setup 3.2 Result 4 Discussion and future study 5 Conclusions Acknowledgement References PRATT 2016 8 14 A ZHANG 2020 518 527 X PARK 2019 106351 J NAGY 2023 110518 Z WANG 2005 121 126 D REINHART 2004 15 28 C PAGE 2008 83 98 J KLEIN 2012 525 536 L FABI 2015 371 383 V LIU 2021 X LIU 2021 102708 X LIU 2022 01 05 X 2022IEEEPOWERENERGYSOCIETYGENERALMEETINGPESGM HOMEENERGYMANAGEMENTCLOTHINGINTEGRATEDTHERMALCOMFORTEVSOCCONCERN LIU 2018 36 46 D WU 2022 100094 H LUO 2017 217 227 F LUO 2019 116 126 F LIU 2020 572 582 Y BARONE 2023 113015 G ZHAO 2023 113325 X FU 2023 127073 Y WEI 2017 1 6 T PROCEEDINGS54THANNUALDESIGNAUTOMATIONCONFERENCE2017 DEEPREINFORCEMENTLEARNINGFORBUILDINGHVACCONTROL YE 2021 531 Y ZHANG 2018 279 294 Y ZHANG 2019 472 490 Z KATHIRGAMANATHAN 2021 A HOMOD 2022 R YU 2021 407 419 L NAUG 2022 A BAYER 2022 187 194 D ENHANCINGPERFORMANCEMULTIAGENTREINFORCEMENTLEARNINGFORCONTROLLINGHVACSYSTEMS ZHANG 2018 148 157 Z PROCEEDINGS5THCONFERENCESYSTEMSFORBUILTENVIRONMENTS PRACTICALIMPLEMENTATIONEVALUATIONDEEPREINFORCEMENTLEARNINGCONTROLFORARADIANTHEATINGSYSTEM AZUATALAM 2020 D LI 2021 11150 11162 J CORACI 2021 D DELTETTO 2021 D LI 2022 Z ESRAFILIANNAJAFABADI 2022 109747 M LU 2023 112854 X QIU 2023 S WETTER 2010 185 203 M WANG 2023 113088 X LI 2023 121217 H KONG 2022 117987 M FANGER 1970 1970 P THERMALCOMFORTANALYSISAPPLICATIONSINENVIRONMENTALENGINEERING GUNAY 2013 31 47 H WANG 2005 121 126 D GUNAY 2015 567 588 H CARLUCCI 2020 106768 S CHOI 2022 109345 H PRATT 2013 1 5 A 2013IEEEPOWERENERGYSOCIETYGENERALMEETING PROOFOFCONCEPTHOMEENERGYMANAGEMENTSYSTEMAUTONOMOUSLYCONTROLLINGSPACEHEATING LIU 2020 382 392 X WU 2015 1 5 H IEEEPOWERENERGYSOCIETYGENERALMEETING STOCHASTICOPTIMALSCHEDULINGRESIDENTIALAPPLIANCESRENEWABLEENERGYSOURCES SHAFIEKHAH 2018 629 638 M HEIDARI 2022 119206 A WU 2014 379 388 H WU 2015 2955 2964 H LILLICRAP 2015 T 4THINTERNATIONALCONFERENCELEARNINGREPRESENTATIONSICLR CONTINUOUSCONTROLDEEPREINFORCEMENTLEARNING LOWE 2017 R ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMSVOL30 MULTIAGENTACTORCRITICFORMIXEDCOOPERATIVECOMPETITIVEENVIRONMENTS GILLESPIE 1996 2084 2091 D SMITH L GYALISTRAS 2010 D TERRESTRIALSYSTEMSECOLOGYETHZURICHSWITZERLANDBUILDINGTECHNOLOGIESDIVISION USEWEATHEROCCUPANCYFORECASTSFOROPTIMALBUILDINGCLIMATECONTROLOPTICONTROLTWOYEARSPROGRESSREPORT GYALISTRAS 2010 D CLIMARHEVAWORLDCONGRESS ANALYSISENERGYSAVINGSPOTENTIALSFORINTEGRATEDROOMAUTOMATION YAN 2015 264 278 D LIUX2024X113770 LIUX2024X113770XX CHU_NSF publishAcceptedManuscriptIndexable http://www.elsevier.com/open-access/userlicense/1.0/ 2024-11-28T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ © 2023 Elsevier B.V. All rights reserved. 2023-12-07T03:38:16.407Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/aggregated-refined U.S. National Science Foundation 1856084 NSF National Science Foundation http://data.elsevier.com/vocabulary/SciValFunders/100000001 http://sws.geonames.org/6252001/ This work is supported in part by the U.S. National Science Foundation under Grant No. 1856084 for the FEWtures project. https://doi.org/10.15223/policy-017 https://doi.org/10.15223/policy-037 https://doi.org/10.15223/policy-012 https://doi.org/10.15223/policy-029 https://doi.org/10.15223/policy-004 item S0378-7788(23)01000-9 S0378778823010009 1-s2.0-S0378778823010009 10.1016/j.enbuild.2023.113770 271089 2023-12-28T11:20:55.404436Z 2024-01-15 1-s2.0-S0378778823010009-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/MAIN/application/pdf/cc2cccbe968112edd0c98e8541adec92/main.pdf main.pdf pdf true 3632889 MAIN 13 1-s2.0-S0378778823010009-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/PREVIEW/image/png/441d13e68347d810804ee3c2a77f1ae9/main_1.png main_1.png png 60565 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0378778823010009-gr010.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr010/DOWNSAMPLED/image/jpeg/093e12f85dde92a2ca93e00027368334/gr010.jpg gr010 gr010.jpg jpg 94116 506 673 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr011.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr011/DOWNSAMPLED/image/jpeg/66902da526ac0f300413b88498e66334/gr011.jpg gr011 gr011.jpg jpg 22292 260 500 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr001.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr001/DOWNSAMPLED/image/jpeg/41bb304747deafbb05b021949d0f3023/gr001.jpg gr001 gr001.jpg jpg 96341 645 506 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr002.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr002/DOWNSAMPLED/image/jpeg/f06cb9f84c6e8af15d93292d14753a59/gr002.jpg gr002 gr002.jpg jpg 24971 282 444 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr003.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr003/DOWNSAMPLED/image/jpeg/0fb0df12927db48e877c84bea4d494d2/gr003.jpg gr003 gr003.jpg jpg 58048 395 394 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr004.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr004/DOWNSAMPLED/image/jpeg/22f784c9f6bb0b93ea8695f2d8b27f17/gr004.jpg gr004 gr004.jpg jpg 50091 274 693 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr005.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr005/DOWNSAMPLED/image/jpeg/435bf544f13d8a900b44cf0c02ff974a/gr005.jpg gr005 gr005.jpg jpg 13662 191 388 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr006.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr006/DOWNSAMPLED/image/jpeg/a402ab67311535d3c701724f07eee9b7/gr006.jpg gr006 gr006.jpg jpg 51768 344 666 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr007.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr007/DOWNSAMPLED/image/jpeg/6223a64cfb1ad52e286a45e661d706c2/gr007.jpg gr007 gr007.jpg jpg 65155 407 526 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr008.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr008/DOWNSAMPLED/image/jpeg/bba4bebeb5f73d3d4f060a2cad113a77/gr008.jpg gr008 gr008.jpg jpg 167846 657 807 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr009.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr009/DOWNSAMPLED/image/jpeg/fc9dfa0679ba3b080133e2d4f3224869/gr009.jpg gr009 gr009.jpg jpg 33604 282 599 IMAGE-DOWNSAMPLED 1-s2.0-S0378778823010009-gr010.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr010/THUMBNAIL/image/gif/75ddb3fa109fcb64a67ace7cbbdd9c99/gr010.sml gr010 gr010.sml sml 17052 164 218 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr011.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr011/THUMBNAIL/image/gif/cef363da1a0947174eaa801d85e89ca7/gr011.sml gr011 gr011.sml sml 4273 114 219 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr001.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr001/THUMBNAIL/image/gif/1b70a7c80999824a8801fea5dbce4f53/gr001.sml gr001 gr001.sml sml 9163 163 128 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr002.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr002/THUMBNAIL/image/gif/678a16590e185622d9d15cde15cf0bb7/gr002.sml gr002 gr002.sml sml 7920 139 219 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr003.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr003/THUMBNAIL/image/gif/854a0d94727232c96594d6a7dc30c223/gr003.sml gr003 gr003.sml sml 8764 163 163 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr004.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr004/THUMBNAIL/image/gif/23cbe65be1c7ef57328b36fa60f6ad05/gr004.sml gr004 gr004.sml sml 7576 87 219 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr005.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr005/THUMBNAIL/image/gif/1e2c7543e628115efb724440f46aaa61/gr005.sml gr005 gr005.sml sml 4658 108 219 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr006.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr006/THUMBNAIL/image/gif/83db31ad33ebaeedf3f14f257fb6eeb0/gr006.sml gr006 gr006.sml sml 9959 113 219 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr007.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr007/THUMBNAIL/image/gif/71bde27ff10088f5e480ee37f95d02a9/gr007.sml gr007 gr007.sml sml 15013 164 212 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr008.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr008/THUMBNAIL/image/gif/47642e0107054bcdacf038ea134ad56c/gr008.sml gr008 gr008.sml sml 17338 164 201 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr009.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/gr009/THUMBNAIL/image/gif/53015fd1415ddc5f152e3d66e3c48ac1/gr009.sml gr009 gr009.sml sml 8862 103 219 IMAGE-THUMBNAIL 1-s2.0-S0378778823010009-gr010_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/09f8dce740620b58f4a04d327278bc65/gr010_lrg.jpg gr010 gr010_lrg.jpg jpg 317877 1344 1789 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr011_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/fc365b759ea94b552eaf877936792be1/gr011_lrg.jpg gr011 gr011_lrg.jpg jpg 70340 692 1330 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr001_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/dc0a134cccef6c8ca6463e94ae883b44/gr001_lrg.jpg gr001 gr001_lrg.jpg jpg 334293 1717 1346 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr002_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/b601aceecab4f2cca5b0d981487eeb00/gr002_lrg.jpg gr002 gr002_lrg.jpg jpg 82790 750 1180 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr003_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/473ee97ab78fc27d19689d43fce361eb/gr003_lrg.jpg gr003 gr003_lrg.jpg jpg 250100 1049 1047 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr004_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/843fb19254a25a353767a29e29ed5956/gr004_lrg.jpg gr004 gr004_lrg.jpg jpg 171530 729 1841 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr005_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/6ecb8972a1628fea79c967d26cb46b9a/gr005_lrg.jpg gr005 gr005_lrg.jpg jpg 46514 509 1032 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr006_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/729812cd0a05287e3ff7a32a0d6794a4/gr006_lrg.jpg gr006 gr006_lrg.jpg jpg 173873 915 1769 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr007_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/cca775ec573887ec4fe410da79f2a0b6/gr007_lrg.jpg gr007 gr007_lrg.jpg jpg 213636 1081 1397 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr008_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/2ca9ff61fd946f93b5e58267c5ead331/gr008_lrg.jpg gr008 gr008_lrg.jpg jpg 1257617 2911 3574 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-gr009_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/HIGHRES/image/jpeg/dc7971582e8f8ae8c92412a6973ab2fa/gr009_lrg.jpg gr009 gr009_lrg.jpg jpg 109768 749 1591 IMAGE-HIGH-RES 1-s2.0-S0378778823010009-si1.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/69fd241a142c14d30e7fb28e585b38b9/si1.svg si1 si1.svg svg 2422 ALTIMG 1-s2.0-S0378778823010009-si10.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/c574e0b0901bfe4a8ed480ff48ebb3f2/si10.svg si10 si10.svg svg 7877 ALTIMG 1-s2.0-S0378778823010009-si11.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/04146e5e91b95207368c34f2c003b75c/si11.svg si11 si11.svg svg 5287 ALTIMG 1-s2.0-S0378778823010009-si12.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/21bddf2e326e07c2f5568c64b1553db3/si12.svg si12 si12.svg svg 2791 ALTIMG 1-s2.0-S0378778823010009-si13.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/2a4604ff0bab61e943e44aabfa4f7135/si13.svg si13 si13.svg svg 2645 ALTIMG 1-s2.0-S0378778823010009-si14.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/69348040959db9a09c54dc68d985795e/si14.svg si14 si14.svg svg 3275 ALTIMG 1-s2.0-S0378778823010009-si15.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/f0bcc16cac770c61e56d8c7577e29408/si15.svg si15 si15.svg svg 5040 ALTIMG 1-s2.0-S0378778823010009-si16.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/9952290ec62264017970177029f23fc8/si16.svg si16 si16.svg svg 4605 ALTIMG 1-s2.0-S0378778823010009-si17.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/d8bfb45780432171fd0a01daa5531f6c/si17.svg si17 si17.svg svg 4674 ALTIMG 1-s2.0-S0378778823010009-si19.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/e4c4aebe1c2580c2f93f1fa67ae91ecf/si19.svg si19 si19.svg svg 1760 ALTIMG 1-s2.0-S0378778823010009-si2.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/75519170587701a527868bdd8d17fb0f/si2.svg si2 si2.svg svg 5926 ALTIMG 1-s2.0-S0378778823010009-si20.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/b374b5e27c1306484c6d1f352b619486/si20.svg si20 si20.svg svg 1969 ALTIMG 1-s2.0-S0378778823010009-si21.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/6098bec2b8fa91c6db9516f54d98244a/si21.svg si21 si21.svg svg 5032 ALTIMG 1-s2.0-S0378778823010009-si22.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/0b091932e95dba5633bb4acd74744dbe/si22.svg si22 si22.svg svg 13404 ALTIMG 1-s2.0-S0378778823010009-si23.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/27d5d84ca8997123a2367111c87035c7/si23.svg si23 si23.svg svg 15601 ALTIMG 1-s2.0-S0378778823010009-si24.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/671dcc1fd434fd234a2338c18d962c9b/si24.svg si24 si24.svg svg 1790 ALTIMG 1-s2.0-S0378778823010009-si25.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/917363a48a281157412d2611ef57dd6e/si25.svg si25 si25.svg svg 2237 ALTIMG 1-s2.0-S0378778823010009-si26.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/ca34213a7df45312c669d71b8081f330/si26.svg si26 si26.svg svg 1882 ALTIMG 1-s2.0-S0378778823010009-si27.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/59dcb75e275b5a3760a5f3818ad32835/si27.svg si27 si27.svg svg 11512 ALTIMG 1-s2.0-S0378778823010009-si28.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/c95ff7793223d9f224bbe9a13e41710c/si28.svg si28 si28.svg svg 1782 ALTIMG 1-s2.0-S0378778823010009-si29.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/ac6142de4b9aa7e07337b7c08120efa1/si29.svg si29 si29.svg svg 3456 ALTIMG 1-s2.0-S0378778823010009-si3.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/fc71544c0726dfc34c53e3ba34e0c1e7/si3.svg si3 si3.svg svg 27710 ALTIMG 1-s2.0-S0378778823010009-si30.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/e5971d076fff29c533dd31a90ee7fc81/si30.svg si30 si30.svg svg 20035 ALTIMG 1-s2.0-S0378778823010009-si31.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/b93e91093d3d02e435692f79df766cf0/si31.svg si31 si31.svg svg 2513 ALTIMG 1-s2.0-S0378778823010009-si32.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/f43fdb5f587f1ca9d9879c912c0c6dc3/si32.svg si32 si32.svg svg 10783 ALTIMG 1-s2.0-S0378778823010009-si33.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/54c379c8394495725546428b8647a5d2/si33.svg si33 si33.svg svg 2231 ALTIMG 1-s2.0-S0378778823010009-si34.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/23222a01848c1db548fc40ae6e8dd0a5/si34.svg si34 si34.svg svg 2127 ALTIMG 1-s2.0-S0378778823010009-si35.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/c9d01fcd6bd59d4a818970a9275f2193/si35.svg si35 si35.svg svg 2194 ALTIMG 1-s2.0-S0378778823010009-si36.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/8cf85b0409fa8e30089e3a274a08c1d3/si36.svg si36 si36.svg svg 2450 ALTIMG 1-s2.0-S0378778823010009-si37.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/91b0242d41844e799f8a8d7e3be5133a/si37.svg si37 si37.svg svg 2511 ALTIMG 1-s2.0-S0378778823010009-si38.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/e3b603aeb7e1656d3cd933891b4772a4/si38.svg si38 si38.svg svg 13108 ALTIMG 1-s2.0-S0378778823010009-si39.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/926f72a2b0bfca0414488902426beb9f/si39.svg si39 si39.svg svg 14332 ALTIMG 1-s2.0-S0378778823010009-si4.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/8d741ccbf6e383ee7bac4bcedd2a2d5b/si4.svg si4 si4.svg svg 16623 ALTIMG 1-s2.0-S0378778823010009-si40.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/f9e135829569166b53a5c6308c68760f/si40.svg si40 si40.svg svg 2460 ALTIMG 1-s2.0-S0378778823010009-si5.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/e4e9956c70808fd09c7bdce835cc668b/si5.svg si5 si5.svg svg 3492 ALTIMG 1-s2.0-S0378778823010009-si6.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/192aeb01065e9f37189d1343a0324746/si6.svg si6 si6.svg svg 2923 ALTIMG 1-s2.0-S0378778823010009-si7.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/2df103d427eae11e40f63fa7218c5d84/si7.svg si7 si7.svg svg 6395 ALTIMG 1-s2.0-S0378778823010009-si8.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/62f65c264eef1706cb02d4588e4756cf/si8.svg si8 si8.svg svg 3355 ALTIMG 1-s2.0-S0378778823010009-si9.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778823010009/image/svg+xml/b23ecac1f0db1ce9c75e7df261bb13aa/si9.svg si9 si9.svg svg 6967 ALTIMG 1-s2.0-S0378778823010009-am.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:10W7QQVVF66/MAIN/application/pdf/634d094ec7ad0c92854b4d8e2316b766/am.pdf am am.pdf pdf false 3749815 AAM-PDF ENB 113770 113770 S0378-7788(23)01000-9 10.1016/j.enbuild.2023.113770 Elsevier B.V. Fig. 1 Illustration of proposed MADRL in multi-zone HVAC control. Three modules are contained in this approach, 1) a MADRL algorithm: Multi-agent Deep Deterministic Policy Gradient; 2) A testbed: EnergyPlus simulator; 3) Stochastic occupant behavior model includes clothing, occupant presence, and metabolic rate. (For interpretation of the colors in the figure(s), the reader is referred to the web version of this article.) Fig. 1 Fig. 2 One-day average occupant presence schedule (top) and activity level schedule (bottom) for each zone. Fig. 2 Algorithm 1 Multi-agent Deep Deterministic Policy Gradient. Algorithm 1 Fig. 3 One-year Tampa weather profile. Fig. 3 Fig. 4 Average episode reward during training of DDPG and MADDPG. Fig. 4 Fig. 5 Three-day behavior simulation result for all zones (base, shoulder, and peak prices are represented by white, light grey, and grey). Fig. 5 Fig. 6 Results of Zone 1 over a three-day period, with the Rule-based method (top), DDPG (middle), and MADDPG (bottom). The red line represents heating setpoints, the blue line indicates cooling setpoints, the black line represents the zone's average temperature, and the green dashed line represents the PMV-PPD value, while the light blue line depicts the outside temperature. Fig. 6 Fig. 7 Results of Zone 2, 3, 4, and 5 over a three-day period. The red line represents heating setpoints, the blue line indicates cooling setpoints, the black line represents the zone's average temperature, and the green dashed line represents the PMV-PPD value, while the light blue line depicts the outside temperature. Fig. 7 Fig. 8 Three days simulation of electricity cost and thermal comfort result (PMV-PPD) for the whole building. Fig. 8 Fig. 9 One-month control patterns of HVAC for all zones. Fig. 9 Fig. 10 One-month HVAC decisions histogram comparison of whole building. Fig. 10 Table 1 Literature review of DRL in HVAC control. Table 1 Reference (by time) Whole building energy simulation Multi-area thermal zone Multi-agent approach Occupant behavior Occupancy Metabolic Clothing [21]/2017 √ √ [30,24]/2018-19 √ √ Const. [31]/2020 √ √ Const. Const. [32]/2021 √ √ √ Const. Const. [33]/2021 √ √ Const. [34]/2021 √ √ [25]/2021 √ √ Const. [27]/2021 √ √ √ Dyn. [35]/2022 √ √ Const. Const. Const. [28]/2022 √ √ √ Dyn. [26]/2022 √ √ √ [29]/2022 √ √ √ Dyn. [36]/2022 √ Dyn. [37]/2023 √ √ √ [38]/2023 √ √ This work √ √ √ Dyn. Dyn. Dyn. Table 2 Activity level and metabolic rate. Table 2 Office Activities Activity Level Met (W/m2) Reading, seated 55 1 Seated, quiet 60 1 Writing 60 1 Typing 65 1.1 Standing, relaxed 70 1.2 Filing, seated 70 1.2 Filing, standing 80 1.4 Walking (0.9 m/s) 115 2 Table 3 HVAC parameters. Table 3 Feature Parameters Setting General High-Speed/Low-Speed Sensible Heat Ratio 0.75 Nominal Capacity (W) 3500 Cooling Rated Cooling COP (W/W) 3.0 Internal Static Air Pressure (Pa) 450 Heating Burner Efficiency 0.98 Nominal Capacity (W) 3500 Fan Total Efficiency 0.7 Pressure Rise (Pa) 600 Fan Maximum Flow Rate (m3/s) 3.0 Power Minimum Flow Fraction 0.25 Motor Efficiency 0.9 Motor In Air-stream Fraction 1.0 Table 4 MADDPG network information. Table 4 Actor Network # of Neurals Activation Input Input(shape=(# of state)) Hidden 1 Dense(128, 256) Relu Hidden 2 Dense(256, 512) Relu Output Dense(128, # of action) Sigmoid Critic Network # of Neurals Activation State Input Input(shape=(# of state)) State Hidden Dense(256, 256) Relu State Output Dense(256, 256) Relu Action Input Input(shape=(# of action)) Action Output Dense(256, 64) Relu Concatenate Concatenate([State Output, Action Output]) Hidden 1 Dense(Concatenate, 512) Relu Hidden 2 Dense(512,256) Relu Output Dense(1) Table 5 Training and execution time comparison. Table 5 Item Rule-based DDPG MADDPG Training time N/A 5 hr 32 hr Single-run execution time 0.01 ms 6.25 ms 29.17 ms Table 6 One-year comparison between different methods. Table 6 Item Rule-based DDPG MADDPG Average Daily Electricity Cost ($ / Day) 216.77 110.83 106.02 Avg. PMV-PPD (%) 10.36 11.43 10.39 Enhancing HVAC energy management through multi-zone occupant-centric approach: A multi-agent deep reinforcement learning solution Xuebo Liu a Yingying Wu b Hongyu Wu a \u204e a Mike Wiegers Department of Electrical and Computer Engineering, Kansas State University, Manhattan, KS 66506, USA Mike Wiegers Department of Electrical and Computer Engineering Kansas State University Manhattan KS 66506 USA Mike Wiegers Department of Electrical and Computer Engineering, Kansas State University, Manhattan, KS 66506, USA b Department of Interior Design and Fashion Studies, Kansas State University, Manhattan, KS 66506, USA Department of Interior Design and Fashion Studies Kansas State University Manhattan KS 66506 USA Department of Interior Design and Fashion Studies, Kansas State University, Manhattan, KS 66506, USA \u204e Corresponding author. Occupant-centric HVAC control places a premium on factors including thermal comfort and electricity cost to guarantee occupant satisfaction. Traditional approaches, reliant on static models for occupant behaviors, fall short in capturing intra-day behavioral variations, resulting in imprecise thermal comfort evaluations and suboptimal HVAC energy management, especially in multi-zone systems with diverse occupant profiles. To address this issue, this paper proposes a novel occupant-centric multi-zone HVAC control approach that intelligently schedules cooling and heating setpoints using Multi-agent Deep Reinforcement Learning (MADRL). This approach systematically takes into account stochastic occupant behavior models, such as dynamic clothing insulation adjustments, metabolic rates, and occupancy patterns. Simulation results demonstrate the efficacy of the proposed approach. Comparative case studies show that the proposed MADRL-based, occupant-centric HVAC control reduces electricity costs by 51.09% compared to rule-based approaches and 4.34% compared to single-agent DRL while maintaining multi-zonal thermal comfort for occupants. Data availability Data will be made available on request. 1 Introduction Buildings in the United States account for approximately 36% of total energy consumption, with HVAC systems being a significant contributor, particularly during hot summers [1]. Smart homes using IoT technologies and human-centered intelligent scheduling for HVAC control is a promising solution for energy-efficient and comfortable buildings [2]. Understanding and incorporating Occupant-Centric Control (OCC) is crucial for effective building energy management [3,4]. Wang et al. [5] investigated occupancy patterns in single-person offices and proposed a probabilistic model for occupancy prediction, emphasizing the complexity and time variation of occupancy intervals. Several studies have proposed algorithms and models for predicting occupancy to improve energy consumption and occupant comfort, including Reinhart [6], Page et al. [7], Klein et al. [8], and Fabi et al. [9]. Furthermore, integrating clothing behaviors and clothing decisions into HVAC control strategies can further enhance building energy efficacy [10\u201312]. There are a lot of literature studies on the simplified model for occupant behavior model in building energy management to reduce the electricity cost while maximizing the occupant thermal comfort in residential buildings [13,14] and commercial buildings [15\u201317]. However, occupancy and clothing behavior are not the only factors that have an effect on occupants' thermal comfort model. Metabolic rate with activity schedule is another important factor that should be conducted in the thermal comfort [18] considered in indoor temperature control. However, dynamic occupant behavior containing the occupancy, clothing adjustment, and metabolic rate involved in thermal comfort in HVAC control is still an unsolved problem [19]. On the other hand, model-based optimization can be time-consuming when dealing with large solution spaces, making it unsuitable for real-time decision-making. In recent years, Deep Reinforcement Learning (DRL), a model-free approach, has gained traction among engineers and researchers for tackling building energy management problems [20]. DRL-based HVAC control methods have been proposed to address challenges posed by large state-action spaces [21,22] and complex indoor environments [23,24]. However, addressing the multi-zone HVAC control problem with continuous action spaces remains a challenge despite the application of DRL techniques in previous studies. In real-world environments, multi-zone thermal control involves complex control agents and often necessitates a balance between competition and cooperation among these agents. Some studies have applied Multi-agent Deep Reinforcement Learning (MADRL) to multi-zone thermal control [25,26], while often lacking dynamic modeling. In Table 1 , \u201cConst.\u201d signifies a consistent schedule applied throughout simulations, while \u201cDyn.\u201d represents changing occupant activities influenced by factors such as time of day, weather, and personal choices. Although certain studies have integrated occupant presence [27\u201329], they do not account for metabolic rate and clothing adjustments. This gap in occupant behavior modeling highlights the need for novel MADRL methods capable of addressing the complexity of multi-zone environments and dynamic occupant behaviors in HVAC control. This paper bridges this gap by proposing a multi-zone HVAC energy management scheme that aims to minimize the electricity cost and the occupants' thermal discomfort using a MADRL approach. The main contributions of this work are three-fold: 1) This paper proposes a pioneering multi-zone HVAC energy management scheme that is the first of its kind to explicitly consider the occupants' behaviors, including occupant presence, clothing conditions, and activity conditions, for minimizing the electricity cost and the occupant's thermal discomfort. 2) An MADRL approach is developed for making sequential HVAC setpoint decisions while considering the continuous action space under a whole-building simulation environment with stochastic occupant behavior. Specifically, the MADRL intelligently schedules the cooling and heating set points for the multi-zone office buildings while accounting for dynamic occupant behaviors. 3) The proposed model is trained and simulated by EnergyPlus in a practical multi-zone building with real-world datasets at daily and yearly timescales. Simulation results show the electricity cost saving of MADRL is, respectively, 4.34% and 51.09% compared to single-agent DRL and rule-based control while maintaining a high comfort level for multi-zone occupants. For the rest of the paper, the mathematical formulation and proposed methodology are presented in Section 2. The simulation results of comparative case studies are in Section 3. Section 4 contains a discussion of this study. Section 5 presents the conclusions of the paper. 2 Problem formulation and methodology 2.1 Overview of approach Reinforcement learning is a paradigm within machine learning wherein an autonomous agent endeavors to acquire an optimal strategy for selecting a sequence of actions within an environment to maximize its cumulative reward. The agent's decision-making process hinges on the feedback it receives in the form of a reward value following each executed action. These decisions are contingent upon the agent's interpretation of the environment, which is encapsulated by a state representation. This iterative process persists as the agent engages with the environment, with the aim of progressively improving its policy, ultimately striving to attain predefined objectives. Fig. 1 provides a visual representation of the research framework, showcasing the seamless integration of the MADRL algorithm within a complex five-zone office building environment. This environment, as shown in the middle module of Fig. 1, is accurately simulated using the Building Controls Virtual Test Bed (BCVTB) [39] in conjunction with EnergyPlus, facilitating realistic building dynamics and HVAC power consumption modeling. Within this framework, the MADRL agent (top module of Fig. 1) actively engages with the environment, effectively making decisions (heating and cooling setpoints of HVAC) pertaining to HVAC control to simultaneously optimize energy efficiency and occupant comfort. A distinctive feature highlighted in the figure is the incorporation of dynamic occupant behavior models, as shown in the bottom module of Fig. 1, represented through a stochastic process. These models dynamically account for variations in factors such as clothing insulation, occupant presence, and metabolic rates over time. Furthermore, it's essential to note the bidirectional interaction, where reward values are transmitted from EnergyPlus to the MADRL module, and optimal actions are passed from MADRL to EnergyPlus during simulation, effectively capturing occupant behavior. This integration stands at the core of the research's mission to achieve efficient multi-zone HVAC control while upholding occupant thermal comfort standards within the building. 2.2 Occupant behavior modeling Building energy management has undergone a significant transformation with the integration of technology, sustainability considerations, and occupant comfort. Occupant-centric control (OCC) has emerged as a prominent concept, shifting the focus from a building-centric to an occupant-focused approach [40\u201342]. Researchers now recognize the importance of addressing occupants' needs and optimizing building systems for their comfort and energy efficiency. In the context of ensuring thermal comfort, the Predicted Mean Vote (PMV)/Predicted Percentage of Dissatisfied (PPD) index, introduced by P.O. Fanger and colleagues, is employed to measure occupants' comfort levels based on their environmental conditions [43]. This index is included in ISO 7730 (2005) and the ASHRAE standard 55 (2004) [44,45]. PMV/PPD models, which take into account the indoor environment and occupant behavior factors as input, have been integrated into OCC as a part objective of the HVAC energy management scheme. The proposed OCC allows occupants to have control over settings such as cooling and heating points in HVAC systems, enhancing their satisfaction and productivity. However, one of the critical factors in implementing OCC is understanding and integrating occupant behavior [46]. Factors such as occupant presence, activity levels, and clothing behavior are significant in optimizing thermal comfort strategies. Prior literature has often overlooked that behavior in building energy management, resulting in an incomplete understanding of occupant needs and potentially leading to inefficient control strategies. Our work contributes to addressing these challenges and developing an approach that considers and integrates these aspects into occupant-centric building energy management systems. Note that during specific time periods, such as morning opening (8 am), lunchtime (noon to 1 pm), and afternoon closing (6 pm to 7 pm), occupants are assumed to be engaged in walking activities, resulting in elevated activity levels. In the simulation, we assumed that occupants within the same zone share similar behaviors in terms of activity level and clothing insulation. This is reasonable in a multi-zone commercial building environment as the behaviors of one can easily affect others within the same zone. This assumption allowed us to group occupants within each zone and apply general patterns of behavior, which is a common approach in HVAC simulations. Initially, we established a fixed schedule and subsequently introduced a stochastic model to this schedule to simulate diverse behaviors across different zones. 2.2.1 Occupant presence Occupant presence information plays a pivotal role in modern building management systems, offering invaluable insights into space utilization and opportunities for optimizing energy consumption. As illustrated in Table 1, occupant presence is a prevalent factor in HVAC control as occupant behavior. In our study, we initially implement a fixed schedule for occupant presence and subsequently introduce stochastic variables to simulate occupancy patterns across the five zones, as depicted in Fig. 2 (top). While future research avenues may explore data-driven or Markov chain models to predict time-dependent occupant behavior within simulations [47\u201349], our current approach serves as an initial exploration of how dynamic occupant behavior influences HVAC control strategies. 2.2.2 Metabolic rate Efficient energy management in office or residential buildings necessitates understanding occupants' metabolic rates and activity levels, which directly impact energy expenditure [18,50]. Metabolic rate, derived from oxygen consumption, indicates an individual's energy expenditure during physical activity. Activity levels, measured in watts per square meter (W/m2), determine the heat generated by occupants. Typical office activities range from 55 W/m2 to 115 W/m2. To optimize energy usage, it is essential to consider these variations in activity levels. Table 2 provides an overview of different behavioral conditions based on metabolic rates (in units: W/m2 and Met). Tailoring energy management strategies to accommodate these diverse activity levels enables the implementation of sustainable practices in office buildings. Fig. 2 (bottom) illustrates the average activity level in the office building. The assumption is that the schedule of this behavior is average in all thermal zones and during morning opening (8 am), lunchtime (noon to 1 pm), and afternoon closing (6 pm to 7 pm), occupants are assumed to have a high activity level. By introducing random variables to the activity level, we can introduce greater diversity in this behavior, capturing more realistic occupant activity patterns. 2.2.3 Clothing behaviors Recognizing the influence of clothing on the discomfort function (PPD in the reward function), it becomes vital to consider occupants' clothing behaviors. To achieve this, the research adopts a dynamic clothing behavior model developed by Schiavon and Lee [51], as represented in Equation (1). Within this model, o c l o denotes the occupant's clothing insulation, while t a ( o u t , 6 ) represents the outdoor temperature at 6 am. Schiavon and Lee's study employed multivariable linear mixed models, with the first model accounting for outdoor air temperature and the second incorporating indoor operative temperature. These models successfully explained the total variance in clothing behavior, enhancing the realism of thermal comfort assessments in office buildings. Moreover, the inclusion of stochastic elements accommodates the inherent variability in clothing behavior, making the evaluation of thermal comfort in the office building more authentic and reflective of the diverse clothing choices and individual preferences of occupants. (1) o c l o = { 1 , t a ( o u t , 6 ) < − 5 o C 0.818 − 0.0364 \u204e t a ( o u t , 6 ) , − 5 o C ≤ t a ( o u t , 6 ) < 5 o C 10 − 0.1635 − 0.0066 + t a ( o u t , 6 ) , 5 o C ≤ t a ( o u t , 6 ) < 26 o C 0.46 , t a ( o u t , 6 ) ≥ 26 o C 2.3 Stochasticity in occupant behavior model Stochastic modeling is a mathematical approach used to analyze systems involving randomness and uncertainty which employs probability theory to describe the likelihood of various outcomes, often using simulations to estimate complex systems. In addition, stochastic modeling is essential to make probabilistic predictions and assess risks in systems influenced by chance events and variability [51]. Previous studies have extensively explored appliance scheduling problems using various stochastic models, such as forecast errors in hot water usage [52], outdoor temperature [53] and renewable energy generation [54,55]. On the other hand, as shown in Table 1, occupant presence has been one of the most popular areas in recent research. However, these studies have primarily focused on only occupant presence as the main aspect of occupant behaviors, while neglecting the dynamic aspects. In addition, varying clothing behaviors and various metabolic rates are not considered. To address this research gap, here we propose a model with occupants' behaviors influenced by the time of day and weather. In addition, we introduce stochasticity [56,57] into the occupant behavior model to show the effect of variability and range of patterns. Specifically, the following parameters are defined: O B ( t ) = { o t p r e s , o t c l o , o t m e t } X ( t ) = { X t p r e s , X t c l o , X t m e t } where t is the time index; O B ( t ) represents the estimated values of occupant behaviors without considering any stochastic effects; X ( t ) represents Gaussian-distributed random variables at time t for occupant presence, clothing behavior and metabolic rate. Note that O B ( t ) values are derived from the office schedules, shown in Fig. 2 for occupant presence and metabolic rate based on different activity levels, while the clothing behavior is determined using Equation (1). Note that the clothing insulation and activity level are measured in the average value through zone because EnergyPlus, as the simulation platform used in this study, has limitations in representing individual differences. Based on those parameters, we define: (2) O B t ˜ = O B ( t ) + X ( t ) where O B t ˜ is the stochastic dynamic occupant behavior that provides the ability to capture the inherent time-dependent variability and uncertainty of occupant behaviors. By incorporating random variables, our model can effectively simulate the nature of occupant behavior (presence, clothing, and metabolic rate), making it the first of its kind to integrate this concept into DRL-based building energy management systems. 2.4 States, actions and rewards of reinforcement learning Three indices are employed: t = { 1 , 2 , 3 , . . . , T } for time slots, m = { 1 , 2 , 3 , . . . , M } for building zones, and j = { H , C } to distinguish between the HVAC dual modes of heating (H) and cooling (C). The Reinforcement Learning consists of sets of states and actions, denoted as S and A, respectively, where s ∈ S and a ∈ A . Specifically, s t m represents the state of zone m at time slot t, and a t m , H and a t m , C indicate the heating and cooling setpoints for zone m at time slot t. In the same way, O B t m ˜ is the stochastic occupant behavior in zone m at time slot t. It is worth mentioning that O B t m ˜ is part of s t m . The reward function r t is defined for the entire building at time slot t. The state s t includes two parts: external states and internal states. External states related to the building's outside environment encompass the outdoor dry bulb temperature, air relative humidity, wind speed, wind direction, diffuse solar radiation, and direct solar radiation. For each zone m, seven states are considered, comprising the zone air temperature, zone thermal comfort mean radiant temperature, zone air relative humidity, zone thermal comfort clothing value, thermal comfort index (PMV/PPD value), occupant counts, and zone average metabolic rate. Additionally, there are two internal states associated with electricity price and HVAC power consumption. The power consumption in our simulation represents the total electricity consumed by HVAC for the entire building, with the assumption that the entire building receives a single utility bill. As a result, power consumption is treated as a single parameter, and individual HVAC power consumption for each zone is not considered. The policy of the proposed MADDPG is a mapping that takes the current multi-zone environment observation and generates a probability distribution of actions, specifically the heating and cooling setpoints. This approach empowers the agent to make informed decisions based on the current state of the building and its zones, leading to optimized HVAC control strategies that adapt to various environmental and occupant conditions. The set tuple { s t , a t } is used to represent the states, including external states and internal states, and actions of all zones in the building: { s t , a t } = { ( s t 1 , . . . , s t M ) , ( a t 1 , H , a t 1 , C , . . . , a t M , H , a t M , C ) } A reward function in DRL is a numerical signal that informs an agent about the desirability of its actions in a given state, with higher values indicating favorable actions and lower values representing unfavorable ones. The agent's goal is to learn a policy that maximizes the cumulative reward it receives over time. The reward function for the whole environment is defined as follows: (3) r t ( m ) = − d ⋅ ∑ m = 1 M P P D ( s t m ) − b ⋅ C t ( s t , a t ) In (3), the reward function consists of two components: 1) a discomfort function calculated using the PMV/PPD, and 2) an electricity cost function C t . The weighted coefficients d t and b t can be determined based on historical data [51] and represent varying preferences of occupants, including cost-saving or comfort-seeking type. The electricity cost function C t is given by: (4) C t ( s t m , a t m ) = c t ∑ m = 1 M p t m Δ t where, c t is the electricity price at time slot t, Δt is the simulation time interval, and p t m is the electricity consumption caused by the HVAC system in zone m at time slot t. Importantly, c t and p t m are part of the states that can be observed from the environment. 2.5 Multi-agent deep reinforcement learning While classical reinforcement learning algorithms like Q-learning and policy gradient have exhibited proficiency in single-agent domains, their application presents unique challenges characterized by evolving policies, non-stationary surroundings, and the imperative for agent collaboration. In response to these multifaceted demands, the machine learning community has introduced DDPG, a prominent member of the reinforcement learning family renowned for its aptitude in handling continuous action spaces [58]. DDPG serves as a pivotal precursor to our exploration of MADDPG, an extension tailored explicitly for multi-agent domains. MADDPG advances the DDPG paradigm by empowering agents to deliberate global states and make informed decisions predicated on the actions of fellow agents, thereby enhancing coordination and overall system performance. The ensuing discourse delves deeper into the nuanced application of DDPG and the pivotal role of MADDPG in addressing the intricacies of multi-agent scenarios [59]. MADDPG is specifically crafted for multi-agent scenarios, where multiple agents interact within the same environment, potentially requiring coordination, communication, collaboration, or competition among agents. MADDPG extends DDPG to accommodate these complex multi-agent dynamics, making it suitable for modeling a wide range of cooperative or competitive interactions among autonomous agents. MADDPG offers several positive aspects in the context of multi-agent reinforcement learning: 1) Cooperative Learning: MADDPG facilitates cooperative learning by allowing agents to share information and learn from each other. By considering the joint actions and observations of all agents, MADDPG promotes coordination and collaboration among the agents, leading to better overall performance. 2) Centralized Learning, Decentralized Execution: MADDPG employs a centralized training approach, where a centralized critic network is used to estimate the Q-values based on the joint actions and observations. However, during execution, each agent acts independently based on its local observations, enabling decentralized decision-making and reducing communication requirements. 3) Handling Non-Stationarity: MADDPG is designed to handle non-stationarity in multi-agent environments, where agents' policies may change during training. By incorporating a centralized critic network that considers all agents' actions and observations, MADDPG can adapt to changing dynamics and maintain stability during training. 4) Policy Exploration and Exploitation: MADDPG combines the benefits of exploration and exploitation by utilizing the DDPG algorithm. DDPG employs an exploration policy, such as adding noise to the actions, to encourage exploration and discover new strategies. At the same time, it leverages the learned policies to exploit the most promising actions and maximize performance. The proposed MADDPG is formulated using the Bellman equation, enabling the learning of a Q-function and a multi-agent-based policy. Similar to DDPG, a deep neural network (DNN) is utilized as the Value Function Approximation (VFA) in MADDPG. This approach integrates the actor-evaluation approach and multi-agent technique, making it suitable for handling model-free, high-dimensional, and continuous action spaces in multi-zone environments. The Q-Value function, representing the value function, is given by the following expression: (5) Q π ( s t , a t ) ← Q ( s t , a t ) + α [ r t ( s t , a t ) + γ max a t + 1 ∈ A \u2061 Q ( s t + 1 , a t + 1 ) − Q ( s t , a t ) ] π ∈ Π represents the policy, which is a set of actions with a probability distribution. α denotes the learning rate, and γ is the discount factor used for future reward considerations. With Equation (5) as the foundation, the VFA of DRL can be formulated as follows: (6) y l = r l + γ Q ( s l + 1 , μ ( s l + 1 | θ μ ) | θ Q ) where l ∈ L denotes the index of mini-batch L, which is sampled from the experience replay buffer B. The parameters θ μ and θ Q correspond to the weights of the actor neural network μ ( ⋅ ) and the evaluation network Q ( ⋅ ) , respectively. The evaluation network Q ( ⋅ ) is updated through the minimization of the loss function: (7) L o s s = 1 M ∑ t ( y l − Q ( s l , a l | θ Q ) ) 2 To facilitate the exploration of the actor-network, the Ornstein-Uhlenbeck process is utilized [60]. The actor networks are updated using the policy gradient technique, which applies the chain rule to compute the gradient of the expected return with respect to the actor parameters, represented by the approximated loss of the distribution J: (8) ∇ θ μ J ≈ 1 M ∑ l ∇ a Q ( s , a | θ Q ) | s = s l , a = μ ( s l ) ∇ θ μ μ ( s | θ μ ) | s l The MADDPG algorithm introduces specific modifications tailored for multi-zone HVAC control: \u2022 During initialization, M actors and target actors are established, each corresponding to a zone within the building. \u2022 Each actor contributes the action for its respective zone during policy execution, resulting in a set of zone-specific actions. \u2022 The stochastic occupant behavior, represented by Equation (2), is applied to the environment (EnergyPlus) with each execution, capturing variability in occupant actions. \u2022 The outputs of all M actors and target actors serve as inputs to the target evaluation network. \u2022 All actor networks are updated using the sampled policy gradient, allowing the agents to learn and improve their strategies based on the environment's feedback. \u2022 Instead of returning a single-actor network, the well-trained multiple-actor networks are returned, providing zone-specific actions for each zone in the building. It is essential to highlight that the MADDPG algorithm employs 2 M + 2 networks (with M being the total number of zones) compared to the four neural networks used in single-agent DDPG. This increase in the number of networks leads to longer training times for the MADDPG algorithm compared to DDPG, as will be demonstrated in Section 4. To learn in the multi-agent environment better, we utilized Cyclical Learning Rates (CLR) [61] to enhance neural network training in MADDPG. CLR dynamically adjusts the learning rate during training, allowing it to increase and decrease within a single run. By cycling between upper and lower bounds, the network explores a wider range of learning rates, improving performance and convergence. CLR benefits neural network training by preventing instabilities and escaping saddle points. It facilitates faster traversal across the loss landscape, leading to better solutions. Therefore, implementing CLR in MADDPG optimizes the networks' generalization and optimization capabilities, while dynamic learning rate adjustment improves parameter space exploration, resulting in superior model performance. 3 Simulation result 3.1 Simulation setup A single-floor rectangular building with five zones (containing one interior and four exterior zones) is used to simulate the practical building, which features windows on all four facades and glass doors on the south and north facades. The HVAC system incorporates a packaged variable air volume system with direct expansion cooling coils and gas heating coils, serving the five zones. The HVAC parameters are listed in Table 3 . For the simulation, the one-year weather dataset of Tempa, Florida, USA, is employed, providing detailed measurements at 15-minute intervals. This dataset includes all needs for the external state, as shown in Fig. 3 . Time-of-Use (ToU) electricity tariff chosen is the Pacific Gas & Electric EToU-E6, which consists of three price levels: the base, shoulder, and peak prices, represented by white, light grey, and grey colors, respectively, with unit costs of $0.244/kWh, $0.32/kWh, and $0.436/kWh in Fig. 5. Note that the current validation in this study utilizes EnergyPlus as the whole-building simulator. The MADDPG algorithm is implemented in Python 3.8.10 with BCVTB serving as the interface. The computational platform used for the experiments is a PC equipped with an Intel(R) Core(TM) i7-4790 CPU and 8 GB RAM with Windows Subsystem for Linux (WSL) Version 2. To clearly show the efficacy of the proposed approach, we compare the proposed MADDPG with 1) a single-agent DDPG counterpart (control with occupant behavior) and 2) a rule-based control scheme (control without occupant behavior), which is discussed in [62,63]. The rule-based control highlights its reliance on outside temperature for HVAC electricity cost reduction in a whole-year hourly time step simulation. This method optimizes electricity cost by allowing slightly wider temperature ranges while ensuring occupant comfort which is deployed in realistic buildings. 3.2 Result This section presents the simulation results for three compared methods: Rule-based method (from [62], DDPG (from [58]) and MADDPG (from Algorithm 1 )), all applied to the testbed of a 5-zone building with 15 minutes time interval simulation model. The neural network information, including input, hidden, and output layers for actor and critic networks, is shown in Table 4 . Table 5 displays the total training time for DDPG and MADDPG, along with the single-run execution times for the rule-based method, DDPG, and MADDPG. It is important to note that the rule-based method does not utilize any deep neural network for computation, making it significantly faster in execution time compared to the learning-based approaches. The single-run execution time refers to the time taken for a one-time decision-making process. Specifically, DDPG takes 5 hours to train and 6.25 ms for one-time decision-making, while MADDPG takes 32 hours (5.4 times longer than DDPG) for training and 29.17 ms (3.66 times longer than DDPG) for one-time decision-making. Additionally, the reward function plot (Fig. 4 ) displays the training rewards for the episodes. It is evident that MADDPG exhibits better reward returns after approximately 25 episodes of training compared to DDPG. It is important to note that MADDPG takes longer to train compared to DDPG due to the presence of more neural networks. However, this extended training time leads to higher reward returns after the training process. In the following, we present the simulation results for three days, encompassing occupant behavior, decision results for all zones, and the whole building's electricity cost with average PMV-PPD. Fig. 5 provides a visualization of the three-day simulation of occupant behavior, illustrating fluctuations in metabolic rate, occupant presence, and clothing adjustments across all zones. The base price, shoulder price, and peak price are visually represented in white, light grey, and grey colors, respectively. It's essential to emphasize that our simulation environment is grounded in stochastic behavior modeling rather than a fixed schedule. This deliberate choice allows us to accurately capture the significant variability in occupant thermal comfort experiences over time. Furthermore, our approach offers flexibility in adjusting stochastic modeling parameters to align with real-world scenarios, leveraging insights from historical datasets [64]. It's worth noting that in our modeling, we assume that clothing adjustments play a relatively minor role in the overall variations. Detailed schedules for clothing behavior, metabolic rate, and occupant presence are elaborated upon in Section 2.2 for a more comprehensive understanding. Fig. 6 compares decision results, including heating and cooling setpoints of HVAC, for the three methods, along with room and outside temperatures. The weather dataset contains a wealth of information, with the outside temperature being the major factor affecting the room temperature. In the rule-based simulations, the control range (between heating and cooling setpoints) is narrow, as it solely considers the outside temperature for the control strategy. In addition, the heating and cooling set points for our rule-based method are derived from [62,63], in which high cooling and heating set points are observed in the early morning. Therefore, the rule-based method is typically less adaptive than DDPG and MADDPG which considers occupant behavior due to limited control range. As a result, the room temperature is controlled within this range without considering occupant behavior. In contrast, both DDPG and MADDPG show a wider range of temperature control as they take into account the occupant's behavior. Specifically, DDPG cools the zone once on Day 1 around 4 pm and requires no control on Day 2, while on Day 3, it cools the zone from 9 am to 6 pm. On the other hand, MADDPG adapts to the outside environment on Day 1 and Day 2. On Day 3, it maintains climate control from 9 am to 6 pm but undergoes a two-hour shift from the grey area (high electricity price) to the white area (based price). Furthermore, there are two pre-heating phase on Day 1 around 8 am and Day 3 from about 5 am to 8 am to raise the zone temperature due to its base price period, leading to lower electricity costs while ensuring similar thermal comfort levels. The decisions made by MADDPG demonstrate a more adaptive and cost-effective approach, taking into account both the outside environment and occupant behavior, resulting in better energy efficiency and comfort management. Fig. 7 presents a visual representation of the three-day simulation results for Zones 2 to 5, offering insights into the strategies employed by the three methods. It's worth noting that the single-agent method demonstrates consistent actions across all zones, while MADDPG exhibits adaptive actions tailored to each zone's unique requirements. Importantly, MADDPG effectively avoids peak ToU hours, as evidenced by its morning actions around 7 am or 8 am, leading to cost savings. Additionally, MADDPG maintains a high level of thermal comfort, as reflected in the lower PMV-PPD values compared to the single-agent method. Fig. 8 illustrates the evaluation metrics for the three methods, including HVAC whole building cost and average PMV-PPD in the five zones. As expected, the rule-based method incurs the highest electricity cost due to its narrow control climate range, which limits zone temperatures and leads to increased electricity consumption. This highlights the crucial importance of considering occupant behavior in the simulation. Regarding thermal comfort, the PMV-PPD values for the first two days are similar across all methods. However, on the last day, both the rule-based and MADDPG methods control the temperature at 25 o C, while DDPG maintains it at 24 o C. This slight difference in temperature control results in varied performance in thermal comfort, as evident in the PMV-PPD results. Notably, the pre-heating on the last day contributes to higher electricity costs in MADDPG but provides more comfortable thermal control compared to DDPG. The findings underscore the significance of incorporating occupant behavior into the simulation. By accounting for occupant preferences and adjusting temperature settings accordingly, MADDPG optimizes both electricity costs and thermal comfort, offering a more adaptive and efficient HVAC control strategy for the building. This approach provides a more personalized and responsive solution that takes into account occupant comfort while achieving energy savings. An interesting finding is that the single-agent DDPG demonstrates a nearly identical control action for all zones, as depicted in Fig. 9 . The control pattern remains consistent over the time horizon, with a relaxation of the control range during nights and a narrowing of the range during daytime. However, a crucial limitation of this approach is that it uses similar temperature setpoints for all zones, therefore covering each other plot line in the top (rule-based) and middle (DDPG) in Fig. 9, which does not reflect the actual real-world conditions in the simulations. Fig. 10 displays the decision distribution over one month of simulation. It becomes evident that MADDPG provides more options in terms of temperature settings, while DDPG and rule-based control exhibit a more limited range of options in the simulation results. This phenomenon indicates that MADDPG employs a more detailed and zone-specific control strategy, while DDPG applies the similar control approach to all five zones. Consequently, DDPG fails to capture the distinct differences between zones within the building, resulting in different simulation outcomes. This observation highlights the advantage of using MADDPG, which allows for more personalized and adaptive control strategies for each zone, leading to enhanced performance and efficiency in the overall HVAC management within the building. To comprehensively represent the simulation results at the long-term level, one-year worth of weather data was employed in this study from the Tampa dataset from January 1 to December 31. Table 6 presents a one-year comparison of the three methods, showcasing the average daily electricity cost ($/day) and average PMV-PPD across all five zones during the year-long simulation. The rule-based control approach exhibits the highest electricity cost but maintains the best thermal comfort levels. However, this advantage in thermal comfort comes at the cost of overlooking occupant behavior, as the rule-based control solely relies on outside temperature, leading to non-optimal energy usage. In contrast, MADDPG stands out with exceptional performance, achieving the lowest electricity cost, which is 51.09% lower than the rule-based control and 4.36% lower than DDPG. Importantly, MADDPG not only excels in cost-efficiency but also enhances thermal comfort levels compared to DDPG. Its capacity to strike a harmonious balance between cost-effectiveness and occupant comfort positions it as a highly promising and superior choice for HVAC control in buildings. MADDPG achieves this through a multi-agent control strategy, which takes into account the unique thermal transfer characteristics and occupant behaviors in different zones. The control strategy, as in DDPG, would not capture these differences and result in suboptimal multi-zone thermal control, as shown in Fig. 10. MADDPG's incorporation of multi-agent techniques, training the agents to cooperate and coordinate within the environment, leads to better results in this study. The approach effectively optimizes both electricity cost and thermal comfort, demonstrating its superiority over the rule-based and single-agent DDPG methods. The consideration of occupant behavior and zone-specific thermal dynamics in MADDPG results in more adaptive and efficient HVAC control, offering a more desirable outcome for building occupants and energy management. 4 Discussion and future study The findings from the figures and table in this study highlight the effectiveness of the MADDPG approach in multi-zone HVAC control. MADDPG operates by making pre-emptive decisions to avoid peak ToC price periods while ensuring consistent thermal comfort. Its capability to customize HVAC setpoints individually for different zones, as opposed to applying uniform actions across all zones, significantly enhances its ability to reduce electricity costs compared to the rule-based approach. Furthermore, MADDPG exhibits superior thermal comfort performance when contrasted with the single-agent DDPG method. In addition, over the course of one year, MADDPG consistently outperformed the single-agent DDPG methods in terms of average daily electricity cost, while maintaining superior thermal comfort levels compared to DDPG, striking a balance between cost reduction and occupant satisfaction. This improved performance is attributed to MADDPG's ability to adaptively design HVAC setpoints based on zone-specific characteristics and occupant behaviors, effectively utilizing multi-agent techniques to optimize both electricity cost and thermal comfort. Regarding the issues of similar actions for all zones in DDPG, we realize that during the training phase, all agents participate in centralized learning, sharing a global value function that captures interactions and dependencies between agents and the environment. However, this collective approach does not distinguish individual agents, treating those agents as a unified entity. Consequently, the shared knowledge acquired through single-agent DDPG tends to result in similar actions among agents, particularly when they face similar environmental conditions such as a testbed of multi-zone HVAC building. However, MADDPG is tailored for multi-agent environments, which facilitates communication and coordination among multiple agents, enabling them to learn distinct policies and make varied decisions based on observations and other agents' actions. This study serves as a proof of concept for applying MADRL to multi-zone thermal control while considering dynamic occupant behavior. One of the critical avenues for future research is the validation of this approach in real-world environments. The validation process entails several essential steps to ensure the algorithm's practicality and effectiveness in realistic scenarios. Firstly, it involves establishing the necessary hardware and software infrastructure, gathering real-world data, including occupant behavior and weather variations, and constructing a simulation model for virtual testing using the EnergyPlus simulator. Following this, the MADDPG algorithm undergoes offline training before its implementation within a realistic building system. Continuous system operation over an extended period facilitates ongoing performance monitoring of MADDPG, including model calibration for building models and parameter updates based on user feedback. Finally, tracking electricity consumption and occupant comfort, followed by comprehensive data analysis, evaluates MADDPG's performance compared to baseline approaches in realistic buildings. 5 Conclusions This study introduces a multi-zone HVAC energy management approach using MADDPG to minimize electricity costs and enhance occupants' thermal comfort. The MADDPG model proves its effectiveness in multi-zone HVAC control by accounting for dynamic occupant behavior and zone-specific thermal dynamics. Simulation results highlight its capacity to optimize both electricity cost and thermal comfort, surpassing rule-based and single-agent DDPG methods. The incorporation of multi-agent techniques empowers personalized and adaptive control strategies for each zone, leading to improved HVAC management performance and efficiency. MADDPG demonstrates its adaptability by making informed cooling and heating setpoint decisions based on external conditions and occupant behavior. Moreover, over a year-long simulation, MADDPG consistently achieves the lowest electricity cost while striking a remarkable balance between energy savings and occupant comfort. The inclusion of stochastic modeling, as exemplified in this study, opens new avenues for more realistic and sophisticated building energy management systems. Future studies include considering an energy management system that focuses on multi-zone HVAC control with the effect of bioclimatic and passive strategy to achieve higher reward feedback. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgement This work is supported in part by the U.S. National Science Foundation under Grant No. 1856084 for the FEWtures project. References [1] A. Pratt D. Krishnamurthy M. Ruth H. Wu M. Lunacek P. Vaynshenk Transactive home energy management systems: the impact of their proliferation on the electric grid IEEE Electrif. Mag. 4 4 2016 8 14 10.1109/MELE.2016.2614188 A. Pratt, D. Krishnamurthy, M. Ruth, H. Wu, M. Lunacek, P. Vaynshenk, Transactive home energy management systems: The impact of their proliferation on the electric grid, IEEE Electrification Magazine 4 (4) (2016) 8\u201314. doi:10.1109/MELE.2016.2614188. [2] X. Zhang M. Pipattanasomporn T. Chen S. Rahman An iot-based thermal model learning framework for smart buildings IEEE Int. Things J. 7 1 2020 518 527 10.1109/JIOT.2019.2951106 X. Zhang, M. Pipattanasomporn, T. Chen, S. Rahman, An iot-based thermal model learning framework for smart buildings, IEEE Internet of Things Journal 7 (1) (2020) 518\u2013527. doi:10.1109/JIOT.2019.2951106. [3] J.Y. Park M.M. Ouf B. Gunay Y. Peng W. O'Brien M.B. Kjærgaard Z. Nagy A critical review of field implementations of occupant-centric building controls Build. Environ. 165 2019 106351 10.1016/j.buildenv.2019.106351 https://www.sciencedirect.com/science/article/pii/S036013231930561X J. Y. Park, M. M. Ouf, B. Gunay, Y. Peng, W. O'Brien, M. B. Kjærgaard, Z. Nagy, A critical review of field implementations of occupant-centric building controls, Building and Environment 165 (2019) 106351. doi:https://doi.org/10.1016/j.buildenv.2019.106351. URL https://www.sciencedirect.com/science/article/pii/S036013231930561X [4] Z. Nagy B. Gunay C. Miller J. Hahn M. Ouf S. Lee B.W. Hobson T. Abuimara K. Bandurski M. André C.-L. Lorenz S. Crosby B. Dong Z. Jiang Y. Peng M. Favero J.Y. Park K. Nweye P. Nojedehi H. Stopps L. Sarran C. Brackley K. Bassett K. Govertsen N. Koczorek O. Abele E. Casavant M. Kane Z. O'Neill T. Yang J. Day B. Huchuk R.T. Hellwig M. Vellei Ten questions concerning occupant-centric control and operations Build. Environ. 2023 110518 10.1016/j.buildenv.2023.110518 https://www.sciencedirect.com/science/article/pii/S0360132323005450 Z. Nagy, B. Gunay, C. Miller, J. Hahn, M. Ouf, S. Lee, B. W. Hobson, T. Abuimara, K. Bandurski, M. André, C.-L. Lorenz, S. Crosby, B. Dong, Z. Jiang, Y. Peng, M. Favero, J. Y. Park, K. Nweye, P. Nojedehi, H. Stopps, L. Sarran, C. Brackley, K. Bassett, K. Govertsen, N. Koczorek, O. Abele, E. Casavant, M. Kane, Z. O'Neill, T. Yang, J. Day, B. Huchuk, R. T. Hellwig, M. Vellei, Ten questions concerning occupant-centric control and operations, Building and Environment (2023) 110518 doi:https://doi.org/10.1016/j.buildenv.2023.110518. URL https://www.sciencedirect.com/science/article/pii/S0360132323005450 [5] D. Wang C.C. Federspiel F. Rubinstein Modeling occupancy in single person offices Energy Build. 37 2 2005 121 126 10.1016/j.enbuild.2004.06.015 https://www.sciencedirect.com/science/article/pii/S0378778804001951 D. Wang, C. C. Federspiel, F. Rubinstein, Modeling occupancy in single person offices, Energy and Buildings 37 (2) (2005) 121\u2013126. doi:https://doi.org/10.1016/j.enbuild.2004.06.015. URL https://www.sciencedirect.com/science/article/pii/S0378778804001951 [6] C.F. Reinhart Lightswitch-2002: a model for manual and automated control of electric lighting and blinds Sol. Energy 77 2004 15 28 10.1016/J.SOLENER.2004.04.003 C. F. Reinhart, Lightswitch-2002: a model for manual and automated control of electric lighting and blinds, Solar Energy 77 (2004) 15\u201328. doi:10.1016/J.SOLENER.2004.04.003. [7] J. Page D. Robinson N. Morel J.L. Scartezzini A generalised stochastic model for the simulation of occupant presence Energy Build. 40 2008 83 98 10.1016/J.ENBUILD.2007.01.018 J. Page, D. Robinson, N. Morel, J. L. Scartezzini, A generalised stochastic model for the simulation of occupant presence, Energy and Buildings 40 (2008) 83\u201398. doi:10.1016/J.ENBUILD.2007.01.018. [8] L. Klein J.Y. Kwak G. Kavulya F. Jazizadeh B. Becerik-Gerber P. Varakantham M. Tambe Coordinating occupant behavior for building energy and comfort management using multi-agent systems Autom. Constr. 22 2012 525 536 10.1016/J.AUTCON.2011.11.012 L. Klein, J. Y. Kwak, G. Kavulya, F. Jazizadeh, B. Becerik-Gerber, P. Varakantham, M. Tambe, Coordinating occupant behavior for building energy and comfort management using multi-agent systems, Automation in Construction 22 (2012) 525\u2013536. doi:10.1016/J.AUTCON.2011.11.012. [9] V. Fabi R.K. Andersen S. Corgnati Verification of stochastic behavioral models of occupants' interactions with windows in residential buildings Build. Environ. 94 2015 371 383 10.1016/J.BUILDENV.2015.08.016 V. Fabi, R. K. Andersen, S. Corgnati, Verification of stochastic behavioural models of occupants' interactions with windows in residential buildings, Building and Environment 94 (2015) 371\u2013383. doi:10.1016/J.BUILDENV.2015.08.016. [10] X. Liu Y. Wu H. Wu PV-EV integrated home energy management considering residential occupant behaviors Sustainability (Switzerland) 13 24 2021 10.3390/su132413826 X. Liu, Y. Wu, H. Wu, PV-EV integrated home energy management considering residential occupant behaviors, Sustainability (Switzerland) 13 (24) (2021). doi:10.3390/su132413826. [11] X. Liu Y. Wu H. Zhang H. Wu Hourly occupant clothing decisions in residential HVAC energy management J. Build. Eng. 40 2021 102708 10.1016/j.jobe.2021.102708 X. Liu, Y. Wu, H. Zhang, H. Wu, Hourly occupant clothing decisions in residential HVAC energy management, Journal of Building Engineering 40 (2021) 102708. doi:https://doi.org/10.1016/j.jobe.2021.102708. [12] X. Liu Y. Wu H. Zhang B. Liu L. Edmonds H. Wu Home energy management with clothing integrated thermal comfort and ev soc concern 2022 IEEE Power & Energy Society General Meeting (PESGM) Denver, CO, USA 2022 01 05 10.1109/PESGM48719.2022.9917003 X. Liu, Y. Wu, H. Zhang, B. Liu, L. Edmonds, H. Wu, Home energy management with clothing integrated thermal comfort and ev soc concern, in: 2022 IEEE Power & Energy Society General Meeting (PESGM), Denver, CO, USA, 2022, pp. 01\u201305. doi:10.1109/PESGM48719.2022.9917003. [13] D. Liu Y. Xu Q. Wei X. Liu Residential energy scheduling for variable weather solar energy based on adaptive dynamic programming IEEE/CAA J. Autom. Sin. 5 1 2018 36 46 10.1109/JAS.2017.7510739 D. Liu, Y. Xu, Q. Wei, X. Liu, Residential energy scheduling for variable weather solar energy based on adaptive dynamic programming, IEEE/CAA Journal of Automatica Sinica 5 (1) (2018-01-10) 36\u201346. doi:10.1109/JAS.2017.7510739. [14] H. Wu A. Pratt P. Munankarmi M. Lunacek S.P. Balamurugan X. Liu P. Spitsen Impact of model predictive control-enabled home energy management on large-scale distribution systems with photovoltaics Adv. Appl. Energy 6 2022 100094 10.1016/J.ADAPEN.2022.100094 H. Wu, A. Pratt, P. Munankarmi, M. Lunacek, S. P. Balamurugan, X. Liu, P. Spitsen, Impact of model predictive control-enabled home energy management on large-scale distribution systems with photovoltaics, Advances in Applied Energy 6 (2022) 100094. doi:10.1016/J.ADAPEN.2022.100094. [15] F. Luo Z.Y. Dong K. Meng J. Wen H. Wang J. Zhao An operational planning framework for large-scale thermostatically controlled load dispatch IEEE Trans. Ind. Inform. 13 1 2017 217 227 10.1109/TII.2016.2515086 F. Luo, Z. Y. Dong, K. Meng, J. Wen, H. Wang, J. Zhao, An operational planning framework for large-scale thermostatically controlled load dispatch, IEEE Transactions on Industrial Informatics 13 (1) (2017) 217\u2013227. doi:10.1109/TII.2016.2515086. [16] F. Luo G. Ranzi C. Wan Z. Xu Z.Y. Dong A multistage home energy management system with residential photovoltaic penetration IEEE Trans. Ind. Inform. 15 1 2019 116 126 10.1109/TII.2018.2871159 F. Luo, G. Ranzi, C. Wan, Z. Xu, Z. Y. Dong, A multistage home energy management system with residential photovoltaic penetration, IEEE Transactions on Industrial Informatics 15 (1) (2019) 116\u2013126. doi:10.1109/TII.2018.2871159. [17] Y. Liu D. Zhang H.B. Gooi Optimization strategy based on deep reinforcement learning for home energy management CSEE J. Power Energy Syst. 6 3 2020 572 582 10.17775/CSEEJPES.2019.02890 Y. Liu, D. Zhang, H. B. Gooi, Optimization strategy based on deep reinforcement learning for home energy management, CSEE Journal of Power and Energy Systems 6 (3) (2020-09) 572\u2013582, CSEE Journal of Power and Energy Systems. doi:10.17775/CSEEJPES.2019.02890. [18] G. Barone A. Buonomano C. Forzano G. Giuzio A. Palombo G. Russo A new thermal comfort model based on physiological parameters for the smart design and control of energy-efficient hvac systems Renew. Sustain. Energy Rev. 173 2023 113015 10.1016/j.rser.2022.113015 https://www.sciencedirect.com/science/article/pii/S1364032122008966 G. Barone, A. Buonomano, C. Forzano, G. Giuzio, A. Palombo, G. Russo, A new thermal comfort model based on physiological parameters for the smart design and control of energy-efficient hvac systems, Renewable and Sustainable Energy Reviews 173 (2023) 113015. doi:https://doi.org/10.1016/j.rser.2022.113015. URL https://www.sciencedirect.com/science/article/pii/S1364032122008966 [19] X. Zhao Y. Yin Z. He Z. Deng State-of-the-art, challenges and new perspectives of thermal comfort demand law for on-demand intelligent control of heating, ventilation, and air conditioning systems Energy Build. 295 2023 113325 10.1016/j.enbuild.2023.113325 https://www.sciencedirect.com/science/article/pii/S0378778823005558 X. Zhao, Y. Yin, Z. He, Z. Deng, State-of-the-art, challenges and new perspectives of thermal comfort demand law for on-demand intelligent control of heating, ventilation, and air conditioning systems, Energy and Buildings 295 (2023) 113325. doi:https://doi.org/10.1016/j.enbuild.2023.113325. URL https://www.sciencedirect.com/science/article/pii/S0378778823005558 [20] Y. Fu S. Xu Q. Zhu Z. O'Neill V. Adetola How good are learning-based control v.s. model-based control for load shifting? Investigations on a single zone building energy system Energy 273 2023 127073 10.1016/j.energy.2023.127073 https://www.sciencedirect.com/science/article/pii/S036054422300467X Y. Fu, S. Xu, Q. Zhu, Z. O'Neill, V. Adetola, How good are learning-based control v.s. model-based control for load shifting? investigations on a single zone building energy system, Energy 273 (2023) 127073. doi:https://doi.org/10.1016/j.energy.2023.127073. URL https://www.sciencedirect.com/science/article/pii/S036054422300467X [21] T. Wei Y. Wang Q. Zhu Deep reinforcement learning for building HVAC control Proceedings of the 54th Annual Design Automation Conference 2017 Austin, TX, USA 2017 1 6 10.1145/3061639.3062224 T. Wei, Y. Wang, Q. Zhu, Deep reinforcement learning for building HVAC control, in: Proceedings of the 54th Annual Design Automation Conference 2017, Austin TX USA, 2017, pp. 1\u20136. doi:10.1145/3061639.3062224. [22] Y. Ye D. Qiu H. Wang Y. Tang G. Strbac Real-time autonomous residential demand response management based on twin delayed deep deterministic policy gradient learning Energies 14 3 2021 531 10.3390/EN14030531 Y. Ye, D. Qiu, H. Wang, Y. Tang, G. Strbac, Real-time autonomous residential demand response management based on twin delayed deep deterministic policy gradient learning, Energies 14 (3) (2021) 531. doi:10.3390/EN14030531. [23] Y. Zhang X. Bai F.P. Mills J.C. Pezzey Rethinking the role of occupant behavior in building energy performance: a review Energy Build. 172 2018 279 294 10.1016/J.ENBUILD.2018.05.017 Y. Zhang, X. Bai, F. P. Mills, J. C. Pezzey, Rethinking the role of occupant behavior in building energy performance: A review, Energy and Buildings 172 (2018) 279\u2013294. doi:10.1016/J.ENBUILD.2018.05.017. [24] Z. Zhang A. Chong Y. Pan C. Zhang K.P. Lam Whole building energy model for HVAC optimal control: a practical framework based on deep reinforcement learning Energy Build. 199 2019 472 490 10.1016/j.enbuild.2019.07.029 Z. Zhang, A. Chong, Y. Pan, C. Zhang, K. P. Lam, Whole building energy model for HVAC optimal control: A practical framework based on deep reinforcement learning, Energy and Buildings 199 (Sep. 2019) 472\u2013490. doi:10.1016/j.enbuild.2019.07.029. [25] A. Kathirgamanathan E. Mangina D. Finn Development of a soft actor critic deep reinforcement learning approach for harnessing energy flexibility in a large office building Energy AI 5 2021 10.1016/j.egyai.2021.100101 A. Kathirgamanathan, E. Mangina, D. Finn, Development of a soft actor critic deep reinforcement learning approach for harnessing energy flexibility in a large office building, Energy and AI 5 (2021). doi:10.1016/j.egyai.2021.100101. [26] R. Homod H. Togun A.K. Hussein F.N. Al-Mousawi Z. Yaseen W. Al-Kouz H. Abd O. Alawi M. Goodarzi O. Hussein Dynamics analysis of a novel hybrid deep clustering for unsupervised learning by reinforcement of multi-agent to energy saving in intelligent buildings Appl. Energy 313 2022 10.1016/j.apenergy.2022.118863 R. Homod, H. Togun, A. K. Hussein, F. N. Al-Mousawi, Z. Yaseen, W. Al-Kouz, H. Abd, O. Alawi, M. Goodarzi, O. Hussein, Dynamics analysis of a novel hybrid deep clustering for unsupervised learning by reinforcement of multi-agent to energy saving in intelligent buildings, Applied Energy 313 (2022). doi:10.1016/j.apenergy.2022.118863. [27] L. Yu Y. Sun Z. Xu C. Shen D. Yue T. Jiang X. Guan Multi-agent deep reinforcement learning for hvac control in commercial buildings IEEE Trans. Smart Grid 12 1 2021 407 419 10.1109/TSG.2020.3011739 L. Yu, Y. Sun, Z. Xu, C. Shen, D. Yue, T. Jiang, X. Guan, Multi-agent deep reinforcement learning for hvac control in commercial buildings, IEEE Transactions on Smart Grid 12 (1) (2021) 407\u2013419. doi:10.1109/TSG.2020.3011739. [28] A. Naug M. Quinones-Grueiro G. Biswas Deep reinforcement learning control for non-stationary building energy management Energy Build. 277 2022 10.1016/j.enbuild.2022.112584 A. Naug, M. Quinones-Grueiro, G. Biswas, Deep reinforcement learning control for non-stationary building energy management, Energy and Buildings 277 (2022). doi:10.1016/j.enbuild.2022.112584. [29] D. Bayer M. Pruckner Enhancing the Performance of Multi-Agent Reinforcement Learning for Controlling HVAC Systems 2022 187 194 10.1109/SusTech53338.2022.9794179 D. Bayer, M. Pruckner, Enhancing the performance of multi-agent reinforcement learning for controlling hvac systems, 2022, pp. 187\u2013194. doi:10.1109/SusTech53338.2022.9794179. [30] Z. Zhang K.P. Lam Practical implementation and evaluation of deep reinforcement learning control for a radiant heating system Proceedings of the 5th Conference on Systems for Built Environments 2018 Shenzen China 148 157 10.1145/3276774.3276775 Z. Zhang, K. P. Lam, Practical implementation and evaluation of deep reinforcement learning control for a radiant heating system, in: Proceedings of the 5th Conference on Systems for Built Environments, Shenzen, China, Nov. 2018, pp. 148\u2013157. doi:10.1145/3276774.3276775. [31] D. Azuatalam W.L. Lee F. de Nijs A. Liebman Reinforcement learning for whole-building hvac control and demand response Energy AI 2 2020 10.1016/J.EGYAI.2020.100020 D. Azuatalam, W. L. Lee, F. de Nijs, A. Liebman, Reinforcement learning for whole-building hvac control and demand response, Energy and AI 2 (11 2020). doi:10.1016/J.EGYAI.2020.100020. [32] J. Li W. Zhang G. Gao Y. Wen G. Jin G. Christopoulos Toward intelligent multizone thermal control with multiagent deep reinforcement learning IEEE Int. Things J. 8 14 2021 11150 11162 10.1109/JIOT.2021.3051400 J. Li, W. Zhang, G. Gao, Y. Wen, G. Jin, G. Christopoulos, Toward intelligent multizone thermal control with multiagent deep reinforcement learning, IEEE Internet of Things Journal 8 (14) (2021) 11150\u201311162. doi:10.1109/JIOT.2021.3051400. [33] D. Coraci S. Brandi M. Piscitelli A. Capozzoli Online implementation of a soft actor-critic agent to enhance indoor temperature control and energy efficiency in buildings Energies 14 2021 10.3390/en14040997 D. Coraci, S. Brandi, M. Piscitelli, A. Capozzoli, Online implementation of a soft actor-critic agent to enhance indoor temperature control and energy efficiency in buildings, Energies 14 (2021). doi:10.3390/en14040997. [34] D. Deltetto D. Coraci G. Pinto M. Piscitelli A. Capozzoli Exploring the potentialities of deep reinforcement learning for incentive-based demand response in a cluster of small commercial buildings Energies 14 2021 10.3390/en14102933 D. Deltetto, D. Coraci, G. Pinto, M. Piscitelli, A. Capozzoli, Exploring the potentialities of deep reinforcement learning for incentive-based demand response in a cluster of small commercial buildings, Energies 14 (2021). doi:10.3390/en14102933. [35] Z. Li Z. Sun Q. Meng Y. Wang Y. Li Reinforcement learning of room temperature set-point of thermal storage air-conditioning system with demand response Energy Build. 259 2022 10.1016/j.enbuild.2022.111903 Z. Li, Z. Sun, Q. Meng, Y. Wang, Y. Li, Reinforcement learning of room temperature set-point of thermal storage air-conditioning system with demand response, Energy and Buildings 259 (2022). doi:10.1016/j.enbuild.2022.111903. [36] M. Esrafilian-Najafabadi F. Haghighat Towards self-learning control of hvac systems with the consideration of dynamic occupancy patterns: application of model-free deep reinforcement learning Build. Environ. 226 2022 109747 10.1016/j.buildenv.2022.109747 https://www.sciencedirect.com/science/article/pii/S0360132322009775 M. Esrafilian-Najafabadi, F. Haghighat, Towards self-learning control of hvac systems with the consideration of dynamic occupancy patterns: Application of model-free deep reinforcement learning, Building and Environment 226 (2022) 109747. doi:https://doi.org/10.1016/j.buildenv.2022.109747. URL https://www.sciencedirect.com/science/article/pii/S0360132322009775 [37] X. Lu Y. Fu Z. O'Neill Benchmarking high performance hvac rule-based controls with advanced intelligent controllers: a case study in a multi-zone system in modelica Energy Build. 284 2023 112854 10.1016/J.ENBUILD.2023.112854 X. Lu, Y. Fu, Z. O'Neill, Benchmarking high performance hvac rule-based controls with advanced intelligent controllers: A case study in a multi-zone system in modelica, Energy and Buildings 284 (2023) 112854. doi:10.1016/J.ENBUILD.2023.112854. [38] S. Qiu Z. Li Z. Pang Z. Li Y. Tao Multi-agent optimal control for central chiller plants using reinforcement learning and game theory Systems 11 2023 10.3390/systems11030136 S. Qiu, Z. Li, Z. Pang, Z. Li, Y. Tao, Multi-agent optimal control for central chiller plants using reinforcement learning and game theory, Systems 11 (2023). doi:10.3390/systems11030136. [39] M. Wetter Co-simulation of building energy and control systems with the building controls virtual test bed J. Build. Perform. Simul. 4 3 2010 185 203 10.1080/19401493.2010.518631 M. Wetter, Co-simulation of building energy and control systems with the building controls virtual test bed, Journal of Building Performance Simulation 4 (3) (2010) 185\u2013203. doi:10.1080/19401493.2010.518631. [40] X. Wang B. Dong Physics-informed hierarchical data-driven predictive control for building hvac systems to achieve energy and health nexus Energy Build. 291 2023 113088 10.1016/j.enbuild.2023.113088 https://www.sciencedirect.com/science/article/pii/S0378778823003183 X. Wang, B. Dong, Physics-informed hierarchical data-driven predictive control for building hvac systems to achieve energy and health nexus, Energy and Buildings 291 (2023) 113088. doi:https://doi.org/10.1016/j.enbuild.2023.113088. URL https://www.sciencedirect.com/science/article/pii/S0378778823003183 [41] H. Li H. Johra F. de Andrade Pereira T. Hong J. Le Dréau A. Maturo M. Wei Y. Liu A. Saberi-Derakhtenjani Z. Nagy A. Marszal-Pomianowska D. Finn S. Miyata K. Kaspar K. Nweye Z. O'Neill F. Pallonetto B. Dong Data-driven key performance indicators and datasets for building energy flexibility: a review and perspectives Appl. Energy 343 2023 121217 10.1016/j.apenergy.2023.121217 https://www.sciencedirect.com/science/article/pii/S0306261923005810 H. Li, H. Johra, F. de Andrade Pereira, T. Hong, J. Le Dréau, A. Maturo, M. Wei, Y. Liu, A. Saberi-Derakhtenjani, Z. Nagy, A. Marszal-Pomianowska, D. Finn, S. Miyata, K. Kaspar, K. Nweye, Z. O'Neill, F. Pallonetto, B. Dong, Data-driven key performance indicators and datasets for building energy flexibility: A review and perspectives, Applied Energy 343 (2023) 121217. doi:https://doi.org/10.1016/j.apenergy.2023.121217. URL https://www.sciencedirect.com/science/article/pii/S0306261923005810 [42] M. Kong B. Dong R. Zhang Z. O'Neill Hvac energy savings, thermal comfort and air quality for occupant-centric control through a side-by-side experimental study Appl. Energy 306 2022 117987 10.1016/j.apenergy.2021.117987 https://www.sciencedirect.com/science/article/pii/S0306261921012903 M. Kong, B. Dong, R. Zhang, Z. O'Neill, Hvac energy savings, thermal comfort and air quality for occupant-centric control through a side-by-side experimental study, Applied Energy 306 (2022) 117987. doi:https://doi.org/10.1016/j.apenergy.2021.117987. URL https://www.sciencedirect.com/science/article/pii/S0306261921012903 [43] P.O. Fanger Thermal Comfort. Analysis and Applications in Environmental Engineering 1970 Danish Technical Press Copenhagen 1970 P. O. Fanger, Thermal comfort. analysis and applications in environmental engineering.Copenhagen: Danish Technical Press. 1970 (1970). [44] UNI EN ISO 7730, Ergonomics of the thermal environment \u2014 analytical determination and interpretation of thermal comfort using calculation of the PMV and PPD indices and local thermal comfort criteria, 2005. [45] ASHRAE Standard 55/2004, Thermal environmental conditions for human occupancy, 2004. [46] H.B. Gunay W. O'Brien I. Beausoleil-Morrison A critical review of observation studies, modeling, and simulation of adaptive occupant behaviors in offices Build. Environ. 70 2013 31 47 10.1016/J.BUILDENV.2013.07.020 H. B. Gunay, W. O'Brien, I. Beausoleil-Morrison, A critical review of observation studies, modeling, and simulation of adaptive occupant behaviors in offices, Building and Environment 70 (2013) 31\u201347. doi:10.1016/J.BUILDENV.2013.07.020. [47] D. Wang C.C. Federspiel F. Rubinstein Modeling occupancy in single person offices Energy Build. 37 2005 121 126 10.1016/J.ENBUILD.2004.06.015 D. Wang, C. C. Federspiel, F. Rubinstein, Modeling occupancy in single person offices, Energy and Buildings 37 (2005) 121\u2013126. doi:10.1016/J.ENBUILD.2004.06.015. [48] H.B. Gunay W. O'Brien I. Beausoleil-Morrison Implementation and comparison of existing occupant behaviour models in energyplus J. Build. Perform. Simul. 9 2015 567 588 10.1080/19401493.2015.1102969 https://www.tandfonline.com/doi/abs/10.1080/19401493.2015.1102969 H. B. Gunay, W. O'Brien, I. Beausoleil-Morrison, Implementation and comparison of existing occupant behaviour models in energyplus, http://dx.doi.org/10.1080/19401493.2015.1102969 9 (2015) 567\u2013588. doi:10.1080/19401493.2015.1102969. URL https://www.tandfonline.com/doi/abs/10.1080/19401493.2015.1102969 [49] S. Carlucci M.D. Simone S.K. Firth M.B. Kjærgaard R. Markovic M.S. Rahaman M.K. Annaqeeb S. Biandrate A. Das J.W. Dziedzic G. Fajilla M. Favero M. Ferrando J. Hahn M. Han Y. Peng F. Salim A. Schlüter C. van Treeck Modeling occupant behavior in buildings Build. Environ. 174 2020 106768 10.1016/J.BUILDENV.2020.106768 S. Carlucci, M. D. Simone, S. K. Firth, M. B. Kjærgaard, R. Markovic, M. S. Rahaman, M. K. Annaqeeb, S. Biandrate, A. Das, J. W. Dziedzic, G. Fajilla, M. Favero, M. Ferrando, J. Hahn, M. Han, Y. Peng, F. Salim, A. Schlüter, C. van Treeck, Modeling occupant behavior in buildings, Building and Environment 174 (2020) 106768. doi:10.1016/J.BUILDENV.2020.106768. [50] H. Choi B. Jeong J. Lee H. Na K. Kang T. Kim Deep-vision-based metabolic rate and clothing insulation estimation for occupant-centric control Build. Environ. 221 2022 109345 10.1016/j.buildenv.2022.109345 https://www.sciencedirect.com/science/article/pii/S0360132322005789 H. Choi, B. Jeong, J. Lee, H. Na, K. Kang, T. Kim, Deep-vision-based metabolic rate and clothing insulation estimation for occupant-centric control, Building and Environment 221 (2022) 109345. doi:https://doi.org/10.1016/j.buildenv.2022.109345. URL https://www.sciencedirect.com/science/article/pii/S0360132322005789 [51] A. Pratt B. Banerjee T. Nemarundwe Proof-of-concept home energy management system autonomously controlling space heating 2013 IEEE Power Energy Society General Meeting Vancouver, BC, Canada 2013 1 5 10.1109/PESMG.2013.6672709 A. Pratt, B. Banerjee, T. Nemarundwe, Proof-of-concept home energy management system autonomously controlling space heating, in: 2013 IEEE Power Energy Society General Meeting, Vancouver, BC, Canada, 2013, pp. 1\u20135. doi:10.1109/PESMG.2013.6672709. [52] X. Liu H. Wu L. Wang M.N. Faqiry Stochastic home energy management system via approximate dynamic programming IET Energy Syst. Integr. 2 4 2020 382 392 10.1049/iet-esi.2020.0060 X. Liu, H. Wu, L. Wang, M. N. Faqiry, Stochastic home energy management system via approximate dynamic programming, IET Energy Systems Integration 2 (4) (2020) 382\u2013392. doi:10.1049/iet-esi.2020.0060. [53] H. Wu A. Pratt S. Chakraborty Stochastic optimal scheduling of residential appliances with renewable energy sources IEEE Power Energy Society General Meeting 2015 1 5 10.1109/PESGM.2015.7286584 H. Wu, A. Pratt, S. Chakraborty, Stochastic optimal scheduling of residential appliances with renewable energy sources, in: IEEE Power Energy Society General Meeting, 2015, pp. 1\u20135. doi:10.1109/PESGM.2015.7286584. [54] M. Shafie-Khah P. Siano A stochastic home energy management system considering satisfaction cost and response fatigue IEEE Trans. Ind. Inform. 14 2 2018 629 638 10.1109/TII.2017.2728803 M. Shafie-Khah, P. Siano, A stochastic home energy management system considering satisfaction cost and response fatigue, IEEE Transactions on Industrial Informatics 14 (2) (2018) 629\u2013638. doi:10.1109/TII.2017.2728803. [55] A. Heidari F. Maréchal D. Khovalyg Reinforcement learning for proactive operation of residential energy systems by learning stochastic occupant behavior and fluctuating solar energy: balancing comfort, hygiene and energy use Appl. Energy 318 2022 119206 10.1016/J.APENERGY.2022.119206 A. Heidari, F. Maréchal, D. Khovalyg, Reinforcement learning for proactive operation of residential energy systems by learning stochastic occupant behavior and fluctuating solar energy: Balancing comfort, hygiene and energy use, Applied Energy 318 (2022) 119206. doi:10.1016/J.APENERGY.2022.119206. [56] H. Wu M. Shahidehpour Stochastic scuc solution with variable wind energy using constrained ordinal optimization IEEE Trans. Sustain. Energy 5 2 2014 379 388 10.1109/TSTE.2013.2289853 H. Wu, M. Shahidehpour, Stochastic scuc solution with variable wind energy using constrained ordinal optimization, IEEE Transactions on Sustainable Energy 5 (2) (2014) 379\u2013388. doi:10.1109/TSTE.2013.2289853. [57] H. Wu M. Shahidehpour A. Alabdulwahab A. Abusorrah Thermal generation flexibility with ramping costs and hourly demand response in stochastic security-constrained scheduling of variable energy sources IEEE Trans. Power Syst. 30 6 2015 2955 2964 10.1109/TPWRS.2014.2369473 H. Wu, M. Shahidehpour, A. Alabdulwahab, A. Abusorrah, Thermal generation flexibility with ramping costs and hourly demand response in stochastic security-constrained scheduling of variable energy sources, IEEE Transactions on Power Systems 30 (6) (2015) 2955\u20132964. doi:10.1109/TPWRS.2014.2369473. [58] T.P. Lillicrap J.J. Hunt A. Pritzel N. Heess T. Erez Y. Tassa D. Silver D. Wierstra Continuous control with deep reinforcement learning 4th International Conference on Learning Representations (ICLR) San Juan, Puerto Rico 2015 10.48550/arxiv.1509.02971 T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, D. Wierstra, Continuous control with deep reinforcement learning, in: 4th International Conference on Learning Representations (ICLR), San Juan, Puerto Rico, 2015. doi:10.48550/arxiv.1509.02971. [59] R. Lowe Y. Wu A. Tamar J. Harb O. Pieter Abbeel I. Mordatch Multi-agent actor-critic for mixed cooperative-competitive environments I. Guyon U.V. Luxburg S. Bengio H. Wallach R. Fergus S. Vishwanathan R. Garnett Advances in Neural Information Processing Systems, vol. 30 2017 Curran Associates, Inc. https://proceedings.neurips.cc/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf R. Lowe, Y. WU, A. Tamar, J. Harb, O. Pieter Abbeel, I. Mordatch, Multi-agent actor-critic for mixed cooperative-competitive environments, in: I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, R. Garnett (Eds.), in: Advances in Neural Information Processing Systems, Vol. 30, Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf [60] D.T. Gillespie Exact numerical simulation of the Ornstein-Uhlenbeck process and its integral Phys. Rev. E 54 2 1996 2084 2091 10.1103/PhysRevE.54.2084 D. T. Gillespie, Exact numerical simulation of the ornstein-uhlenbeck process and its integral, Phys. Rev. E 54 (2) (1996) 2084\u20132091. doi:10.1103/PhysRevE.54.2084. [61] L.N. Smith Cyclical learning rates for training neural networks arXiv:1506.01186 2017 L. N. Smith, Cyclical learning rates for training neural networks (2017). arXiv:1506.01186. [62] D. Gyalistras M. Gwerder Use of Weather and Occupancy Forecasts for Optimal Building Climate Control (Opticontrol): Two Years Progress Report Terrestrial Systems Ecology ETH Zurich, Switzerland and Building Technologies Division vol. 158 2010 Siemens Switzerland Ltd. Zug, Switzerland D. Gyalistras, M. Gwerder, et al., Use of weather and occupancy forecasts for optimal building climate control (opticontrol): Two years progress report, Terrestrial Systems Ecology ETH Zurich, Switzerland and Building Technologies Division, Siemens Switzerland Ltd., Zug, Switzerland 158 (2010). [63] D. Gyalistras M. Gwerder F. Oldewurtel C.N. Jones M. Morari B. Lehmann K. Wirth V. Stauch Analysis of energy savings potentials for integrated room automation Clima - RHEVA World Congress 2010 https://infoscience.epfl.ch/record/169732 D. Gyalistras, M. Gwerder, F. Oldewurtel, C. N. Jones, M. Morari, B. Lehmann, K. Wirth, V. Stauch, Analysis of energy savings potentials for integrated room automation, Clima - RHEVA World Congress (2010). URL https://infoscience.epfl.ch/record/169732 [64] D. Yan W. O'Brien T. Hong X. Feng H.B. Gunay F. Tahmasebi A. Mahdavi Occupant behavior modeling for building performance simulation: current state and future challenges Energy Build. 107 2015 264 278 10.1016/J.ENBUILD.2015.08.032 D. Yan, W. O'Brien, T. Hong, X. Feng, H. B. Gunay, F. Tahmasebi, A. Mahdavi, Occupant behavior modeling for building performance simulation: Current state and future challenges, Energy and Buildings 107 (2015) 264\u2013278. doi:10.1016/J.ENBUILD.2015.08.032.",
    "scopus-id": "85178414713",
    "coredata": {
        "eid": "1-s2.0-S0378778823010009",
        "dc:description": "Occupant-centric HVAC control places a premium on factors including thermal comfort and electricity cost to guarantee occupant satisfaction. Traditional approaches, reliant on static models for occupant behaviors, fall short in capturing intra-day behavioral variations, resulting in imprecise thermal comfort evaluations and suboptimal HVAC energy management, especially in multi-zone systems with diverse occupant profiles. To address this issue, this paper proposes a novel occupant-centric multi-zone HVAC control approach that intelligently schedules cooling and heating setpoints using Multi-agent Deep Reinforcement Learning (MADRL). This approach systematically takes into account stochastic occupant behavior models, such as dynamic clothing insulation adjustments, metabolic rates, and occupancy patterns. Simulation results demonstrate the efficacy of the proposed approach. Comparative case studies show that the proposed MADRL-based, occupant-centric HVAC control reduces electricity costs by 51.09% compared to rule-based approaches and 4.34% compared to single-agent DRL while maintaining multi-zonal thermal comfort for occupants.",
        "openArchiveArticle": "false",
        "prism:coverDate": "2024-01-15",
        "openaccessUserLicense": null,
        "prism:aggregationType": "Journal",
        "prism:url": "https://api.elsevier.com/content/article/pii/S0378778823010009",
        "dc:creator": [
            {
                "@_fa": "true",
                "$": "Liu, Xuebo"
            },
            {
                "@_fa": "true",
                "$": "Wu, Yingying"
            },
            {
                "@_fa": "true",
                "$": "Wu, Hongyu"
            }
        ],
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/article/pii/S0378778823010009"
            },
            {
                "@_fa": "true",
                "@rel": "scidir",
                "@href": "https://www.sciencedirect.com/science/article/pii/S0378778823010009"
            }
        ],
        "dc:format": "application/json",
        "openaccessType": null,
        "pii": "S0378-7788(23)01000-9",
        "prism:volume": "303",
        "articleNumber": "113770",
        "prism:publisher": "Elsevier B.V.",
        "dc:title": "Enhancing HVAC energy management through multi-zone occupant-centric approach: A multi-agent deep reinforcement learning solution",
        "prism:copyright": "© 2023 Elsevier B.V. All rights reserved.",
        "openaccess": "0",
        "prism:issn": "03787788",
        "openaccessArticle": "false",
        "prism:publicationName": "Energy and Buildings",
        "openaccessSponsorType": null,
        "prism:pageRange": "113770",
        "pubType": "fla",
        "prism:coverDisplayDate": "15 January 2024",
        "prism:doi": "10.1016/j.enbuild.2023.113770",
        "prism:startingPage": "113770",
        "dc:identifier": "doi:10.1016/j.enbuild.2023.113770",
        "openaccessSponsorName": null
    },
    "objects": {"object": [
        {
            "@category": "standard",
            "@height": "506",
            "@width": "673",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr010.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "94116",
            "@ref": "gr010",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "260",
            "@width": "500",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr011.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "22292",
            "@ref": "gr011",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "645",
            "@width": "506",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr001.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "96341",
            "@ref": "gr001",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "282",
            "@width": "444",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr002.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "24971",
            "@ref": "gr002",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "395",
            "@width": "394",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr003.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "58048",
            "@ref": "gr003",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "274",
            "@width": "693",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr004.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "50091",
            "@ref": "gr004",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "191",
            "@width": "388",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr005.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "13662",
            "@ref": "gr005",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "344",
            "@width": "666",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr006.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "51768",
            "@ref": "gr006",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "407",
            "@width": "526",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr007.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "65155",
            "@ref": "gr007",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "657",
            "@width": "807",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr008.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "167846",
            "@ref": "gr008",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "282",
            "@width": "599",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr009.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "33604",
            "@ref": "gr009",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "218",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr010.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "17052",
            "@ref": "gr010",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "114",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr011.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "4273",
            "@ref": "gr011",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "128",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr001.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "9163",
            "@ref": "gr001",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "139",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr002.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "7920",
            "@ref": "gr002",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "163",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr003.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "8764",
            "@ref": "gr003",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "87",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr004.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "7576",
            "@ref": "gr004",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "108",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr005.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "4658",
            "@ref": "gr005",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "113",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr006.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "9959",
            "@ref": "gr006",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "212",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr007.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "15013",
            "@ref": "gr007",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "201",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr008.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "17338",
            "@ref": "gr008",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "103",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr009.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "8862",
            "@ref": "gr009",
            "@mimetype": "image/gif"
        },
        {
            "@category": "high",
            "@height": "1344",
            "@width": "1789",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr010_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "317877",
            "@ref": "gr010",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "692",
            "@width": "1330",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr011_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "70340",
            "@ref": "gr011",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1717",
            "@width": "1346",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr001_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "334293",
            "@ref": "gr001",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "750",
            "@width": "1180",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr002_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "82790",
            "@ref": "gr002",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1049",
            "@width": "1047",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr003_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "250100",
            "@ref": "gr003",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "729",
            "@width": "1841",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr004_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "171530",
            "@ref": "gr004",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "509",
            "@width": "1032",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr005_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "46514",
            "@ref": "gr005",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "915",
            "@width": "1769",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr006_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "173873",
            "@ref": "gr006",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1081",
            "@width": "1397",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr007_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "213636",
            "@ref": "gr007",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2911",
            "@width": "3574",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr008_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "1257617",
            "@ref": "gr008",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "749",
            "@width": "1591",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-gr009_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "109768",
            "@ref": "gr009",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si1.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2422",
            "@ref": "si1",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si10.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7877",
            "@ref": "si10",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si11.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5287",
            "@ref": "si11",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si12.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2791",
            "@ref": "si12",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si13.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2645",
            "@ref": "si13",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si14.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3275",
            "@ref": "si14",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si15.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5040",
            "@ref": "si15",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si16.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4605",
            "@ref": "si16",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si17.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4674",
            "@ref": "si17",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si19.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1760",
            "@ref": "si19",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si2.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5926",
            "@ref": "si2",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si20.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1969",
            "@ref": "si20",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si21.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5032",
            "@ref": "si21",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si22.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "13404",
            "@ref": "si22",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si23.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "15601",
            "@ref": "si23",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si24.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1790",
            "@ref": "si24",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si25.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2237",
            "@ref": "si25",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si26.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1882",
            "@ref": "si26",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si27.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11512",
            "@ref": "si27",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si28.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1782",
            "@ref": "si28",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si29.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3456",
            "@ref": "si29",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si3.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "27710",
            "@ref": "si3",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si30.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "20035",
            "@ref": "si30",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si31.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2513",
            "@ref": "si31",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si32.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "10783",
            "@ref": "si32",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si33.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2231",
            "@ref": "si33",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si34.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2127",
            "@ref": "si34",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si35.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2194",
            "@ref": "si35",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si36.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2450",
            "@ref": "si36",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si37.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2511",
            "@ref": "si37",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si38.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "13108",
            "@ref": "si38",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si39.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "14332",
            "@ref": "si39",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si4.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "16623",
            "@ref": "si4",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si40.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2460",
            "@ref": "si40",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si5.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3492",
            "@ref": "si5",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si6.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2923",
            "@ref": "si6",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si7.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6395",
            "@ref": "si7",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si8.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3355",
            "@ref": "si8",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-si9.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6967",
            "@ref": "si9",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778823010009-am.pdf?httpAccept=%2A%2F%2A",
            "@multimediatype": "Acrobat PDF file",
            "@type": "AAM-PDF",
            "@size": "3749815",
            "@ref": "am",
            "@mimetype": "application/pdf"
        }
    ]},
    "link": {
        "@rel": "abstract",
        "@href": "https://api.elsevier.com/content/abstract/scopus_id/85178414713"
    }
}}