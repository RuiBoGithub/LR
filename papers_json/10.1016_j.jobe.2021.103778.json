{"full-text-retrieval-response": {
    "scopus-eid": "2-s2.0-85121269022",
    "originalText": "serial JL 312002 291210 291862 291881 31 Journal of Building Engineering JOURNALBUILDINGENGINEERING 2021-12-03 2021-12-03 2021-12-16 2021-12-16 2022-04-12T07:56:36 1-s2.0-S2352710221016363 S2352-7102(21)01636-3 S2352710221016363 10.1016/j.jobe.2021.103778 S300 S300.1 FULL-TEXT 1-s2.0-S2352710221X00125 2022-12-12T23:24:48.558699Z 0 0 20220415 2022 2021-12-03T04:15:25.080814Z absattachment articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table e-component body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid highlightsabst orcid primabst ref specialabst 2352-7102 23527102 true 47 47 C Volume 47 8 103778 103778 103778 20220415 15 April 2022 2022-04-15 2022 article fla © 2021 Elsevier Ltd. All rights reserved. ACOUPLEDDEEPLEARNINGBASEDINTERNALHEATGAINSDETECTIONPREDICTIONMETHODFORENERGYEFFICIENTOFFICEBUILDINGOPERATION WEI S 1 Introduction and literature review 1.1 Research gap and novelty 1.2 Aims and objectives 2 Method 2.1 Deep learning approach 2.1.1 Pre-processing 2.1.2 Selection and configuration of the detection model 2.2 Application of the CNN-based approach 2.2.1 Experimental setup 2.2.2 Experimental procedure and formation of DLIP 2.3 Model performance and analysis 2.3.1 Evaluation of the detection method 2.3.2 Internal heat gains estimation 2.3.3 Building energy simulation 3 Results and discussion 3.1 Evaluation of model training 3.2 Detection performance and profiles 3.2.1 Detection performance 3.2.2 Detection performance analysis 3.2.3 Further detection accuracy evaluation 3.2.4 Deep learning profiles generation 3.3 Building energy performance analysis 3.3.1 Internal heat gains 3.3.2 Heating and cooling demands 4 Conclusions and future works Author statement Acknowledgements Appendix A Supplementary data Abbreviations References LI 2021 102136 L SHRESTHA 2021 101831 J ZHENG 2021 100040 W GUO 2021 107368 M MOKHTARI 2021 107561 R WANG 2018 108 117 W ANNAQEEB 2020 141246 141257 M HOBSON 2020 110179 B TIEN 2020 110386 P WEI 2020 115506 S ERICKSON 2010 7 12 V PROC2NDACMWORKSHOPEMBEDSENSSYSTENERGYEFFICBUILD OCCUPANCYBASEDDEMANDRESPONSEHVACCONTROLSTRATEGY BURAKGUNAY 2015 71 85 H PENG 2017 145 160 Y LABEODAN 2015 303 314 T ZHANG 2007 1 6 Z PROCEEDINGS200710THINTERNATIONALCONFERENCEINFORMATIONFUSION MOVINGTARGETSDETECTIONLOCALIZATIONINPASSIVEINFRAREDSENSORNETWORKS YANG 2016 344 349 J KAUSHIK 2006 5257 5260 A PROCEEDINGS2006INTERNATIONALCONFERENCEIEEEENGINEERINGINMEDICINEBIOLOGYSOCIETY CHARACTERIZATIONPASSIVEINFRAREDSENSORSFORMONITORINGOCCUPANCYPATTERN LI 2012 89 99 N BALAJI 2013 1 14 B PROCEEDINGS11THACMCONFERENCEEMBEDDEDNETWORKEDSENSORSYSTEMS SENTINELOCCUPANCYBASEDHVACACTUATIONUSINGEXISTINGWIFIINFRASTRUCTUREWITHINCOMMERCIALBUILDINGS TEKLER 2020 106681 Z DENG 2020 109872 Z YUN 2014 8057 8081 J CHOI 2021 111389 H JAZIZADEH 2018 829 841 F KIM 2019 216 222 S REALTIMEOCCUPANCYPREDICTIONINALARGEEXHIBITIONHALLUSINGDEEPLEARNINGAPPROACHENERGYBUILD ZOU 2017 385 398 J FENG 2020 4490 4501 C WEI 2021 545 557 S TIEN 2020 P RAMANAN 2003 D FINDINGTRACKINGPEOPLEBOTTOMUPPROCEEDINGSCVPRIEEECOMPUTERSOCIETYCONFERENCECOMPUTERVISIONPATTERNRECOGNITION GIRSHICK 2014 580 587 R PROCEEDINGSIEEECONFERENCECOMPUTERVISIONPATTERNRECOGNITION RICHFEATUREHIERARCHIESFORACCURATEOBJECTDETECTIONSEMANTICSEGMENTATION HE 2015 1904 1916 K GIRSHICK 2015 1440 1448 R PROCEEDINGSIEEEINTERNATIONALCONFERENCECOMPUTERVISION FASTRCNN GALVEZ 2018 2023 2027 R PROCEEDINGSTENCON20182018IEEEREGION10CONFERENCE OBJECTDETECTIONUSINGCONVOLUTIONALNEURALNETWORKS 2015 ENVIRONMENTALDESIGNCIBSEGUIDEA SHAHZAD 2018 689 709 S SHAHZAD 2020 373 395 S 2017 STANDARD55THERMALENVIRONMENTALCONDITIONSFORHUMANOCCUPANCY 2019 ANSIASHRAEIESSTANDARD9012019ENERGYSTANDARDFORBUILDINGSEXCEPTLOWRISERESIDENTIALBUILDINGS WEIX2022X103778 WEIX2022X103778XS HEFCE none 2022-12-16T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ © 2021 Elsevier Ltd. All rights reserved. 0 https://doi.org/10.15223/policy-017 https://doi.org/10.15223/policy-037 https://doi.org/10.15223/policy-012 https://doi.org/10.15223/policy-029 https://doi.org/10.15223/policy-004 item S2352-7102(21)01636-3 S2352710221016363 1-s2.0-S2352710221016363 10.1016/j.jobe.2021.103778 312002 2022-07-28T22:00:28.705626Z 2022-04-15 1-s2.0-S2352710221016363-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/MAIN/application/pdf/7195f23f5e674279a9f8a4b4185627ee/main.pdf main.pdf pdf true 20756680 MAIN 26 1-s2.0-S2352710221016363-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/PREVIEW/image/png/35724e639d35f1a231d26cd3f89c3cde/main_1.png main_1.png png 52906 849 656 IMAGE-WEB-PDF 1 1-s2.0-S2352710221016363-gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr8/DOWNSAMPLED/image/jpeg/d28c09b2c4aa91e6f80ef559c0bab06f/gr8.jpg gr8 gr8.jpg jpg 109819 295 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr9/DOWNSAMPLED/image/jpeg/2d25f0cd29d83599210909a082670b25/gr9.jpg gr9 gr9.jpg jpg 150338 491 669 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr6/DOWNSAMPLED/image/jpeg/53bd60de09d8485c4266c0c6fb38e908/gr6.jpg gr6 gr6.jpg jpg 178579 1019 505 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr7/DOWNSAMPLED/image/jpeg/ae08555ed530b3ce046eb506c809a10d/gr7.jpg gr7 gr7.jpg jpg 98995 205 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr4/DOWNSAMPLED/image/jpeg/83227d0eac651a4af8dfe3af9f1b7fd7/gr4.jpg gr4 gr4.jpg jpg 254520 610 624 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr5/DOWNSAMPLED/image/jpeg/6b798e0e855ae289568bfaa7ae549f04/gr5.jpg gr5 gr5.jpg jpg 120273 262 624 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr2/DOWNSAMPLED/image/jpeg/fa1d4691ce158ad356ef2285a59d01e3/gr2.jpg gr2 gr2.jpg jpg 146012 379 669 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr3/DOWNSAMPLED/image/jpeg/73d54e7fdef3bbfeecd193b583c94002/gr3.jpg gr3 gr3.jpg jpg 130232 233 669 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr1/DOWNSAMPLED/image/jpeg/a27ba5655ba19f1e3a42997a5be511a9/gr1.jpg gr1 gr1.jpg jpg 164762 390 624 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr10/DOWNSAMPLED/image/jpeg/e0624a165deab3e3cdb9f571d45452f3/gr10.jpg gr10 gr10.jpg jpg 284871 931 544 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr11.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr11/DOWNSAMPLED/image/jpeg/212399cea2fc634afeb2d4f45e7c890a/gr11.jpg gr11 gr11.jpg jpg 144874 742 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr12.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr12/DOWNSAMPLED/image/jpeg/8e68bf40481e75d97dcde692660eeb22/gr12.jpg gr12 gr12.jpg jpg 126663 636 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr13.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr13/DOWNSAMPLED/image/jpeg/571a04123090a87bc381583f1f3a4dc4/gr13.jpg gr13 gr13.jpg jpg 133425 682 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr14.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr14/DOWNSAMPLED/image/jpeg/4b69f99dee42ad6fb0c83b2f6f354515/gr14.jpg gr14 gr14.jpg jpg 154216 701 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr15.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr15/DOWNSAMPLED/image/jpeg/9fb28dc30f50f75e276a08482d4b1c80/gr15.jpg gr15 gr15.jpg jpg 157564 536 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr16.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr16/DOWNSAMPLED/image/jpeg/5d856657abd86178c7a17c9f22140aef/gr16.jpg gr16 gr16.jpg jpg 115850 390 669 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr17.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr17/DOWNSAMPLED/image/jpeg/dfc6fead1698967f2c612150936c43c5/gr17.jpg gr17 gr17.jpg jpg 128611 514 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr18.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr18/DOWNSAMPLED/image/jpeg/2e5374c7822474118eee2e8943306116/gr18.jpg gr18 gr18.jpg jpg 160859 557 624 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr19.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr19/DOWNSAMPLED/image/jpeg/e95cc0130e80051932d038f759a1906e/gr19.jpg gr19 gr19.jpg jpg 171934 737 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr20.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr20/DOWNSAMPLED/image/jpeg/dcf8143e548ab94166513979dd2ffcb6/gr20.jpg gr20 gr20.jpg jpg 95713 277 544 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr21.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr21/DOWNSAMPLED/image/jpeg/847012f94a14420204874e7220dad0cc/gr21.jpg gr21 gr21.jpg jpg 148886 681 624 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr22.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr22/DOWNSAMPLED/image/jpeg/b9302b5ccfded815ff28b6240d12256c/gr22.jpg gr22 gr22.jpg jpg 148594 641 580 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-fx3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx3/DOWNSAMPLED/image/jpeg/5de4d24e62ebb34cb1a4af3663af1a6b/fx3.jpg fx3 fx3.jpg jpg 86612 70 112 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-fx4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx4/DOWNSAMPLED/image/jpeg/fc7786e0234143a7c88917fc37352df8/fx4.jpg fx4 fx4.jpg jpg 81044 70 112 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx1/DOWNSAMPLED/image/jpeg/7d64029b6835a3e2b6f93ae2d8c72a8a/fx1.jpg fx1 fx1.jpg jpg 78204 69 112 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-fx2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx2/DOWNSAMPLED/image/jpeg/31a033bec98703de24017c47b59840d0/fx2.jpg fx2 fx2.jpg jpg 84847 70 112 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-ga1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/ga1/DOWNSAMPLED/image/jpeg/054656fe040c345fe45a32a2aba0389d/ga1.jpg ga1 true ga1.jpg jpg 108961 200 331 IMAGE-DOWNSAMPLED 1-s2.0-S2352710221016363-gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr8/THUMBNAIL/image/gif/7e0fcb08d9abcf0a00084fae2f761c41/gr8.sml gr8 gr8.sml sml 74534 111 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr9/THUMBNAIL/image/gif/8e19f94261195008f7a2bef1323278e3/gr9.sml gr9 gr9.sml sml 84946 161 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr6/THUMBNAIL/image/gif/626d6ef128a26abc7a6d434250c2e2cf/gr6.sml gr6 gr6.sml sml 72613 163 81 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr7/THUMBNAIL/image/gif/36e089bd0030f3e423f4a7f4689da861/gr7.sml gr7 gr7.sml sml 71864 77 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr4/THUMBNAIL/image/gif/32b7c37f3465b55d05437ee69ba271ce/gr4.sml gr4 gr4.sml sml 96686 163 167 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr5/THUMBNAIL/image/gif/9f4a571dae7333950e8e412ddce9db10/gr5.sml gr5 gr5.sml sml 76251 92 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr2/THUMBNAIL/image/gif/a32907b4d5c30b13c6e366cd1431953e/gr2.sml gr2 gr2.sml sml 83382 124 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr3/THUMBNAIL/image/gif/cff91a6b7a68074123544f8b5723c898/gr3.sml gr3 gr3.sml sml 76609 76 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr1/THUMBNAIL/image/gif/c97ced66461c54bc6e356632678aabea/gr1.sml gr1 gr1.sml sml 89917 137 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr10/THUMBNAIL/image/gif/e32cb87875cadeac3a920595dce8eb34/gr10.sml gr10 gr10.sml sml 87447 163 95 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr11.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr11/THUMBNAIL/image/gif/91d278718beb09d05a081b22e21f45cf/gr11.sml gr11 gr11.sml sml 73695 164 128 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr12.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr12/THUMBNAIL/image/gif/9ab631ab146302f1af8912cb8ff11e66/gr12.sml gr12 gr12.sml sml 73161 163 149 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr13.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr13/THUMBNAIL/image/gif/901d0ad374bb4d07436bfcf03c107196/gr13.sml gr13 gr13.sml sml 73106 164 139 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr14.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr14/THUMBNAIL/image/gif/8c50efb6fb3467ec304bfc4f8980f2fa/gr14.sml gr14 gr14.sml sml 76908 163 135 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr15.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr15/THUMBNAIL/image/gif/d761cbd565769d9747582935019be6fd/gr15.sml gr15 gr15.sml sml 82069 163 177 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr16.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr16/THUMBNAIL/image/gif/f21aafa16b4db440ae89cc9f3b5df4fa/gr16.sml gr16 gr16.sml sml 77324 128 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr17.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr17/THUMBNAIL/image/gif/9e74b5b6837412b22468686cb4822c28/gr17.sml gr17 gr17.sml sml 76341 164 185 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr18.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr18/THUMBNAIL/image/gif/9cf232432622c87578daf2427a2fb63b/gr18.sml gr18 gr18.sml sml 79039 164 184 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr19.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr19/THUMBNAIL/image/gif/74d9d197b36f936a625ea80364b2a383/gr19.sml gr19 gr19.sml sml 76004 164 129 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr20.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr20/THUMBNAIL/image/gif/1b9ded8d456f6e0bfdc80584466c3d07/gr20.sml gr20 gr20.sml sml 71915 112 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr21.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr21/THUMBNAIL/image/gif/4afb562baae6c77701a85b7dbcda6e4e/gr21.sml gr21 gr21.sml sml 75598 164 150 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr22.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr22/THUMBNAIL/image/gif/2e9eb747490f7fa6a80458129f2c1fc1/gr22.sml gr22 gr22.sml sml 77316 163 148 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-fx3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx3/THUMBNAIL/image/gif/0deef33a75433ee96615761dca2920ac/fx3.sml fx3 fx3.sml sml 94127 137 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-fx4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx4/THUMBNAIL/image/gif/316bd4824909e36aa3ec2cd22596ca83/fx4.sml fx4 fx4.sml sml 92035 137 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx1/THUMBNAIL/image/gif/7a0f28d6a375ee5a3cca23c616246986/fx1.sml fx1 fx1.sml sml 89790 136 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-fx2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx2/THUMBNAIL/image/gif/2c69e5ccee9f086b4f0a3d1c40056554/fx2.sml fx2 fx2.sml sml 92965 137 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-ga1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/ga1/THUMBNAIL/image/gif/93b71883e6ac7a9634e0625b82f4dca8/ga1.sml ga1 true ga1.sml sml 89004 132 219 IMAGE-THUMBNAIL 1-s2.0-S2352710221016363-gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr8/HIGHRES/image/jpeg/8c4daea1fba759e171a7a7bd296a26ca/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 343151 1306 2568 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr9/HIGHRES/image/jpeg/b6d1f0b151a045f2e9684a95db18d495/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 660725 2174 2962 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr6/HIGHRES/image/jpeg/64d0029ecd06c0866c89d20b831d4bc7/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 1006675 4516 2238 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr7/HIGHRES/image/jpeg/c1afe3c162002b86e227b9cdf2cd49db/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 291397 906 2568 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr4/HIGHRES/image/jpeg/2de970abeade56baf489dee8777e6a7f/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 1740876 2704 2764 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr5/HIGHRES/image/jpeg/97581d7ead046d0533d94c1146eee488/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 519345 1160 2764 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr2/HIGHRES/image/jpeg/36ea755f08ef9caed9cb34f0616ebdb5/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 692248 1676 2962 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr3/HIGHRES/image/jpeg/896e8f18e234c3fe0dc68a2468bb9dff/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 548264 1032 2962 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr1/HIGHRES/image/jpeg/7da9d77ba7a8cac375a5f0f5301bfc43/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 826542 1726 2764 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr10_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr10/HIGHRES/image/jpeg/5102c85d5ef4f915dfd1de3a4500c483/gr10_lrg.jpg gr10 gr10_lrg.jpg jpg 1982995 4124 2410 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr11_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr11/HIGHRES/image/jpeg/1d9db0665ccac696424580f3212bc877/gr11_lrg.jpg gr11 gr11_lrg.jpg jpg 558158 3286 2568 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr12_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr12/HIGHRES/image/jpeg/fbc651d2ae59a9d837b0c9394b0931a7/gr12_lrg.jpg gr12 gr12_lrg.jpg jpg 461206 2816 2568 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr13_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr13/HIGHRES/image/jpeg/2802ff63efd9673bbb58176c58f65018/gr13_lrg.jpg gr13 gr13_lrg.jpg jpg 503504 3020 2567 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr14_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr14/HIGHRES/image/jpeg/0a21aa5bdfea5f48c344ef201189ea36/gr14_lrg.jpg gr14 gr14_lrg.jpg jpg 604322 3104 2568 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr15_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr15/HIGHRES/image/jpeg/50f2d0929ea44937d2f7fafda22ad2f9/gr15_lrg.jpg gr15 gr15_lrg.jpg jpg 615747 2372 2568 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr16_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr16/HIGHRES/image/jpeg/2076a0a45b36e2196e7f8dc2f0de0aff/gr16_lrg.jpg gr16 gr16_lrg.jpg jpg 464713 1726 2962 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr17_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr17/HIGHRES/image/jpeg/a5a7f8fe721625c7ebd39adfae28fcff/gr17_lrg.jpg gr17 gr17_lrg.jpg jpg 545091 2276 2568 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr18_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr18/HIGHRES/image/jpeg/973dff2b76232925a896cb10ce696dbe/gr18_lrg.jpg gr18 gr18_lrg.jpg jpg 796120 2466 2764 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr19_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr19/HIGHRES/image/jpeg/aafb0f5ea435d0d69293ea3f5b700722/gr19_lrg.jpg gr19 gr19_lrg.jpg jpg 994914 3264 2568 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr20_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr20/HIGHRES/image/jpeg/a08d1ae799d4628382393976fc9f714b/gr20_lrg.jpg gr20 gr20_lrg.jpg jpg 292605 1228 2410 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr21_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr21/HIGHRES/image/jpeg/595e3c29457b9e32115e8e7282139357/gr21_lrg.jpg gr21 gr21_lrg.jpg jpg 776077 3018 2764 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-gr22_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/gr22/HIGHRES/image/jpeg/116aeefafe07fec749b0f72eecb59033/gr22_lrg.jpg gr22 gr22_lrg.jpg jpg 730705 2836 2568 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-fx3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx3/HIGHRES/image/jpeg/17f47a9f2810965d73c90e0754484ae8/fx3_lrg.jpg fx3 fx3_lrg.jpg jpg 130343 311 497 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-fx4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx4/HIGHRES/image/jpeg/084b108f9fe8e575120da48b4240a3c3/fx4_lrg.jpg fx4 fx4_lrg.jpg jpg 125548 311 496 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx1/HIGHRES/image/jpeg/fe526734e3b999c90b5f4f1bd3a4b8b7/fx1_lrg.jpg fx1 fx1_lrg.jpg jpg 118994 307 496 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-fx2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/fx2/HIGHRES/image/jpeg/f6ff658a027a6711dccc4b7ef16c46b8/fx2_lrg.jpg fx2 fx2_lrg.jpg jpg 125348 311 498 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-ga1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/ga1/HIGHRES/image/jpeg/74e74ed486699e3aa8133967ce78d5d1/ga1_lrg.jpg ga1 true ga1_lrg.jpg jpg 375891 886 1468 IMAGE-HIGH-RES 1-s2.0-S2352710221016363-mmc2.mp4 https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/mmc2/MAIN/video/mp4/64d0d8b12f906851da494d670e594240/mmc2.mp4 mmc2 mmc2.mp4 mp4 11846020 VIDEO 1-s2.0-S2352710221016363-mmc1.mp4 https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/mmc1/MAIN/video/mp4/0aaad53540c5473b079f1e6d526cea35/mmc1.mp4 mmc1 mmc1.mp4 mp4 17523048 VIDEO 1-s2.0-S2352710221016363-si2.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/STRIPIN/image/svg+xml/8c93dc05519bf5b3e6cebea2ce4ea925/si2.svg si2 si2.svg svg 57200 ALTIMG 1-s2.0-S2352710221016363-si3.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/STRIPIN/image/svg+xml/96a13710458222429331fe3066c0ed19/si3.svg si3 si3.svg svg 52646 ALTIMG 1-s2.0-S2352710221016363-si4.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/STRIPIN/image/svg+xml/1f8c42cdca4c51121408f4f69d3ce299/si4.svg si4 si4.svg svg 91214 ALTIMG 1-s2.0-S2352710221016363-si1.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710221016363/STRIPIN/image/svg+xml/ebf101151ca8fb43c21f2194a9674cce/si1.svg si1 si1.svg svg 54188 ALTIMG 1-s2.0-S2352710221016363-am.pdf am am.pdf pdf 3862022 AAM-PDF https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:10QK7B0LB29/MAIN/application/pdf/5ed047f2da447340729890448c8fec0b/am.pdf JOBE 103778 103778 S2352-7102(21)01636-3 10.1016/j.jobe.2021.103778 Elsevier Ltd Fig. 1 A coupled real-time detection and prediction method for internal heat gains powered by deep learning and computer vision. Fig. 1 Fig. 2 An outline of the research approach for the coupled detection and prediction. Fig. 2 Fig. 3 The CNN architecture used for model training for equipment and occupancy detection and recognition. Fig. 3 Fig. 4 a) SRB building and location of the experiment room, and b) view from the camera and the detected occupants and equipment. Fig. 4 Fig. 5 Simultaneous detection and recognitions of PC screens and occupants and formation of the DLIP. Fig. 5 Fig. 6 Static a) Occupancy and b) Equipment profiles. Scenario-based c) Occupancy, and d) Equipment profiles representing a typical office week (Wednesday \u2013 Saturday). Fig. 6 Fig. 7 Total loss versus the number of training steps. Fig. 7 Fig. 8 Confusion matrix showing the performance of the detection model for a) equipment and b) occupancy activity. Fig. 8 Fig. 9 Preview of real-time equipment and occupancy activity detection model \u2013 Experimental Test., see Video 1. Fig. 9 Fig. 10 Example captures of important stages during the test. Fig. 10 Fig. 11 Average bounding box detection accuracy for a) PC Monitor on and b) occupancy activities of sitting, standing and walking, during the experimental test. Fig. 11 Fig. 12 The detection performance of equipment (PC monitors on) during the experimental test. Fig. 12 Fig. 13 Detection performance of occupants' activities during test. Fig. 13 Fig. 14 Experimental test detection performances of equipment (PC monitor on) based on the percentages of labels identified. Fig. 14 Fig. 15 Experimental test detection performances of occupancy activities based on the percentages of labels identified. Fig. 15 Fig. 16 Preview of video showing the application of the proposed detection model in the test with the DLIP generation, see Video 2. Fig. 16 Fig. 17 Counting-based deep learning profiles for detected a) Equipment, and b) occupancy obtained from the test carried out in the test room. Fig. 17 Fig. 18 Heat gain-based deep learning profile for detected a) equipment and b) occupancy vs Typical Profiles and the Actual Observation Profile for comparison. Fig. 18 Fig. 19 a) Equipment, b) occupancy sensible, and c) occupancy latent heat gain distributions under Scenario 1\u20134 for four days. Fig. 19 Fig. 20 Total internal heat gains under Scenario 1-4. Fig. 20 Fig. 21 a) Distribution of heating loads and b) total heating loads for four days during the heating season under Scenario 1-4. Fig. 21 Fig. 22 a) Distribution of cooling loads and b) total cooling loads for four days during cooling season under Scenario 1-4. Fig. 22 Table 1 The number of images for training and testing the equipment and occupancy activities detection model. Table 1 Equipment No. of Images No. of Labels Training Testing Total Training Testing Total PC Monitor 400 100 500 873 150 1023 Occupancy Activities Training Testing Total Training Testing Total Sitting 400 100 500 753 149 902 Standing 400 100 500 701 134 835 Walking 400 100 500 1000 177 1177 Table 2 Overview of the scenarios for the BES model. Table 2 Scenario 1:Constant Typical Scenario 2: Equipment Detection Only Scenario 3: Occupancy Detection Only Scenario 4: Coupled Image Representation Image 1 Image 2 Image 3 Image 4 PC Monitor on Profile Static Profile (Fig. 6b) Equipment DLIP (Fig. 6d) Static Profile (Fig. 6b) Equipment DLIP (Fig. 9b) Number of PC Monitor On (Equipment) 8 during each weekday and 4 during the weekend Varies according to the equipment usage 8 during each weekday and 4 during the weekend Varies according to the equipment usage For each PC, it represents 2 PC monitor-on and 1 computer-onMaximum conditions: 4 PCs = (8 PC Monitors turned on, 4 Computers) Occupancy Profile Static Profile (Constant sitting) (Fig. 6a) Static Profile (Constant sitting) (Fig. 6a) Occupancy DLIP (Fig. 6c) Occupancy DLIP (Fig. 6c) Number of occupants' present in room 8 during each weekday and 4 during the weekend 8 during each weekday and 4 during the weekend Varies according to the actual occupancy Varies according to the actual occupancy Occupancy Internal Gains Max sensible gain: 75W/personMax latent gain: 70W/person Equipment Internal Gains Monitor gain: 50W/per monitorPC gain: 200W/per PC Heating Profile 22 °C during building operational hours [38,39] Cooling Profile 25 °C during building operational hours [38,39] Table 3 Summary of model training results. Table 3 Training Conditions and Results Equipment Model Occupancy Activity Model Model Used Faster RCNN with InceptionV2 Total Steps 85,422 102,194 Training Duration 5 h 3 min, 51 s 10 h 29 min, 52 s Average Loss 0.0577 0.13436 Minimum Loss 0.003516 0.005654 Table 4 Performance of the equipment usage detection model. Table 4 Equipment Accuracy Precision Recall F1 Score PC Monitor 83.33% 0.9124 0.9058 0.9091 Table 5 Performance of the occupancy detection model. Table 5 Activity Accuracy Precision Recall F1 Score 1 Sitting 94.04% 0.9250 0.8911 0.9077 2 Standing 91.43% 0.9064 0.8284 0.8657 3 Walking 92.70% 0.8643 0.9266 0.9047 Table 6 Equipment model performance evaluation based on evaluation metrics. Table 6 Equipment: PC monitor on Accuracy Precision Recall F1 Score Monitor A 80.10% 1.0000 0.8010 0.8895 Monitor B 99.12% 1.0000 0.9912 0.9956 Monitor C 89.22% 0.9986 0.8934 0.9430 Monitor D 41.07% 1.0000 0.4107 0.5822 All PC Monitors 76.21% 1.0000 0.7621 0.8650 Table 7 Occupancy activity model performance evaluation. Table 7 Class Activity Accuracy Precision Recall F1 Score Person A 1 Sitting 89.02% 0.7715 0.9419 0.8482 2 Standing 81.48% 1.0000 0.4445 0.6154 3 Walking 81.64% 0.8287 0.9412 0.8814 Person B 1 Sitting 71.26% 0.5335 0.9268 0.6772 2 Standing 66.67% \u2013 0.0000 0.0000 3 Walking 85.56% 0.7297 0.9000 0.8060 Person C 1 Sitting 99.00% 1.0000 0.9900 0.9950 2 Standing \u2013 \u2013 \u2013 \u2013 3 Walking \u2013 \u2013 \u2013 \u2013 All Occupants 1 Sitting 86.95% 0.7305 0.9549 0.8278 2 Standing 79.37% 1.0000 0.3810 0.5518 3 Walking 90.58% 0.8130 0.9318 0.8684 Average for all activities 85.63% 0.8478 0.7559 0.7493 A coupled deep learning-based internal heat gains detection and prediction method for energy-efficient office building operation Shuangyu Wei ∗ Paige Wenbin Tien Yupeng Wu John Kaiser Calautit Dept. of Arch and Built Env, University of Nottingham, Nottingham, NG7 2RD, UK Dept. of Arch and Built Env University of Nottingham Nottingham NG7 2RD UK Dept. of Arch and Built Env, University of Nottingham, Nottingham, NG7 2RD, UK ∗ Corresponding author. Occupants' behaviour and the use of electrical equipment can significantly impact the building energy demand. Accurate occupancy and equipment usage information are key to improving the performance of demand-driven control, which can automatically adjust the heating, cooling and ventilation system operation. Employing static schedules is commonly used for the operation of heating, ventilation and air-conditioning systems, while it cannot satisfy the actual requirements due to the dynamic variations within the conditioned spaces. This study introduces a coupled real-time occupancy and equipment usage detection and recognition approach using deep learning and computer vision techniques for efficient building energy controls. The experimental results presented an overall equipment detection and occupancy activity detection accuracy of 78.39% and 93.60%. To investigate the influence of the implementation of the approach on building energy demand, a case study office building was selected to conduct experimental tests and modeled using a building energy simulation tool. Four scenarios with different occupancy and equipment profiles were defined and evaluated. The simulation results showed that heat gains, when employing static profiles were larger than the heat gains predicted when using the deep learning influenced profiles. Up to 53.95% lower heat gains were estimated when using both occupancy and equipment detection approaches than static schedules solely. The results highlighted the importance of monitoring real-time occupancy and electrical equipment usage and the advantages of using deep learning detection techniques to provide data for demand-driven controls, optimising building energy efficiency while maintaining a comfortable indoor environment. Graphical abstract Image 1 Keywords Artificial intelligence Buildings Deep learning Computer vision Energy HVAC 1 Introduction and literature review The growing consumption of energy from the built environment sector can be attributed to the increasing urbanisation and living standards [1]. While this is a significant contributor to greenhouse gas emissions worldwide [2], it also presents a great opportunity to reduce energy demand and help achieve the targets set by many nations to cut emissions. Hence, many researchers are focusing on developing strategies and technologies to enhance buildings\u2019 energy efficiency. A large portion of this energy used is due to the conditioning of the building spaces to provide comfortable space for its occupants. In particular, due to the COVID-19 pandemic, ventilation will be integral to the risk mitigation strategy for reducing the transmission of COVID-19 [3]. This could increase the demand for higher ventilation rates, especially with more people returning to the workplace during and after the pandemic [4]. The increased ventilation rates could lead to increased energy use, particularly when using mechanical systems. In addition, the pandemic has also affected how we use spaces such as offices. Workplaces have adopted flexible or hybrid working environments, which will impact the building occupancy level and the heating, ventilation and air-conditioning (HVAC) operation [5]. The occupancy, especially in large-sized spaces, will be more difficult to estimate or predict [6], and the use of traditional HVAC control strategies can lead to a mismatch of the demand and supply of building services [7]. Such control strategies could be employing fixed setpoint schedules for the HVAC operation and would inevitably result in under or over-conditioning issues [8]. An example is when an HVAC system runs at full capacity while there are no occupants in the conditioned space. This could lead to a substantial waste of energy and resources. The building occupants generate heat depending on the level of activity. This increases the internal heat gains and affects the energy consumption of heating or cooling systems, depending on the indoor-outdoor conditions [9]. Therefore, with the varying occupancy levels, activities and distribution, the HVAC system operation will vary and require various amounts of energy at different times of the day to provide comfortable conditions for the occupants. Indirectly, occupants can also affect the internal heat gains by using equipment and appliances in the building [10]. Like the occupancy levels, equipment usage in offices such as computers and laptops can also be varied, depending on several factors. For example, the occupants may leave their computers ON when taking breaks or leaving the office [11]. This could lead to uneven heat gains distribution and cause difficulties in the design and efficient operation of HVAC. Recently, there has been an increase in the number of studies on the development of demand-driven control strategies for buildings, which can better adapt to the stochastic nature of occupancy and minimise unnecessary energy usage while providing comfortable indoor conditions [11,12]. Unlike conventional strategies, which assumes a certain number of occupants present throughout the day, such strategies coordinate the actual or real-time operation of the HVAC to the requirements of the space and its occupants [13]. Energy can be saved by reducing the operation time of the HVAC and also adjusting the heating, cooling and ventilation setpoints based on the information obtained about the space [14]. Real-time information on the occupancy number, location and activities, equipment number, status and type will be central to the effective implementation of such an approach [15,16]. Various sensor technologies can be used to detect and collect data on occupancy number and location, such as PIR sensors [17], RFID [18], WiFi [19] and Bluetooth [20] and wearables [21]. Some researchers also developed and investigated the application of motion sensors for occupancy movement tracking [22]. Recently, cameras have been employed in several research studies to track occupancy behaviour or activities [9] using visual detection approaches based on artificial intelligence and computer vision. Later, the study [10] employed a similar approach to identifying equipment switched ON in an office space to detect the count, location, type, and status of equipment and predict the sensible heat gains. These technologies can be integrated with demand-driven controls to provide real-time information, which can help estimate the actual cooling, heating and ventilation demands of a building zone or space. Such technologies are powered by artificial intelligence (AI) approaches such as computer vision and deep learning. For example, the study of [23] developed a vision-based method for counting occupants in offices. The experimental study showed that the technique performed better for a smaller office with less than 5 occupants. The study showed that the proposed system could reduce building energy consumption, but there are several issues raised, such as privacy concerns. Furthermore, the study only focused on the occupant's number and did not consider other parameters such as activities and interaction with appliances and equipment. While the work of [24] introduced an approach using video cameras to measure the thermoregulation states of the occupant, which can then be used to control the HVAC system. Like many of the existing studies [25\u201327] on the application of computer vision for occupancy information detection, the main focus was on enhancing the performance of the model for detection rather than evaluating its impact on the building energy performance. 1.1 Research gap and novelty The previous works highlighted the importance of demand-driven controls for HVACs, which can lead to energy saving in buildings. At the same time, the integration with cameras and vision-based approaches is promising. In particular, its applications for the detection of occupancy behaviour can then be used to estimate the heat emissions in real-time and adjust the HVAC operation. In addition, the appliances and equipment in spaces can also be detected, which also contributes to the internal heat gains, and their usage is dependent on the occupants utilising the space. Hence, a combined approach that can detect occupancy and equipment usage simultaneously in real-time is desirable and will be developed in this study. Furthermore, there is limited implementation of such an approach in real-world environments, providing more insight into its capabilities. This is particularly evident in the context of commercial buildings such as offices spaces. Finally, the impact of the application of such an approach on the building energy demand must be investigated. This study will address this by comparing scenarios including a building that employs conventional control strategy, occupancy detection, equipment usage detection and the combination of both. 1.2 Aims and objectives The present work aims to develop a detection approach for the occupancy and equipment usages in an office space, simultaneously and in real-time, to adjust HVAC controls based on actual demands, as illustrated in Fig. 1 . It can reduce not only unnecessary building energy use but also maintain a comfortable indoor environment. The detection method will be developed based on the Faster R\u2013CNN model, which is suitable for the required detection tasks. The model will be trained in the Tensorflow software and deployed to an AI-powered camera. The tests will be conducted in an office space at the University of Nottingham and used to detect different occupancy activities such as sitting and walking and the computers switched ON. The detection performance will be evaluated using standard evaluation metrics suggested in the literature. The approach will generate activity, usage and heat gain profiles, which can then be used as input for the control system. In this study, BES will be used to evaluate different scenarios of applying the proposed approach. Each scenario represents a different variation in equipment and occupancy profiles to demonstrate the effectiveness of demand-driven controls integrated with live occupancy and equipment detection. 2 Method An overview of the proposed research method is summarised in Fig. 2 . As mentioned previously, an office building at the university was selected to test the coupled detection approach, and evaluation was carried out by assessing the detection performance and performing BES modelling of different scenarios. 2.1 Deep learning approach Deep learning is a type of machine learning algorithm that employ several layers to extract high-level features from the data instead of manually adding required features for recognition and classification tasks. To attain the desired results, a majority of the deep learning methods requires to implement neural networks. Powerful computational tools and high volumes of data are needed for all the deep learning models to extract features. Recently, numerous applications of the deep learning method have been developed, especially object detection using computer vision methods. The present study will use the convolutional neural network (CNN) because of its good performance in images and videos tasks [28]. The dataset's pre-processing is not required because the original images will be directly fed into the model [29]. 2.1.1 Pre-processing As a large amount of data is required for the CNN model to learn features, collecting data for the model training and testing is this framework's first and important step. Because previous studies solely provided limited data, a larger dataset must be created by collecting images from the Google search engine. The images of occupants performing different activities, including sitting, walking, and standing, were collected for occupancy detection, and the images of personal computer monitors in different offices which are On were collected to perform equipment detection. Following [30], 80% of the data was employed to train the model, and the rest of the data was used for testing. Table 1 presents the details of the created dataset in this study. After using LabelImg to label the desired objects in the dataset, the XML files were generated and then converted to TFRecord files to train and test the proposed CNN model. 2.1.2 Selection and configuration of the detection model Region-based CNN (R\u2013CNN) models are the most frequently used deep learning models for object detection. They extract a large amount of region proposals from the input image, which most likely contain the desired objects, and then employs a CNN to generate features for each proposal. Based on this, the classifier layer classifies the object on the input image [31]. However, the originally developed R\u2013CNN models were computationally expensive in both space and time to perform object detection [31]. Therefore, Fast R-CNNs were developed to significantly reduce the computational cost by sharing the convolutions across proposals [32,33]. It doesn't require disk storage for feature caching but provides better detection quality than R\u2013CNN [33]. To further improve the efficiency and accuracy, the Faster R-CNNs were formed based on Fast R\u2013CNN with the use of Region Proposal Networks (RPNs), which can efficiently generate the region proposal. This leads to a further reduction of the cost and improvement of accuracy. Therefore, the Faster R\u2013CNN model was employed as the detection model in the present work. Additionally, in order to reduce the computational expense and optimise the detection performance, an inception module was involved in the Faster R\u2013CNN model to enhance the computing resources [34]. Fig. 3 presents the architecture of the proposed Faster R\u2013CNN with InceptionV2 for equipment and occupancy detection. 2.2 Application of the CNN-based approach The following sections detail the implementation of the proposed approach in the case study building. The experimental setup and procedure are discussed. Furthermore, the deep learning influenced profile (DLIP) formed by gathering the live detection data is also discussed. 2.2.1 Experimental setup In this study, the Sustainable Research Building at the Department of Architecture and Built Environment at the University of Nottingham, as shown in Fig. 4 a, was selected as the case study building. An open-plan office on the first floor of this building was selected as the test room to conduct the experimental tests. The building is constructed to a very high standard, achieving a BREEAM rating of Excellent. The construction materials\u2019 properties are detailed in Section 2.3.3. To cover one side of the test room, a camera that was connected to a PC was installed at one of the corners close to the ceiling of the room. Fig. 4b presents the view of the test room from the camera. In future works, a 360 camera could be used to capture the entire space. Within the detected side of the room, 6 monitors were connected to a desktop computer respectively. The approximate heat rates of a monitor and a computer are listed in Table 2 . It should be noticed that the actual heat rates of the computers are not constant and could be affected by the usage and applications running on the computers. This impact will not be taken into account in the present study but will be investigated in future work. The building has several openable windows for natural ventilation and a window air conditioning unit, typically operated at a set point of 21 °C during occupied hours. 2.2.2 Experimental procedure and formation of DLIP As the metabolic heat production rate is dependent on physical activity, the heat released from a human body is varied when the person is performing different activities. This could cause a relatively great change of internal heat gains, especially when a building is occupied by a large number of people. The heat gain is a significant factor in designing the operation strategy for HVACs. Therefore, by detecting and recognising different occupants\u2019 activities, a more accurate and efficient HVAC control operation can be performed to meet the actual requirements of thermal comfort and generate potential energy savings. During the test, different types of office activities were carried out by the occupants, including walking, sitting and standing. Although there were other types of activities, only three types were considered since the detection model was trained only to detect the walking, sitting and standing activities. In addition, the behaviour of the occupants also influenced the usage of computers and monitors. Therefore, the model was also trained to enable the detection and recognition of the monitors when they are switched ON. When performing live detection, the real-time information of the occupants' activities and PC monitors\u2019 mode were collected and used to generate the occupancy and equipment profiles. Fig. 5 shows an example of the DLIP formed from 2 frames. It should be noted that the images taken by the device are solely used as an example to show how the proposed approach detects and recognises PC monitors and occupants simultaneously. In reality, no images or videos will be captured or output from the camera. Only DLIP graphs will be generated, which can then be employed to predict the heat emission in the detected space. 2.3 Model performance and analysis As demonstrated in Fig. 2, the performance of the model is evaluated according to the experimental detection and recognition results and the analysis of obtained results and also building energy performance simulation and analysis. The conditions for the framework analysis are provided in this section. 2.3.1 Evaluation of the detection method To evaluate the performance of the trained model, the model would be tested using the generated test dataset detailed in Table 1, and the results would be demonstrated in a confusion matrix. The values are obtained in terms of true positive (TP), which is a correct detection, true negative (TN), which is a correct detection but wrong classification, false positive (FP), which is the number of instances that the prediction was wrong and false negative (FN) which is the number of instances when it is classified as something else, but it actually wasn't. In this study, four evaluation metrics were employed to assess the detection performance: accuracy, precision, recall and F1 score. Eqs. (1)\u2013(4) express these evaluation metrics respectively according to the created confusion matrix. (1) A c c u r a c y = ( T P + T N ) ( P + N ) (2) Precision = TP TP + FP (3) Recall = TP TP + FN (4) F 1 S c o r e = 2 × P r e c i s i o n × R e c a l l P r e c i s i o n + R e c a l l 2.3.2 Internal heat gains estimation As the internal heat gains are significant factors to design the operation of the HVAC controls, it is useful to attain the correct estimation of the heat gains to obtain more accurate results of building energy performance and achieve efficient controls according to these results. The total equipment heat gain was calculated by summing the heat rates of the detection monitors and computers [35]. While the heat emissions from different occupancy activities such as sitting, standing and walking [35] are used to predict the total heat emissions from occupants. 2.3.3 Building energy simulation The details of the building energy simulation and conditions for analysing the impact of the proposed approach on building energy demands with the use of the suggested test scenarios are provided in this section. The BES tool Integrated Environment Solutions Virtual Environment (IES VE) was used for building energy simulation. The validation of the tool and the theory are fully detailed in our previous works [36,37]. The geometry was modeled with some simplifications. For instance, some features such as surrounding buildings and furniture were not included. Several thermal zones were modeled within the building to allow specific settings and evaluation in different zones. The U-value of the roof and floor were 0.15 W/m2K, the wall was 0.17 W/m2K and windows were 1.92 W/m2K. The infiltration rate was set to be 0.1ach. The setpoint temperature for cooling was set to 25 °C and for heating was 22 °C [38,39]. Several scenarios were simulated using different profiles for the occupancy and equipment heat gains, as detailed in Table 2. Each scenario represents a different variation in equipment and occupancy profiles and would be used as input for BES models to demonstrate the effectiveness of the integration of demand-driven controls and live detection. Table 2 provides the details of each scenario and setups for the building simulation. For each scenario, four days of a typical week (Wednesday \u2013 Saturday) in the heating and cooling period were selected and simulated here. Scenario 1 represents the conventional method where static or fixed setpoints are used for the control strategy. The typical occupancy and equipment profile for PC monitors given in Fig. 6 a and b were assigned to this simulation case. Effectively, during the building operational hours, the most common occupancy activity in an office space being \u2018sitting\u2019 were assumed to be performed by 8 occupants during the weekday and 4 people performing this on the weekend. Correspondingly, for electrical equipment, 8 PC monitors were assumed to be turned on throughout the building operational hours during the 3 weekdays, and 4 PC monitors were on during the weekend. Scenarios 2 and 3 presents the application of only one of the deep learning detection approaches with scenario 2 for equipment only, scenario 3 for occupancy activity only and scenario 4 when both detections were applied. For these scenarios, Fig. 6c and d presents the assigned occupancy and equipment profiles. To provide a more realistic scenario, different profiles were created for each day, and a brief description of each is given in Fig. 6. 3 Results and discussion 3.1 Evaluation of model training The proposed equipment and occupancy detection models, as described in Section 2.2 was trained using the Faster RCNN with InceptionV2 mode. Table 3 shows the corresponding training results. According to the total loss graphs presented in Fig. 7 , it can be indicated that the models have been adequately trained because of the convergence of their loss functions. The trained models were used to perform detections on the images located within the testing dataset (Table 1) to generate confusion matrices in Fig. 8 , and the corresponding performance results in Table 4 for the equipment detection model, and Table 5 for the occupancy activity detection model. The equipment detection was trained to detect and provide recognition responses of PC monitors ON. Based on the images within the test dataset, a total of 150 prediction labels should be assigned to these images. The results suggest 125 labels (83.33% of the total number of labels) were correctly assigned to PC monitors ON. This influenced the provision of the overall model performance giving an average detection accuracy of 83.33%. Moreover, 12 labels were identified as \u201cPC monitor on\u201d when they were turned off and 13 labels were not identified as \u201cPC monitor on\u201d when they were in use. Based on these results, an overall F1 score of 0.9091 was achieved, suggesting the model can provide adequate detection and recognition of PC monitors. For the occupancy activity detection model, the confusion matrix was presented based on the percentage of response labels achieved, as this was due to the variation in the number of labels for each of the responses within the test image dataset. The activity of sitting achieved the highest performance with a detection accuracy of 94.04%. However, the body forms and shapes of occupants when they are standing and walking are slightly similar, which may result in the difficulties in recognising the actual occupancy activity. Therefore, it causes a lower accuracy values of standing and walking activities, which are 91.43% and 92.70% respectively. In spite of this, based on the confusion matrix results, it suggested that the model can provide sufficiently accurate detection of occupants within indoor spaces as most of the prediction labels identified the activities correctly. 3.2 Detection performance and profiles 3.2.1 Detection performance To test the model's detection performance, the occupants performed all of the selected occupancy activities, and the PC monitors were presented as both on and off. Fig. 9 presents a preview of the application of both equipment and occupancy models under real-time detection and recognition during the experiment. The camera was located close to the space's ceiling at the height and angle. In practice, the device will only output the number of occupants conducting each of the activities and the PC monitors identified as being on in real-time. No image or video will be stored or outputted during the entire process. The information outputted from the device can then be employed to generate deep learning influenced heat emission profiles and adjust the HVAC system operation to achieve an efficient and adaptive control. According to the experimental detection test carried out within the selected case study office space, Fig. 10 shows snapshot images from the various key stages highlighted by the timeline in Fig. 9. As previously given by the evaluation of the model approach with the capability to detect through sources of still images in Section 3.1, more importantly, Fig. 10 presents further verification of the model's capability to detect both occupants and equipment within an actual office space under real-time. Bounding boxes were presented as an output to the detection and recognition response. Above each of the boxes, it shows the detection accuracy. Furthermore, both the appearance and the bounding boxes' shape and sizes varied between each of the detection intervals. 3.2.2 Detection performance analysis The analysis was based on the performance of the CNN-based detection approach during the experimental test. Fig. 11 demonstrates the average bounding box detection accuracy. The value of the accuracy for each detected target showed above each of the bounding boxes. Individual detection accuracy for each PC monitor, and each person presented within the camera detection recording was also obtained. As described in Section 2.3.1., for analysis, the PC monitors that appeared in the detection camera screen from left to right were each given the names of PC Monitor A, B, C and D. Similarly, the occupants were also noted as Person A, B and C. Overall, the PC monitors achieved an average accuracy of 93.75%, with the highest detection accuracy achieved by PC Monitor C with 96.78% and the lowest was achieved by PC Monitor D with 82.23%. The PC monitors' detection accuracy variations suggest the results had a large impact from different factors. Since, PC monitor D was positioned the furthest away compared to the other PC monitors where it was approximately 7.5 m away from the camera, compared to PC monitor C, positioned at approximately 5 m away from the camera, it resulted in the lowest detection accuracy. Furthermore, the PC monitor positioning angle may also have influenced the variation in the detection performance achieved between PC monitors A, B and C. Because the experimental test was carried out for a short period, not all of the different activities were performed by the occupants. Despite this, the data obtained from the test was still enough for the analysis of the detection performance. Fig. 11b presents the detection performance of occupancy activities. Overall, stable performance with minimal detection accuracy variations was achieved for all the activities performed by the detected occupants, giving an average detection accuracy of 98.7%. All three occupants performed the activity of sitting, and the detection of Person A, B and C achieved the accuracies of 97.88%, 98.91% and 98.38%, respectively. Since Person B achieved the highest value, and Person A achieved the lowest, it suggests that distance had a negligible effect on people's detection and recognition with a sitting position. However, the camera angle used for detection may impact the low detection accuracy achieved for Person A compared to Person B. The standing activity was only performed by Person A, and an accuracy of 98.81% was achieved. Additionally, walking by Person A and B achieved an accuracy of 98.72% and 98.75%. Effectively, the detection performance achieved for both equipment and occupancy is solely based on the developed detection models and its detection performed during this experimental test. Therefore, it presents the occupancy activity-based model's capabilities to identify the differences between the human body shapes for each specific activity and the equipment model to detect and recognize PC monitors within an office-based environment. Figs. 12 and 13 present the overall detection performance, with Fig. 12 for equipment (PC monitor on) and Fig. 13 for occupancy activity. The detection labelled assigned at every second during the experimental test was classified as a correct detection, no detection, or incorrect detection. Because the performance of PC monitors was influenced by the detection camera's distance from the PC monitors, Fig. 12 was evaluated based on each PC monitor. The aspect for the achievement of a correct detection includes the times when the PC monitor was on and correctly identified, and the times when detection was not implemented when the monitors were off. However, as evaluated by the stable bounding box detection accuracy across all occupants and activities, results given in Fig. 13 were based on each activity and not each person. Additionally, for occupancy activity, correct detection was given when the device correctly recognized the activity performed by the occupant and when detection was not implemented as the occupant was not performing that activity. Fig. 12 presents the breakdown of each of the monitors' detection performance and suggests the results partially succeed the evaluation made about the bounding box detection accuracy. PC Monitor D achieved the lowest amount of correct detections due to its distance from the detection camera. PC Monitors A, B and C achieved of correct detections for 82.80%, 99.22% and 90.46% of the time. Since there was constant obstruction of Monitor A and C by Person A and B, it may have influenced Monitor B to achieve the highest value. Overall, it showed that correct detections for PC monitors were recorded for an average of 78.39% of the time, no detections for 21.59% of the time, and subsequently incorrect detections for 0.03% of the time. For occupancy activities, the results presented in Fig. 13 suggests an overall achievement of correct detections for 93.60% of the time, no or missed detections for 4.22% of the time and incorrect detections for 2.18% of the time. Based on the three activities, the best results were achieved for the activity of sitting as this action is very different to the activities of standing and walking. Effectively, the body poses when people are standing and walking are similar, which influenced the activity of standing to achieve low correct detection. Furthermore, a category entitled \u2018None\u2019 was added for this evaluation of occupancy activity detection performances. This category demonstrated that no activity was identified by the model when such occupant was not present. This was achieved 83.78% of the time. Accordingly, it was incorrect by displaying a detection of any form of activity when actually there was no activity conducted for 16.22% of the time. 3.2.3 Further detection accuracy evaluation This section provides a further evaluation of the detection performance during the test according to the analysis using the classification evaluation metrics. Fig. 14 shows the different PC monitors' results based on the prediction response label of \u2018PC monitor on\u2019, and Fig. 15 shows the results for the different occupants based on the selected activities. Given in the following confusion matrixes, the number of labelled responses appeared as true positives (top left), true negatives (bottom right), false positives (top right) and false negatives (bottom left) were displayed in the form of percentage values due to the unbalanced number of labels for each response as different activities were performed for various times during the experimental test. Alike the results presented in Fig. 12 of the overall detection performance for PC monitors, the confusion matrix results suggest that the best performance was achieved when detecting PC monitor B with the highest percentage of true positives, succeeding by PC Monitor C, A and then D. The confusion matrices indicated by Fig. 12e suggests that overall, there was some occurrence of false negatives, where the PC monitors were detected as off or other when actually the monitors were on. Additionally, minimal occurrence of true negative results was achieved. According to the confusion matrix results illustrated in Fig. 15 for each PC monitor, different evaluation metrics listed in Table 6 can be obtained to further evaluate the detection performance. The average accuracy of 76.21% with an F1 score of 0.8650 was achieved. The best performance was achieved by Monitor B with an accuracy of 99.12% and a F1 score of 0.9956 and the lowest performance was Monitor D with an accuracy of 41.07% and a F1 score of 0.5822. Hence, the results in Table 6 for the different PC monitors reinforces the evaluation made in Section 3.2.2. and indicates that most of the detection response labels were correctly assigned to the PC monitors. The confusion matrices are given in Fig. 15 clearly presents the detection performance of each of the activities performed by each person. It verifies that Person A and B performed all three activities during the experimental test, while Person C only performed the activity of sitting. Based on the detection and recognition of all occupants, high performance was achieved for the activity of sitting, with only the occasional no predictions made that was highlighted within the response category of none or other and times. Additionally, there were times when sitting predictions were made when actual occupants were not present. This was considered as incorrect detections since some of the chairs were identified as occupants performing the activity of sitting. Furthermore, the accuracy of the detection of the activity of standing was the lowest. On the contrary, walking activity achieved a good performance. Therefore, solely based on this experimental detection test using the developed detection model, the results suggest the activity of standing can be confused with the identification of it as sitting or walking. However, both activities of sitting and walking were less likely to be incorrectly recognized. Hence, there are limitations to the current model and could be further enhanced to improve the detection performances. Similar to Table 6, the results in Table 7 present the evaluation of the occupancy activity model performance with the use of the common evaluation metrics. The results reflect the evaluation made, presenting sitting and walking with higher accuracy and F1 scores than standing. In summary, the real-time application of the deep learning-based models in the selected office during the experimental test presents an overall accuracy of 76.21% for equipment and overall performance accuracy of 85.63% for occupancy activities. In comparison with the occupancy counting method developed in the study [23] which only performed accurately for a smaller office with less than 5 occupants, the proposed method, which is able to recognize occupants\u2019 activities and interaction with appliances and equipment, can also be implemented in large-size offices with a high detection accuracy. While the detection accuracy of the proposed model was lower than the relevant studies [24\u201327], which suggests that further improvements are required to achieve higher performance. 3.2.4 Deep learning profiles generation According to the real-time experimental detection using the deep learning models in Fig. 8, detection and response achieved provided time-stamped data in the form of both equipments (PC monitor on) and occupancy activities. The real-time based data was employed to generate the count-based deep learning influenced profiles (DLIP) presented in Fig. 16 , describing the provided video of the experimental test and profile generation. The formation of such profiles is based on the process described in Section 2.3.2. The profiles which were shown in the video presented in Fig. 17 , with Fig. 17a for equipment (PC monitor on) and Fig. 17b for occupancy activities. The profiles provide informative data about the amount of equipment in use and the occupants which were detected and performing each of the activities during the experimental test's detection period. To enable the real-time profile-based data to give assistance to building energy simulation and building energy system controls, the heat emission-based DLIPs were formed based on the equipment and occupancy profile indicated in Fig. 17. The heat emission-based profiles are shown in Fig. 18 . The generated DLIPs were compared with the static profiles and the Actual Observation Profile corresponding to the \u2018true\u2019 operation of the occupants' PC monitor and activity. Compared with the use of the typical profiles, the DLIP predicted up to 54.4% lower equipment heat gains from the PC monitor detection and up to 29.1% lower occupancy heat gains. This indicates the advantage of using such a deep learning-based approach to better understand the occupants and the equipment usage within the office space. It identifies the times when the equipment usage is increased or decreased, or occupants\u2019 activities is varied, which can affect the overall building HVAC system operations through the influence of the variations within the building internal heat gains. However, since the generation of the data for these profiles is highly dependent on the detection performance, the DLIP still alternates between different responses as shown in Fig. 18a and b. This resulted in the differences between the DLIP and the Actual Observation Profiles with up to 24.6% for PC monitors and only 4.14% for occupancy activities. Although there were variations between the DLIP and the Actual Observation Profile, it still provided DLIPs which were considerably advantageous in comparison to the Typical profiles as it avoided the majority of the high discrepancy indicating the potential of such deep learning-based approach for to provide a more accurate understanding of the conditions within the conditioned space for building energy system operations. 3.3 Building energy performance analysis The simulation was performed using the profiles defined in Scenario 1\u20134 to evaluate the deep learning method's impact to estimate building energy consumption. The simulation results in terms of the internal heat gains and heating and cooling demands are discussed in the following sections. 3.3.1 Internal heat gains The activity of occupants and the use of equipment generate internal heat gains. The amount of internal heat gains generated within a space is influenced by the changes in occupants\u2019 activities and equipment usage, which further affects the HVAC system operation strategy due to changing heating, cooling and ventilation demands within the conditioned spaces. Fig. 19 shows the distribution of occupancy and equipment gains overtime for the four typical days under different scenarios. The results of employing Scenario 1 present the heat gains using fixed or static profiles that were typically used for building heating, cooling and ventilation design. Comparing Scenario 1, the other scenarios, which employed the deep learning method to assess real-time occupancy and/or equipment profiles, generated significant differences in heat gains, especially on the days with similar profiles as Weekday 2. It also suggests that the requirements of building services are varied to achieve a comfortable indoor environment. To present the heat gain difference under four scenarios, the total equipment gains, occupancy sensible gains, and occupancy latent gains for four days were plotted in Fig. 20 . It is apparent that equipment gains are the major contribution of the total heat gains as there were only a few people whose main activity in the office space was sitting while a large amount of equipment was set up, which caused more heat emission from equipment. As Scenario 1 results represent the benchmark values, it shows that the total heat gain using the fixed or static profiles for four days was 139.4 kW. This value was larger than the results of the other scenarios assisted by the deep learning method for an accurate estimation. As compared to Scenario 1, Scenario 2, 3, and 4 created remarkable differences of 38.74%, 15.21%, and 53.95%, respectively. As can be seen, the lowest total heat gains were predicted when using the deep learning method for both equipment and occupancy gain estimations (Scenario 4). It indicated that an under- or over-estimation of occupancy and equipment heat gains could occur when using scheduled or static profiles. Therefore, incorporating the deep learning method into an HVAC system can help it predict the live heat gains of space and achieve efficient controls while meeting the actual requirements. In addition, based on the simulation results, Scenario 1, Scenario 2, which used equipment detection, generated a larger difference than Scenario 3, which used occupancy detection only. It implies that the detection of usage of equipment has a greater influence on heat gain estimation in the selected office space because of the relatively low number and less movement of occupants. 3.3.2 Heating and cooling demands This section analysed the energy consumption of the case study building under four different simulation cases (Scenarios 1\u20134) in heating and cooling seasons. Fig. 21 shows the heating results for the four selected days during the heating season. The heating load variation across the simulation days was presented in Fig. 21a. For Scenario 1 and 2, due to the use of the typical profile, the working hour in this office was assumed to be from 6:00 to 18:00, which means the office would be occupied during this period. Therefore, the heating setpoint temperature was set to be 22 °C in the pre-scheduled period. For Scenario 3 and 4, the heating was provided based on the actual occupied period because of the use of deep learning detection method. It could mitigate the waste of energy for unnecessary heating during the unoccupied period, especially on weekends. Moreover, it is apparent that equipment and occupancy gains directly affect the heating demand over time. When heat gains was estimated to be lower, more heating was required within the detected space to maintain the comfort level. The simulation results of the total heating demand for the selected four days during the heating period under Scenario 1\u20134 were shown in Fig. 21b, giving total heating loads of 5.4 kWh, 37.1 kWh, 4 kWh, and 42 kWh. Under Scenario 4, which predicted the lowest heat gains, it indicated that maximum heating was required among all simulation scenarios to achieve thermal comfort during the heating period. It indicated that following the static profile couldn't meet the actual occupants' demands for thermal comfort as the energy required to provide heating under Scenario 4 was more than six times higher then that under Scenarios 1. It highlighted that the proposed method enabled to address the issue of under-estimating the actual heating demand of reaching the required thermal level. It should be noted that the heat gains predicted for Scenario 1 was higher than that for Scenario 3, while the heating loads for Scenario 1 was also greater. The reason is in Scenario 3 the heating was provided based on the actual occupied period due to the use of deep learning-generated occupancy profile, while in Scenario 1 the provision of heating followed the static profile. The unnecessary heating provided during the unoccupied time was reduced in Scenario 3. Overall, although following the profiles generated by deep learning detection technique may increase the building energy use because more energy is required to make the HVAC system adapt to the actual demands during the heating season, it can make an improvement of occupants' comforts by maintaining a better indoor environment. Fig. 22 shows the cooling results for the four selected days in the cooling season. The cooling load distribution across the simulation days was presented in Fig. 22a. For Scenario 1 and 2, due to the use of a typical occupancy profile, the cooling was provided with the setpoint temperature of 25 °C from 6:00 to 18:00 in the office. The cooling was provided based on the actual occupied period under Scenario 3 and 4. This method could avoid providing unnecessary cooling in the conditioned space and further reduce the building energy consumption. In addition, the cooling demands were influenced by the variations of internal heat gains. With lower heat gains, it caused lower cooling loads. The total cooling demand during the cooling period was presented in Fig. 22b. As shown, the total cooling loads for selected days based on four scenarios were 132.7 kWh, 85 kWh, 117.3 kWh, and 72.5 kWh, respectively. Scenario 4, which employed both detection profiles, estimated the lowest cooling load among all the scenarios and to be 45.37% lower than Scenario 1, which employed fixed or static profiles. The results also indicated that deep learning techniques for occupancy and equipment detection could affect building energy consumption by providing accurate profiles to achieve demand-driven controls. According to the simulation results for selected four days within the case study building, up to 53.95% reduction of internal heat gains could be potentially achieved with the use of both occupancy and equipment detection profiles in comparison with the use of predefined typical or static schedules. In cooling season, the cooling load under Scenario 4 was estimated to be 45.37% lower than that under Scenario 1. While in heating season, the energy required to provide heating under Scenario 4 was more than six times higher then that under Scenarios 1. It suggests that the proposed method can cope with the issue of under- or over-estimating the building energy use when employing the static or fixed profiles. This highlighted the significance of the monitoring of occupancy behaviour and electrical equipment usage and the benefits of using deep learning and computer vision method to monitor real-time occupants\u2019 activities and equipment usage and effectively operate the HVAC system based on the actual requirements. While maintaining comfortable indoor environment, it may create a large potential to reduce the unnecessary building energy consumption. 4 Conclusions and future works The present study introduces an approach which enables the real-time detection of occupancy activity and equipment usage within an office space using computer vision and deep learning techniques for efficient building energy system controls. It offers a novel way to detect and model the occupants' behaviour and also use the detected (occupancy and equipment) information to control the operation of HVACs. In this study, a Faster R\u2013CNN model was selected and enabled the detection and recognition using a camera. Experiments were conducted within an office space to evaluate the proposed approach's practical capability. The experimental results showed that the approach achieved correct equipment and occupancy detections for 78.39% and 93.60% of the time. It indicates the occupancy and equipment detection tasked could be performed accurately using the proposed model. To evaluate the impact on building energy performance, a BES tool was used to model and run energy simulations for the case study building. The simulation results showed that approximately 54% of internal heat gains were predicted to be lower using both occupancy and equipment detection profiles (Scenario 4) compared to the use of static schedules (Scenario 1). This emphasised the importance of real-time occupancy and electrical equipment usage detection and the benefits of using deep learning techniques to generate profiles and input into HVAC control systems to perform efficient controls based on the actual demands. It does not only reduce the unnecessary building energy use but also maintain the comfort level within a space. It should noted that, in practice, no image or videos will be outputted from the device, and only the values of estimated heat gains from detected occupants and equipment will be provided, the occupants' information will not be collected or used in any way. Although the proposed approach has the ability to perform correct detection and recognition tasks to provide real-time equipment and occupancy information, more improvements are required to be implemented to attain a robust approach in future. To optimise the CNN-based model, its architecture will be modified, and more data will be collected and added to the dataset to reduce the error rate, which affects the accuracy of building energy demand estimation. The lower the error rate is, the more precise the energy demand estimation is, which could result in a better indoor environment for occupants. In addition, as people and equipment must always be visible from the camera, a 360 camera may be used to capture the entire space. For the large open space office, if one camera cannot detect and collect the necessary information, a network of cameras will be developed, and further data analysis will be performed to avoid data duplication. Moreover, a strategy which enables demand-driven controls by inputting the real-time equipment and occupancy information attained from the deep learning model to the HVAC system. Furthermore, further improvements will be made to prevent the camera from being hacked to protect the users\u2019 privacy in the future. Author statement Shuangyu Wei: Conceptualization, methodology, software, formal analysis, investigation, data curation, writing - original draft, writing \u2013 review & editing, visualization, validation. Paige Tien: Conceptualization, methodology, software, writing \u2013 review & editing, investigation. Yupeng Wu: Writing \u2013 review & editing, supervision, project administration. John Kaiser Calautit: Conceptualization, methodology, validation, resources, writing \u2013 review & editing, supervision. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements The work is supported by Engineering and Physical Sciences Research Council, United Kingdom (EP/R513283/1); and the scholarship from Faculty of Engineering, University of Nottingham, United Kingdom. The authors would also like to thank L. Yong and K. Calautit for their support in conducting the field experiments. Appendix A Supplementary data The following are the Supplementary data to this article: Multimedia component 1 Multimedia component 1 Multimedia component 2 Multimedia component 2 Appendix A Supplementary data Supplementary data to this article can be found online at https://doi.org/10.1016/j.jobe.2021.103778. Abbreviations AI Artificial Intelligence BES Building Energy Simulation CNN Convolutional Neural Network CNTK Microsoft Cognitive Toolkit DLIP Deep learning influenced profile FN False Negative FP False Positive HVAC Heating, Ventilation and Air-Conditioning IESVE Integrated Environment Solutions Virtual Environment R\u2013CNN Region-based Convolutional Neural Network RPN Region Proposal Networks TN True Negative TP True Positive References [1] L. Li W. Sun W. Hu Y. Sun Impact of natural and social environmental factors on building energy consumption: based on bibliometrics J. Build. Eng. 2021 102136 Li, L., Sun, W., Hu, W. and Sun, Y., 2021. Impact of natural and social environmental factors on building energy consumption: Based on bibliometrics. Journal of Building Engineering, p.102136. [2] J.K. Shrestha Assessment of energy demand and greenhouse gas emissions in low rise building systems: case study of five building systems built after the Gorkha Earthquake in Nepal J. Build. Eng. 34 2021 101831 Shrestha, J.K., 2021. Assessment of energy demand and greenhouse gas emissions in low rise building systems: Case study of five building systems built after the Gorkha Earthquake in Nepal. Journal of Building Engineering, 34, p.101831. [3] W. Zheng J. Hu Z. Wang J. Li Z. Fu H. Li J. Jurasz S.K. Chou J. Yan COVID-19 impact on operation and energy consumption of heating, ventilation and air-conditioning (HVAC) systems Adv. Appl. Energy 3 2021 100040 Zheng, W., Hu, J., Wang, Z., Li, J., Fu, Z., Li, H., Jurasz, J., Chou, S.K., Yan, J., 2021. COVID-19 Impact on Operation and Energy Consumption of Heating, Ventilation and Air-Conditioning (HVAC) Systems. Advances in Applied Energy, Volume 3, 100040. [4] M. Guo P. Xu T. Xiao R. He M. Dai S. Miller Review and comparison of HVAC operation guidelines in different countries during the COVID-19 pandemic Build. Environ. 187 2021 107368 Guo, M., Xu, P., Xiao, T., He, R., Dai, M., Miller, S., 2021. Review and comparison of HVAC operation guidelines in different countries during the COVID-19 pandemic Building and Environment, 187, Article 107368. [5] R. Mokhtari M.H. Jahangir The effect of occupant distribution on energy consumption and COVID-19 infection in buildings: a case study of university building Build. Environ. 190 2021 107561 Mokhtari, R. and Jahangir, M.H., 2021. The effect of occupant distribution on energy consumption and COVID-19 infection in buildings: A case study of university building. Building and Environment, vol. 190: 107561. [6] W. Wang J. Chen T. Hong Modeling occupancy distribution in large spaces with multi-feature classification algorithm Build. Environ. 137 2018 108 117 Wang, W., Chen, J., and Hong, T., 2018. Modeling occupancy distribution in large spaces with multi-feature classification algorithm. Building and Environment, vol. 137, pp. 108-117. [7] M. Annaqeeb R. Markovic V. Novakovic E. Azar Non-intrusive data monitoring and analysis of occupant energy-use behaviors in shared office spaces IEEE Access 8 2020 141246 141257 Annaqeeb, M., Markovic, R., Novakovic, V. and Azar, E., 2020. Non-Intrusive Data Monitoring and Analysis of Occupant Energy-Use Behaviors in Shared Office Spaces. IEEE Access, 8, pp.141246-141257. [8] B. Hobson H. Gunay A. Ashouri G. Newsham Clustering and motif identification for occupancy-centric control of an air handling unit Energy Build. 223 2020 110179 Hobson, B., Gunay, H., Ashouri, A. and Newsham, G., 2020. Clustering and motif identification for occupancy-centric control of an air handling unit. Energy and Buildings, 223, p.110179. [9] P.W. Tien S. Wei J.K. Calautit J. Darkwa C. Wood A vision-based deep learning approach for the detection and prediction of occupancy heat emissions for demand-driven control solutions Energy Build. 226 2020 110386 Tien P.W.; Wei S.; Calautit J.K.; Darkwa J.; Wood C, 2020. A vision-based deep learning approach for the detection and prediction of occupancy heat emissions for demand-driven control solutions. Energy Build., 226, 110386. [10] S. Wei P. Tien J. Calautit Y. Wu R. Boukhanouf Vision-based detection and prediction of equipment heat gains in commercial office buildings using a deep learning method Appl. Energy 277 2020 115506 Wei, S., Tien, P., Calautit, J., Wu, Y. and Boukhanouf, R., 2020. Vision-based detection and prediction of equipment heat gains in commercial office buildings using a deep learning method. Applied Energy, 277, p.115506. [11] V.L. Erickson A.E. Cerpa Occupancy based demand response HVAC control strategy Proc. 2Nd ACM Workshop Embed. Sens. Syst. Energy-Effic. Build 2010 ACM New York, NY, USA 7 12 10.1145/1878431.1878434 Erickson, V.L. and Cerpa. A.E., 2010. Occupancy based demand response HVAC control strategy. Proc. 2Nd ACM Workshop Embed. Sens. Syst. Energy-effic. Build, ACM, New York, NY, USA, pp. 7-12, 10.1145/1878431.1878434 [12] H. Burak Gunay W. O'Brien I. Beausoleil-Morrison Development of an occupancy learning algorithm for terminal heating and cooling units Build. Environ. 93 2 2015 71 85 10.1016/j.buildenv.2015.06.009 Burak Gunay, H., O'Brien, W., Beausoleil-Morrison, I., 2015. Development of an occupancy learning algorithm for terminal heating and cooling units. Building and Environment, vol. 93, p. 2, pp. 71-85. http://dx.doi.org/10.1016/j.buildenv.2015.06.009. [13] Y. Peng A. Rysanek Z. Nagy A. Schlüter Occupancy learning-based demand-driven cooling control for office spaces Build. Environ. 122 2017 145 160 Peng Y.; Rysanek A.; Nagy Z., Schluter A, 2017. Occupancy learning-based demand-driven cooling control for office spaces. Build. Environ., 122, 145-160. [14] T. Labeodan W. Zeiler G. Boxem Y. Zhao Occupancy measurement in commercial office buildings for demand-driven control applications\u2014a survey and detection system evaluation Energy Build. 93 2015 303 314 Labeodan, T., Zeiler, W., Boxem, G. and Zhao, Y., 2015. Occupancy measurement in commercial office buildings for demand-driven control applications-A survey and detection system evaluation. Energy and Buildings, 93, pp.303-314. [15] Z. Zhang X. Gao J. Biswas J.K. Wu Moving targets detection and localization in passive infrared sensor networks Proceedings of the 2007 10th International Conference on Information Fusion 2007 1 6 Quebec, QC, Canada, 9\u201312 July 2007 Zhang, Z.; Gao, X.; Biswas, J.; Wu, J.K., 2007. Moving targets detection and localization in passive infrared sensor networks. In Proceedings of the 2007 10th International Conference on Information Fusion, Quebec, QC, Canada, 9-12 July 2007; pp. 1-6. [16] J. Yang M. Santamouris S.E. Lee Review of occupancy sensing systems and occupancy modeling methodologies for the application in institutional buildings Energy Build. 121 2016 344 349 Yang, J.; Santamouris, M.; Lee, S.E., 2016. Review of occupancy sensing systems and occupancy modeling methodologies for the application in institutional buildings. Energy Build., 121, 344-349. [17] A.R. Kaushik B.G. Celler Characterization of passive infrared sensors for monitoring occupancy pattern Proceedings of the 2006 International Conference of the IEEE Engineering in Medicine and Biology Society 2006 5257 5260 New York, NY, USA, 30 August\u20133 September 2006 Kaushik, A.R.; Celler, B.G., 2006. Characterization of passive infrared sensors for monitoring occupancy pattern. In Proceedings of the 2006 International Conference of the IEEE Engineering in Medicine and Biology Society, New York, NY, USA, 30 August-3 September 2006; pp. 5257-5260. [18] N. Li G. Calis B. Becerik-Gerber Measuring and monitoring occupancy with an RFID based system for demand-driven HVAC operations Autom. ConStruct. 24 2012 89 99 Li, N., Calis, G., Becerik-Gerber, B., 2012. Measuring and monitoring occupancy with an RFID based system for demand-driven HVAC operations, Automation in Construction, Volume 24, Pages 89-99. [19] B. Balaji J. Xu A. Nwokafor R. Gupta Y. Agarwal Sentinel: occupancy based HVAC actuation using existing WiFi infrastructure within commercial buildings Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems 2013 1 14 Roma, Italy, 11\u201315 November 2013 Balaji, B.; Xu, J.; Nwokafor, A.; Gupta, R.; Agarwal, Y., 2013. Sentinel: Occupancy based HVAC actuation using existing WiFi infrastructure within commercial buildings. In Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems, Roma, Italy, 11-15 November 2013; pp. 1-14. [20] Z.D. Tekler R. Low B. Gunay R.K. Andersen L. Blessing A scalable Bluetooth Low Energy approach to identify occupancy patterns and profiles in office spaces Build. Environ. 171 2020 106681 Tekler, Z.D.; Low, R.; Gunay, B.; Andersen, R.K.; Blessing, L., 2020. A scalable Bluetooth Low Energy approach to identify occupancy patterns and profiles in office spaces. Build. Environ., 171, 106681. [21] Z. Deng Q. Chen Development and validation of a smart HVAC control system for multi-occupant offices by using occupants' physiological signals from wristband Energy Build. 214 2020 109872 Deng, Z. and Chen, Q., 2020. Development and validation of a smart HVAC control system for multi-occupant offices by using occupants\u2019 physiological signals from wristband. Energy Build., 214, 109872. [22] J. Yun S.S. Lee Human movement detection and identification using pyroelectric infrared sensors Sensors 14 2014 8057 8081 10.3390/s140508057 Yun, J. and Lee, S. S., 2014. Human Movement Detection and Identification Using Pyroelectric Infrared Sensors. Sensors, 14, 8057-8081. https://doi.org/10.3390/s140508057. [23] H. Choi C.Y. Um K. Kang H. Kim T. Kim Application of vision-based occupancy counting method using deep learning and performance analysis Energy Build. 252 2021 111389 2021 Choi, H., Um, C.Y., Kang, K., Kim, H., Kim, T., 2021. Application of vision-based occupancy counting method using deep learning and performance analysis, Energy and Buildings, Volume 252, 2021, 111389 [24] F. Jazizadeh W. Jung Personalized thermal comfort inference using RGB video images for distributed HVAC control Appl. Energy 220 2018 829 841 Jazizadeh, F. and Jung, W., 2018. Personalized thermal comfort inference using RGB video images for distributed HVAC control. Appl. Energy, 220, 829-841. [25] S. Kim S. Kang K.R. Ryu G. Song Real-time occupancy prediction in a large exhibition hall using deep learning approach Energy Build 199 2019 216 222 Kim, S., Kang, S., Ryu, K.R., Song, G., 2019. Real-time occupancy prediction in a large exhibition hall using deep learning approach Energy Build., 199, pp. 216-222 [26] J. Zou Q. Zhao W. Yang F. Wang Occupancy detection in the office by analyzing surveillance videos and its application to building energy conservation Energy Build. 152 2017 385 398 Zou, J., Zhao, Q., Yang, W., Wang, F., 2017. Occupancy detection in the office by analyzing surveillance videos and its application to building energy conservation. Energy Build., 152, pp. 385-398 [27] C. Feng A. Mehmani J. Zhang Deep learning-based real-time building occupancy detection using AMI data IEEE Trans. Smart Grid 11 5 2020 4490 4501 Feng, C., Mehmani, A. and Zhang, J., 2020. Deep Learning-Based Real-Time Building Occupancy Detection Using AMI Data. IEEE Transactions on Smart Grid, 11(5), pp.4490-4501. [28] S. Wei P.W. Tien Y. Wu J.K. Calautit The impact of deep learning\u2013based equipment usage detection on building energy demand estimation Build. Serv. Eng. Technol. 42 5 2021 545 557 Wei, S., Tien, P.W., Wu, Y. and Calautit, J.K., 2021. The impact of deep learning-based equipment usage detection on building energy demand estimation. Building Services Engineering Research and Technology, 42(5), pp.545-557. [29] P.W. Tien S. Wei J. Calautit J. Darkwa C. Wood Occupancy heat gain detection and prediction using deep learning approach for reducing building energy demand J. Sustain. Dev. Energy Water Environ. Syst. 2020 Tien P.W.; Wei S.; Calautit J.; Darkwa J.; Wood C, 2020. Occupancy heat gain detection and prediction using deep learning approach for reducing building energy demand. J. Sustain. Dev. Energy Water Environ. Syst. [30] D. Ramanan D.A. Forsyth Finding and Tracking People from the Bottom up, Proceedings/CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Madison, WI, USA 18\u201320 June 2003; Volumn 2, pp. II-467\u2013II-474 Ramanan D.; Forsyth D.A., 2003. Finding and tracking people from the bottom up, Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Madison, WI, USA, 18-20 June 2003; Volumn 2, pp. II-467-II-474. [31] R. Girshick J. Donahue T. Darrell J. Malik Rich feature hierarchies for accurate object detection and semantic segmentation Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2014 580 587 Girshick, R., Donahue, J., Darrell, T. and Malik, J., 2014. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 580-587). [32] K. He X. Zhang S. Ren J. Sun Spatial pyramid pooling in deep convolutional networks for visual recognition IEEE Trans. Pattern Anal. Mach. Intell. 37 9 2015 1904 1916 He, K., Zhang, X., Ren, S. and Sun, J., 2015. Spatial pyramid pooling in deep convolutional networks for visual recognition. IEEE transactions on pattern analysis and machine intelligence, 37(9), pp.1904-1916. [33] R. Girshick Fast r-cnn Proceedings of the IEEE International Conference on Computer Vision 2015 1440 1448 Girshick, R., 2015. Fast r-cnn. In Proceedings of the IEEE international conference on computer vision (pp. 1440-1448). [34] R.L. Galvez A.A. Bandala E.P. Dadios R.R.P. Vicerra J.M.Z. Maningo Object detection using convolutional neural networks Proceedings of the TENCON 2018\u20142018 IEEE Region 10 Conference 2018 2023 2027 Jeju Island, Korea, 28\u201331 October 2018 Galvez R.L.; Bandala A.A.; Dadios E.P.; Vicerra R.R.P.; Maningo J.M.Z., 2018. Object Detection Using Convolutional Neural Networks. In Proceedings of the TENCON 2018-2018 IEEE Region 10 Conference, Jeju Island, Korea, 28-31 October 2018; pp. 2023-2027. [35] CIBSE Chartered Institution of Building Services Engineer Environmental Design: CIBSE Guide, A 2015 CIBSE London, UK CIBSE Chartered Institution of Building Services Engineer, 2015. Environmental Design: CIBSE Guide, A; CIBSE: London, UK. [36] S. Shahzad J.K. Calautit K. Calautit B. Hughes A.I. Aquino Advanced personal comfort system (APCS) for the workplace: a review and case study Energy Build. 173 2018 689 709 Shahzad S.; Calautit J.K.; Calautit K.; Hughes B.; Aquino A.I., 2018. Advanced personal comfort system (APCS) for the workplace: A review and case study. Energy Build., 173, 689-709. [37] S. Shahzad K. Calautit S. Wei P.W. Tien J.K. Calautit B. Hughes Analysis of the thermal comfort and energy performance of a thermal chair for open plan office J. Sustain. Dev. Energy Water Environ. Syst. 8 2020 373 395 Shahzad S.; Calautit K.; Wei S.; Tien P.W.; Calautit J.K.; Hughes B., 2020. Analysis of the Thermal Comfort and Energy Performance of a Thermal Chair for Open Plan Office. J. Sustain. Dev. Energy Water Environ. Syst., 8, 373-395. [38] ASHRAE Standard 55\u2014Thermal Environmental Conditions for Human Occupancy 2017 ASHRAE Atlanta, USA ASHRAE, 2017. Standard 55-Thermal environmental conditions for human occupancy, ASHRAE: Atlanta, USA. [39] ASHRAE ANSI/ASHRAE/IES Standard 90.1-2019\u2014Energy Standard for Buildings except Low-Rise Residential Buildings 2019 ASHRAE Atlanta, USA ASHRAE, 2019. ANSI/ASHRAE/IES Standard 90.1-2019-Energy Standard for Buildings Except Low-Rise Residential Buildings, ASHRAE: Atlanta, USA.",
    "scopus-id": "85121269022",
    "coredata": {
        "eid": "1-s2.0-S2352710221016363",
        "dc:description": "Occupants' behaviour and the use of electrical equipment can significantly impact the building energy demand. Accurate occupancy and equipment usage information are key to improving the performance of demand-driven control, which can automatically adjust the heating, cooling and ventilation system operation. Employing static schedules is commonly used for the operation of heating, ventilation and air-conditioning systems, while it cannot satisfy the actual requirements due to the dynamic variations within the conditioned spaces. This study introduces a coupled real-time occupancy and equipment usage detection and recognition approach using deep learning and computer vision techniques for efficient building energy controls. The experimental results presented an overall equipment detection and occupancy activity detection accuracy of 78.39% and 93.60%. To investigate the influence of the implementation of the approach on building energy demand, a case study office building was selected to conduct experimental tests and modeled using a building energy simulation tool. Four scenarios with different occupancy and equipment profiles were defined and evaluated. The simulation results showed that heat gains, when employing static profiles were larger than the heat gains predicted when using the deep learning influenced profiles. Up to 53.95% lower heat gains were estimated when using both occupancy and equipment detection approaches than static schedules solely. The results highlighted the importance of monitoring real-time occupancy and electrical equipment usage and the advantages of using deep learning detection techniques to provide data for demand-driven controls, optimising building energy efficiency while maintaining a comfortable indoor environment.",
        "openArchiveArticle": "false",
        "prism:coverDate": "2022-04-15",
        "openaccessUserLicense": null,
        "prism:aggregationType": "Journal",
        "prism:url": "https://api.elsevier.com/content/article/pii/S2352710221016363",
        "dc:creator": [
            {
                "@_fa": "true",
                "$": "Wei, Shuangyu"
            },
            {
                "@_fa": "true",
                "$": "Tien, Paige Wenbin"
            },
            {
                "@_fa": "true",
                "$": "Wu, Yupeng"
            },
            {
                "@_fa": "true",
                "$": "Calautit, John Kaiser"
            }
        ],
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/article/pii/S2352710221016363"
            },
            {
                "@_fa": "true",
                "@rel": "scidir",
                "@href": "https://www.sciencedirect.com/science/article/pii/S2352710221016363"
            }
        ],
        "dc:format": "application/json",
        "openaccessType": null,
        "pii": "S2352-7102(21)01636-3",
        "prism:volume": "47",
        "articleNumber": "103778",
        "prism:publisher": "Elsevier Ltd.",
        "dc:title": "A coupled deep learning-based internal heat gains detection and prediction method for energy-efficient office building operation",
        "prism:copyright": "© 2021 Elsevier Ltd. All rights reserved.",
        "openaccess": "0",
        "prism:issn": "23527102",
        "dcterms:subject": [
            {
                "@_fa": "true",
                "$": "Artificial intelligence"
            },
            {
                "@_fa": "true",
                "$": "Buildings"
            },
            {
                "@_fa": "true",
                "$": "Deep learning"
            },
            {
                "@_fa": "true",
                "$": "Computer vision"
            },
            {
                "@_fa": "true",
                "$": "Energy"
            },
            {
                "@_fa": "true",
                "$": "HVAC"
            }
        ],
        "openaccessArticle": "false",
        "prism:publicationName": "Journal of Building Engineering",
        "openaccessSponsorType": null,
        "prism:pageRange": "103778",
        "pubType": "fla",
        "prism:coverDisplayDate": "15 April 2022",
        "prism:doi": "10.1016/j.jobe.2021.103778",
        "prism:startingPage": "103778",
        "dc:identifier": "doi:10.1016/j.jobe.2021.103778",
        "openaccessSponsorName": null
    },
    "objects": {"object": [
        {
            "@category": "standard",
            "@height": "295",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr8.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "109819",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "491",
            "@width": "669",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr9.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "150338",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "1019",
            "@width": "505",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr6.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "178579",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "205",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr7.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "98995",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "610",
            "@width": "624",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr4.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "254520",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "262",
            "@width": "624",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr5.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "120273",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "379",
            "@width": "669",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr2.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "146012",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "233",
            "@width": "669",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr3.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "130232",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "390",
            "@width": "624",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "164762",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "931",
            "@width": "544",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr10.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "284871",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "742",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr11.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "144874",
            "@ref": "gr11",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "636",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr12.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "126663",
            "@ref": "gr12",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "682",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr13.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "133425",
            "@ref": "gr13",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "701",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr14.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "154216",
            "@ref": "gr14",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "536",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr15.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "157564",
            "@ref": "gr15",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "390",
            "@width": "669",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr16.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "115850",
            "@ref": "gr16",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "514",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr17.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "128611",
            "@ref": "gr17",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "557",
            "@width": "624",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr18.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "160859",
            "@ref": "gr18",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "737",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr19.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "171934",
            "@ref": "gr19",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "277",
            "@width": "544",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr20.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "95713",
            "@ref": "gr20",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "681",
            "@width": "624",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr21.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "148886",
            "@ref": "gr21",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "641",
            "@width": "580",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr22.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "148594",
            "@ref": "gr22",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "70",
            "@width": "112",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx3.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "86612",
            "@ref": "fx3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "70",
            "@width": "112",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx4.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "81044",
            "@ref": "fx4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "69",
            "@width": "112",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "78204",
            "@ref": "fx1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "70",
            "@width": "112",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx2.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "84847",
            "@ref": "fx2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "200",
            "@width": "331",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-ga1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "108961",
            "@ref": "ga1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@height": "111",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr8.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "74534",
            "@ref": "gr8",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "161",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr9.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "84946",
            "@ref": "gr9",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "81",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr6.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "72613",
            "@ref": "gr6",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "77",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr7.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "71864",
            "@ref": "gr7",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "167",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr4.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "96686",
            "@ref": "gr4",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "92",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr5.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "76251",
            "@ref": "gr5",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "124",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr2.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "83382",
            "@ref": "gr2",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "76",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr3.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "76609",
            "@ref": "gr3",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "137",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "89917",
            "@ref": "gr1",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "95",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr10.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "87447",
            "@ref": "gr10",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "128",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr11.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "73695",
            "@ref": "gr11",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "149",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr12.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "73161",
            "@ref": "gr12",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "139",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr13.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "73106",
            "@ref": "gr13",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "135",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr14.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "76908",
            "@ref": "gr14",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "177",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr15.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "82069",
            "@ref": "gr15",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "128",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr16.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "77324",
            "@ref": "gr16",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "185",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr17.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "76341",
            "@ref": "gr17",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "184",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr18.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "79039",
            "@ref": "gr18",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "129",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr19.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "76004",
            "@ref": "gr19",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "112",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr20.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "71915",
            "@ref": "gr20",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "150",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr21.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "75598",
            "@ref": "gr21",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "148",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr22.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "77316",
            "@ref": "gr22",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "137",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx3.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "94127",
            "@ref": "fx3",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "137",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx4.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "92035",
            "@ref": "fx4",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "136",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "89790",
            "@ref": "fx1",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "137",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx2.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "92965",
            "@ref": "fx2",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "132",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-ga1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "89004",
            "@ref": "ga1",
            "@mimetype": "image/gif"
        },
        {
            "@category": "high",
            "@height": "1306",
            "@width": "2568",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr8_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "343151",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2174",
            "@width": "2962",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr9_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "660725",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "4516",
            "@width": "2238",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr6_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "1006675",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "906",
            "@width": "2568",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr7_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "291397",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2704",
            "@width": "2764",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr4_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "1740876",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1160",
            "@width": "2764",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr5_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "519345",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1676",
            "@width": "2962",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr2_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "692248",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1032",
            "@width": "2962",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr3_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "548264",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1726",
            "@width": "2764",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr1_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "826542",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "4124",
            "@width": "2410",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr10_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "1982995",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "3286",
            "@width": "2568",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr11_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "558158",
            "@ref": "gr11",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2816",
            "@width": "2568",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr12_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "461206",
            "@ref": "gr12",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "3020",
            "@width": "2567",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr13_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "503504",
            "@ref": "gr13",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "3104",
            "@width": "2568",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr14_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "604322",
            "@ref": "gr14",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2372",
            "@width": "2568",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr15_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "615747",
            "@ref": "gr15",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1726",
            "@width": "2962",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr16_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "464713",
            "@ref": "gr16",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2276",
            "@width": "2568",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr17_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "545091",
            "@ref": "gr17",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2466",
            "@width": "2764",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr18_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "796120",
            "@ref": "gr18",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "3264",
            "@width": "2568",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr19_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "994914",
            "@ref": "gr19",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1228",
            "@width": "2410",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr20_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "292605",
            "@ref": "gr20",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "3018",
            "@width": "2764",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr21_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "776077",
            "@ref": "gr21",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2836",
            "@width": "2568",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-gr22_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "730705",
            "@ref": "gr22",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "311",
            "@width": "497",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx3_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "130343",
            "@ref": "fx3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "311",
            "@width": "496",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx4_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "125548",
            "@ref": "fx4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "307",
            "@width": "496",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx1_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "118994",
            "@ref": "fx1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "311",
            "@width": "498",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-fx2_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "125348",
            "@ref": "fx2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "886",
            "@width": "1468",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-ga1_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "375891",
            "@ref": "ga1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-mmc2.mp4?httpAccept=%2A%2F%2A",
            "@multimediatype": "MPEG-4 movie",
            "@type": "VIDEO",
            "@size": "11846020",
            "@ref": "mmc2",
            "@mimetype": "video/mp4"
        },
        {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-mmc1.mp4?httpAccept=%2A%2F%2A",
            "@multimediatype": "MPEG-4 movie",
            "@type": "VIDEO",
            "@size": "17523048",
            "@ref": "mmc1",
            "@mimetype": "video/mp4"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-si2.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "57200",
            "@ref": "si2",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-si3.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "52646",
            "@ref": "si3",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-si4.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "91214",
            "@ref": "si4",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-si1.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "54188",
            "@ref": "si1",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2352710221016363-am.pdf?httpAccept=%2A%2F%2A",
            "@multimediatype": "Acrobat PDF file",
            "@type": "AAM-PDF",
            "@size": "3862022",
            "@ref": "am",
            "@mimetype": "application/pdf"
        }
    ]},
    "link": {
        "@rel": "abstract",
        "@href": "https://api.elsevier.com/content/abstract/scopus_id/85121269022"
    }
}}