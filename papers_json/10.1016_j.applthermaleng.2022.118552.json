{"full-text-retrieval-response": {
    "scopus-eid": "2-s2.0-85129699415",
    "originalText": "serial JL 271641 291210 291787 291811 291877 31 Applied Thermal Engineering APPLIEDTHERMALENGINEERING 2022-04-25 2022-04-25 2022-05-06 2022-05-06 2024-11-11T18:58:34 1-s2.0-S1359431122005038 S1359-4311(22)00503-8 S1359431122005038 10.1016/j.applthermaleng.2022.118552 S300 S300.2 FULL-TEXT 1-s2.0-S1359431122X00094 2024-11-11T19:35:07.800808Z 0 0 20220725 2022 2022-04-26T00:54:54.636353Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast highlightsabst nomenclature primabst pubtype ref 1359-4311 13594311 true 212 212 C Volume 212 60 118552 118552 118552 20220725 25 July 2022 2022-07-25 2022 Original Research Articles article fla © 2022 Elsevier Ltd. All rights reserved. DEEPREINFORCEMENTLEARNINGOPTIMALCONTROLSTRATEGYFORTEMPERATURESETPOINTREALTIMERESETINMULTIZONEBUILDINGHVACSYSTEM FANG X Nomenclature 1 Introduction 2 Methodology 2.1 Establishing EnergyPlus-Python co-simulation testbed 2.2 Reinforcement learning 2.2.1 Markov Decision process 2.2.2 Deep Q-learning 2.3 DQN based control model of building HVAC system 2.4 Proposed DQN framework for building HVAC system control 2.5 Overall flowchart of this study 3 Results and discussions 3.1 Simulation environment description 3.2 Simulation settings 3.3 DQN training hyper-parameter setting 3.4 Performance evaluation and results analysis of DQN control strategy 3.4.1 Energy consumption and temperature violations results of fixed temperature setpoint 3.4.2 Results analysis of the DQN control strategy 3.5 Discussion 4 Conclusions Acknowledgements References CUI 2016 251 263 C LI 2021 108057 G LI 2021 116223 W FANG 2021 119208 X BELLOS 2019 528 535 E FAN 2019 700 710 C WANG 2019 106204 J ZHANG 2021 111436 L FANG 2021 111435 X KATHIRGAMANATHAN 2021 110120 A OLDEWURTEL 2012 15 27 F AMASYALI 2018 1192 1205 K AFRAM 2014 507 519 A HALHOULMERABET 2021 110969 G BEGHI 2011 1125 1134 A FAROOQ 2015 257 267 A DELAC 2022 118442 B AFRAM 2014 343 355 A ATTARAN 2016 613 624 S SCHIRRER 2016 86 98 A HAZYUK 2012 388 394 I FIORENTINI 2017 465 479 M SIROKY 2011 3079 3087 J WEI 2017 1 6 T PROCEEDINGS54THANNUALDESIGNAUTOMATIONCONFERENCE DEEPREINFORCEMENTLEARNINGFORBUILDINGHVACCONTROL VALLADARES 2019 105 117 W BIEMANN 2021 117164 M QIU 2020 110055 S ZOU 2020 106535 Z CHEN 2018 195 205 Y BRANDI 2020 110225 S DU 2021 116117 Y VAZQUEZCANTELI 2019 243 257 J WEN 2020 118019 L WANG 2020 115036 Z JIA 2019 6158 6163 R YANG 2021 117335 T JIANG 2021 389 401 R NASURUDEENAHAMED 2020 92 101 N KOUPPAS 2021 103891 C LEE 2019 726 738 J SEONG 2019 5122 N LI 2021 116605 W RAFTERY 2018 356 370 P AHN 2020 61 74 K HUANG 2021 102654 S FANGX2022X118552 FANGX2022X118552XX 2024-05-06T00:00:00.000Z 2024-05-06T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ © 2022 Elsevier Ltd. All rights reserved. 2022-05-14T09:10:26.107Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/aggregated-refined 2020DK2003 2020GK2077 QL20210107 HNU Hunan University http://data.elsevier.com/vocabulary/SciValFunders/501100003824 http://sws.geonames.org/1814991 Hunan Provincial Innovation Foundation for Postgraduate Studies Hunan Provincial Innovation Foundation for Postgraduate http://data.elsevier.com/vocabulary/SciValFunders/501100010083 http://sws.geonames.org/1814991/ Hunan Provincial Commercialization and Industrialization Plan of Scientific and Technological Achievements Hunan Provincial Research and Development Plan of Key Areas The Hunan Provincial Innovation Foundation for Postgraduate Studies (Grant no. QL20210107), the Hunan Provincial Research and Development Plan of Key Areas (Grant no. 2020DK2003) and the Hunan Provincial Commercialization and Industrialization Plan of Scientific and Technological Achievements (Grant no. 2020GK2077) provided financial assistance for this study. Thanks to Dr. Jiangyu Wang and Dr. Zhiang Zhang for their help in the development of the co-simulation platform. https://doi.org/10.15223/policy-017 https://doi.org/10.15223/policy-037 https://doi.org/10.15223/policy-012 https://doi.org/10.15223/policy-029 https://doi.org/10.15223/policy-004 item S1359-4311(22)00503-8 S1359431122005038 1-s2.0-S1359431122005038 10.1016/j.applthermaleng.2022.118552 271641 2024-11-11T19:35:07.800808Z 2022-07-25 1-s2.0-S1359431122005038-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/MAIN/application/pdf/1889e148a37df9e875bf844c74e2f649/main.pdf main.pdf pdf true 6825879 MAIN 17 1-s2.0-S1359431122005038-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/PREVIEW/image/png/e01e4f5e2853ac284bc3d27302034c50/main_1.png main_1.png png 60119 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1359431122005038-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr1/DOWNSAMPLED/image/jpeg/418959928ba8a5cce9c6df5dfdf05ebc/gr1.jpg gr1 gr1.jpg jpg 42426 270 578 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr10/DOWNSAMPLED/image/jpeg/2f78ecaa564b196003d79807632a28d9/gr10.jpg gr10 gr10.jpg jpg 27426 326 533 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr11.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr11/DOWNSAMPLED/image/jpeg/be7bf279e3777ef6903ce69286356684/gr11.jpg gr11 gr11.jpg jpg 91412 441 533 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr12.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr12/DOWNSAMPLED/image/jpeg/a8be87170a70fa8e900b4a2de8cd8f0a/gr12.jpg gr12 gr12.jpg jpg 25963 279 373 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr13.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr13/DOWNSAMPLED/image/jpeg/49abdfc30637e17fa9fa37edcd8c21a9/gr13.jpg gr13 gr13.jpg jpg 68531 456 774 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr14.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr14/DOWNSAMPLED/image/jpeg/17e4a3f9ad943eadd0b0189b2d8f4fb2/gr14.jpg gr14 gr14.jpg jpg 79132 447 689 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr15.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr15/DOWNSAMPLED/image/jpeg/99bb592020638fc7f4c0e924db900a0c/gr15.jpg gr15 gr15.jpg jpg 64922 454 774 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr16.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr16/DOWNSAMPLED/image/jpeg/20ad1eaf4926d4252e8511988a2538a2/gr16.jpg gr16 gr16.jpg jpg 78811 447 689 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr17.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr17/DOWNSAMPLED/image/jpeg/e8326a558377d85a2c32f9073a017d9e/gr17.jpg gr17 gr17.jpg jpg 37416 317 534 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr18.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr18/DOWNSAMPLED/image/jpeg/7f704c8f5b746525d979675b944804c7/gr18.jpg gr18 gr18.jpg jpg 89756 555 774 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr19.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr19/DOWNSAMPLED/image/jpeg/a4926489609f5c05f3849a1bbcf9a1ed/gr19.jpg gr19 gr19.jpg jpg 52647 495 374 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr2/DOWNSAMPLED/image/jpeg/fd6bf2629d87833b744b9a5c647655c7/gr2.jpg gr2 gr2.jpg jpg 36222 322 533 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr20.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr20/DOWNSAMPLED/image/jpeg/4581cb91eb668b6f765e94953e49fa91/gr20.jpg gr20 gr20.jpg jpg 44554 494 373 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr21.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr21/DOWNSAMPLED/image/jpeg/baddf698ce88701450bd06e6f6d5b225/gr21.jpg gr21 gr21.jpg jpg 29554 289 373 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr22.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr22/DOWNSAMPLED/image/jpeg/f1440fddac4cf8e9b07478eef4a28655/gr22.jpg gr22 gr22.jpg jpg 28295 230 373 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr3/DOWNSAMPLED/image/jpeg/247e4ae43d5a0fe27514929fe3905e5e/gr3.jpg gr3 gr3.jpg jpg 21941 201 373 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr4/DOWNSAMPLED/image/jpeg/c162afad4d29eb38171763876af76a12/gr4.jpg gr4 gr4.jpg jpg 26974 286 533 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr5/DOWNSAMPLED/image/jpeg/fed759ff5c10a1cb5e4033ee0e5797c1/gr5.jpg gr5 gr5.jpg jpg 67526 350 622 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr6/DOWNSAMPLED/image/jpeg/5b3b41ee411ce72f9c9dc0c76eef06be/gr6.jpg gr6 gr6.jpg jpg 20694 282 373 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr7/DOWNSAMPLED/image/jpeg/227f3d7f1083ef4521375abec72d51f7/gr7.jpg gr7 gr7.jpg jpg 49869 265 578 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr8/DOWNSAMPLED/image/jpeg/ec76f6f1157cd23cbebcb07b1b80f194/gr8.jpg gr8 gr8.jpg jpg 12359 159 373 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr9/DOWNSAMPLED/image/jpeg/af3355e22d8854bd813a4d52a99c48bc/gr9.jpg gr9 gr9.jpg jpg 26901 267 311 IMAGE-DOWNSAMPLED 1-s2.0-S1359431122005038-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr1/THUMBNAIL/image/gif/db2587611b97fec7b7db5b8fba2abdda/gr1.sml gr1 gr1.sml sml 7823 102 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr10/DOWNSAMPLED/image/gif/bda7154f4f5226afe6591484be741dc9/gr10.sml gr10 gr10.sml sml 6001 134 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr11.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr11/THUMBNAIL/image/gif/5c163011fcb7b43c278868e382e86874/gr11.sml gr11 gr11.sml sml 21698 164 198 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr12.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr12/THUMBNAIL/image/gif/b00137a91f6e4139e87b05021105358a/gr12.sml gr12 gr12.sml sml 7178 164 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr13.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr13/THUMBNAIL/image/gif/1430f8f61291c3d8e3522e504e6cb7d1/gr13.sml gr13 gr13.sml sml 8363 129 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr14.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr14/THUMBNAIL/image/gif/349e8d76f76c07c369182c2e80c1c91e/gr14.sml gr14 gr14.sml sml 9502 142 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr15.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr15/THUMBNAIL/image/gif/71f50859ab9d8c48c1fce0bf10c5f8d0/gr15.sml gr15 gr15.sml sml 7173 129 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr16.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr16/THUMBNAIL/image/gif/bd4c8333f86a4500e7cbd04b31abaa0a/gr16.sml gr16 gr16.sml sml 9254 142 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr17.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr17/THUMBNAIL/image/gif/4929b40a0f968c95b97dcee386c90736/gr17.sml gr17 gr17.sml sml 5810 130 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr18.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr18/THUMBNAIL/image/gif/b70c44304b9472b3175aafb38bec0cbc/gr18.sml gr18 gr18.sml sml 10431 157 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr19.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr19/THUMBNAIL/image/gif/d08e982b8dbc4e46d499e5fdd1563ed1/gr19.sml gr19 gr19.sml sml 6604 164 124 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr2/THUMBNAIL/image/gif/21e63b5963bac81ec73489b528b41855/gr2.sml gr2 gr2.sml sml 7222 132 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr20.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr20/THUMBNAIL/image/gif/e97159435a9d07a5686b8fd2356a3829/gr20.sml gr20 gr20.sml sml 5506 163 123 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr21.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr21/THUMBNAIL/image/gif/d59983fb401e9ff0065ad048d670df95/gr21.sml gr21 gr21.sml sml 8225 164 212 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr22.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr22/THUMBNAIL/image/gif/067d0862501f9659b33f518f9549f93d/gr22.sml gr22 gr22.sml sml 10561 135 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr3/THUMBNAIL/image/gif/13af9f5c7c5c73b7ffe5ce70731ed04c/gr3.sml gr3 gr3.sml sml 8040 118 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr4/THUMBNAIL/image/gif/188d88db9600d703268805fbc5203eed/gr4.sml gr4 gr4.sml sml 5078 117 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr5/THUMBNAIL/image/gif/7f458bc0f98ec1bb430e871651b5736a/gr5.sml gr5 gr5.sml sml 9618 123 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr6/THUMBNAIL/image/gif/35368dcfb9c2d04f725a5ea8e65d4c18/gr6.sml gr6 gr6.sml sml 5802 164 216 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr7/THUMBNAIL/image/gif/0f4fae94b0d48c2d4ef47baee4ea468d/gr7.sml gr7 gr7.sml sml 9246 100 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr8/THUMBNAIL/image/gif/e212cc93eaba5fe29aa40762a001d2a1/gr8.sml gr8 gr8.sml sml 5036 94 219 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/gr9/MAIN/image/gif/aa661ac2eeb46c70a494b11b848a9eeb/gr9.sml gr9 gr9.sml sml 25739 164 191 IMAGE-THUMBNAIL 1-s2.0-S1359431122005038-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/d354468715a5eab049e10da59700c12f/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 236886 1197 2559 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr10_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/MAIN/image/jpeg/892b1148f558d14d6f9b06aeb51ac4ff/gr10_lrg.jpg gr10 gr10_lrg.jpg jpg 158951 1443 2362 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr11_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/THUMBNAIL/image/jpeg/88117d72090ed790a70d6f3e4e0c9749/gr11_lrg.jpg gr11 gr11_lrg.jpg jpg 597864 1955 2362 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr12_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/26ec3afbb215c5b2457438464d260bca/gr12_lrg.jpg gr12 gr12_lrg.jpg jpg 147170 1236 1654 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr13_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/c008069e8060dcd35694df466eb399a8/gr13_lrg.jpg gr13 gr13_lrg.jpg jpg 385371 2019 3428 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr14_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/0a66f19e3ca62d3db399af1773cce34a/gr14_lrg.jpg gr14 gr14_lrg.jpg jpg 473722 1980 3051 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr15_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/94b6a256c548cf738f8be35830fd0c86/gr15_lrg.jpg gr15 gr15_lrg.jpg jpg 344513 2011 3427 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr16_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/cb6c4a8251a37af91ada2fa2fbd9a508/gr16_lrg.jpg gr16 gr16_lrg.jpg jpg 471210 1980 3051 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr17_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/f10ba70fff56d8c6f0ae493db75dd6a1/gr17_lrg.jpg gr17 gr17_lrg.jpg jpg 243039 1402 2363 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr18_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/9386ae7acc5093fef7eafcafb30c24f9/gr18_lrg.jpg gr18 gr18_lrg.jpg jpg 490844 2455 3425 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr19_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/4491e2715747577a6dc5105e4c536444/gr19_lrg.jpg gr19 gr19_lrg.jpg jpg 311085 2191 1656 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/5962502b404ab7e37484c89a4d5272db/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 178169 1425 2362 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr20_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/d98b7ea3bc33d312797d573f46f9d7c1/gr20_lrg.jpg gr20 gr20_lrg.jpg jpg 291310 2191 1654 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr21_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/2d80be8621239e3d15af0abeb17ec536/gr21_lrg.jpg gr21 gr21_lrg.jpg jpg 161819 1281 1654 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr22_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/c21db077bfec6f10b71b9ebf8017b621/gr22_lrg.jpg gr22 gr22_lrg.jpg jpg 165697 1019 1654 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/09f77079499c08de169e61002154514c/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 107806 892 1653 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/4aa7b2370f78fa1b23f0bb486b438b9a/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 141811 1266 2362 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/79c052453db442ecf38b04fa09e0fcc6/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 301378 1240 2205 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/0a34c476675c92c802cd73ed7164fda0/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 103475 1252 1654 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/df60bc11f594f80bd17a33a89395a662/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 288174 1172 2559 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/16ded6a4c36e14556be78ec535c52df4/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 59598 707 1654 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-gr9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/HIGHRES/image/jpeg/8c933db079d82343cf5eed77d656af00/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 171069 1183 1378 IMAGE-HIGH-RES 1-s2.0-S1359431122005038-si1.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/fa14d48a252d94f0ce1fd5364f0053ae/si1.svg si1 si1.svg svg 11815 ALTIMG 1-s2.0-S1359431122005038-si10.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/a1c3c024a39dd41bbd37f5762fbfa6e4/si10.svg si10 si10.svg svg 3698 ALTIMG 1-s2.0-S1359431122005038-si11.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/6d2c90e76878bac418de2cec7fc34344/si11.svg si11 si11.svg svg 24844 ALTIMG 1-s2.0-S1359431122005038-si12.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/ac0c00f9bae2f01a1a4d3cf5d5ecc1e9/si12.svg si12 si12.svg svg 32468 ALTIMG 1-s2.0-S1359431122005038-si13.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/259394e13f4e148a5df05613f9cd7436/si13.svg si13 si13.svg svg 9365 ALTIMG 1-s2.0-S1359431122005038-si14.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/c6db250195e4a839d0ccb5e817a0882f/si14.svg si14 si14.svg svg 1920 ALTIMG 1-s2.0-S1359431122005038-si15.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/c792d54e75c94771423b60b6f16f68fd/si15.svg si15 si15.svg svg 1411 ALTIMG 1-s2.0-S1359431122005038-si16.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/2fe3271870496604cd1c17ecc32e8297/si16.svg si16 si16.svg svg 25264 ALTIMG 1-s2.0-S1359431122005038-si17.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/45b540e1fbfd15844bc72682c078d469/si17.svg si17 si17.svg svg 24869 ALTIMG 1-s2.0-S1359431122005038-si18.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/bf37cf7fb003eb487faece98cd8b6b37/si18.svg si18 si18.svg svg 8518 ALTIMG 1-s2.0-S1359431122005038-si2.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/0afdc4901ff6d9a6933f88a54ed1c509/si2.svg si2 si2.svg svg 33451 ALTIMG 1-s2.0-S1359431122005038-si3.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/e604885b592a14682f3aa810e67d2004/si3.svg si3 si3.svg svg 9508 ALTIMG 1-s2.0-S1359431122005038-si4.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/39be1b63c9cfecec9f90c2b001e78f02/si4.svg si4 si4.svg svg 21477 ALTIMG 1-s2.0-S1359431122005038-si5.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/4f4ea220adcd0a2d0b434407c36946b4/si5.svg si5 si5.svg svg 24422 ALTIMG 1-s2.0-S1359431122005038-si6.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/b6a00f41cd1bffad23d6f2cf69a3b3a2/si6.svg si6 si6.svg svg 8248 ALTIMG 1-s2.0-S1359431122005038-si7.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/7df715afed799a5b56ddbb773e99e4d6/si7.svg si7 si7.svg svg 11059 ALTIMG 1-s2.0-S1359431122005038-si8.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/ea41eaf9fe85877e4dff10af0514f14c/si8.svg si8 si8.svg svg 37903 ALTIMG 1-s2.0-S1359431122005038-si9.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1359431122005038/STRIPIN/image/svg+xml/4dbf063ab44f402937268ab7b7e289cd/si9.svg si9 si9.svg svg 21321 ALTIMG 1-s2.0-S1359431122005038-am.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:108F0RZ3PL8/MAIN/application/pdf/7e808082ba3f14151c3b082137430f99/am.pdf am am.pdf pdf false 2418027 AAM-PDF ATE 118552 118552 S1359-4311(22)00503-8 10.1016/j.applthermaleng.2022.118552 Elsevier Ltd Fig. 1 EnergyPlus-Python co-simulation testbed. Fig. 2 The detailed implementation diagram of EnergyPlus-Python co-simulation testbed. Fig. 3 Neural network for state-action Q value approximation. Fig. 4 DQN based control model of building HVAC system diagram. Fig. 5 Proposed DQN framework for building HVAC system control [24]. Fig. 6 Greedy factor ε(n) probability values. Fig. 7 Overall flowchart of this study. Fig. 8 Interaction and data exchange of EnergyPlus-Python co-simulation testbed. Fig. 9 3D SketchUp building model for this study [50,51]. Fig. 10 The model schematics of multi-zone building VAV system. Fig. 11 Outdoor air temperature and direct solar radiation during the training and testing process. Fig. 12 DQN control performance comparison with different hyper-parameter configurations during the training process. Fig. 13 Indoor air temperature distribution of each simulation time step for different supply air temperature setpoint. (a) 12 ℃; (b) 13 ℃; (c) 14 ℃; (d) 15 ℃; (e) 16 ℃; (f) 17 ℃; (g) 18 ℃. Fig. 14 Energy consumption and cumulative temperature violations results of different supply air temperature setpoint. (a) Chiller; (b) Fan; (c) Pump; (d) Cumulative energy consumption and temperature violations. Fig. 15 Indoor air temperature distribution of each simulation time step for different chilled supply water temperature setpoint. (a) 6 ℃; (b) 6.5 ℃; (c) 7 ℃; (d) 7.5 ℃; (e) 8 ℃; (f) 8.5 ℃; (g) 9 ℃. Fig. 16 Energy consumption and cumulative temperature violations results of different chilled supply water temperature setpoint. (a) Chiller; (b) Fan; (c) Pump; (d) Cumulative energy consumption and temperature violations. Fig. 17 Average energy consumption and temperature violations of each simulation step during the 30 training episodes. Fig. 18 DQN control actions in the different training episodes. (a) Episode #1; (b) Episode #5; (c) Episode #20; (d) Episode #30. Fig. 19 Cumulative count of DQN control actions at the first ten episodes during the training process. (a) Supply air temperature; (b) Chilled supply water temperature. Fig. 20 Cumulative count of DQN control actions at the first ten episodes during the testing process. (a) Chilled supply water temperature; (b) Supply air temperature. Fig. 21 Average energy consumption and temperature violations of each simulation step for fixed and DQN based temperature setpoint control during the testing test process. Fig. 22 Indoor air temperature of DQN control strategy during a week of the testing process. Table 1 Summary of RL for optimal control of building HVAC system. Reference Building and HVAC system Control action Optimization objective RL algorithm Architecture of simulation environment Wei et al. [24] Unknown, VAV Air flow rate Energy consumption and indoor air temperature Deep-Q-Learning BCVTB Zhang et al. [25] Office building, water-based radiantheating system Supply water temperature setpoint Energy consumption and thermal comfort A3C OpenAI Gym, BCVTB Valladares et al. [26] Laboratory and classroom, air conditioning unit Zone setpoint temperature, fan on or off Indoor thermal comfort, indoor air quality and energy consumption Deep-Q-Learning BCVTB Biemann et al. [27] Data center, VAV Zone setpoint temperature, zone fan mass flow rate Energy consumption and indoor temperature Actor-critic OpenAI Gym Qiu et al. [28] Metro station, central chilled water system Frequency of pump and cooling tower fan System COP Q-learning \u2013 Zou et al. [29] Office building, air handling units Damper position, heating valve status, fan speed, liquidsolenoid status Energy consumption and thermal comfort Deep deterministic policy gradient \u2013 Chen et al. [30] Residential building, unknown Window on/off, Air condition on/off Energy consumption and thermal comfort Q-learning \u2013 Brandi et al. [31] Office building, boiler heating system Supplytemperature setpoint Indoor temperature control and heating energy consumption Deep-Q-learning OpenAI Gym, BCVTB Du et al. [32] Residential building, unknown Zone setpoint temperature Energy consumption cost and thermal comfort Deep deterministic policy gradient \u2013 Table 2 System state variables of the DQN control model. No. Variable Symbols Units/Value 1 Occupancy Occ (0, 1) 2 Indoor air temperature Tin ℃ 3 Outdoor air temperature Tout ℃ 4 Direct solar radiation Sout W/m2 5 Supply air temperature setpoint Tsa_set ℃ 6 Chilled supply water temperature setpoint Tcsw_set ℃ Table 3 Hyper-parameter configurations used for DQN training. Hyper-parameter Candidate value range Selected value λ {1, 2, 3, 5} 1 β { 1, 2, 3, 5} 5 γ {0.9, 0.95, 0.99} 0.99 εmin {0.01, 0.02, 0.05} 0.01 εmax {0.9, 0.95, 1} 1 εdecay {0.0001, 0.0005, 0.001} 0.001 Learning rate {0.001, 0.002, 0.005, 0.01} 0.001 Batch size {128, 256, 512} 512 Memory size {1, 2, 3, 4, 5} × Batch size 1 Target network update (m days) {1 day, 3 days, 5 days, 7 days, 9 days} 7 days Neural network layers {3, 4, 5} 4 Number of neural units in hidden layer {64, 100, 128, 200, 256, 512} (512, 512) Activation function \u2013 Relu Optimizer \u2013 Adam Table 4 Control performance comparison of fixed and DQN based temperature setpoint control during the testing test process. Control scenario Case study Temperature setpoint Average energy consumption (kWh) Average temperature violations(℃) Energy consumption improve or not Temperature violation improve or not DQN control \u2013 \u2013 57.5896 6.5987 \u2013 \u2013 A: Supply air temperature setpoint control Case A-1 12 ℃ 58.6665 6.4611 ↑ ↓ Case A-2 13 ℃ 60.9438 9.3403 ↑ ↑ Case A-3 14 ℃ 61.9299 13.8583 ↑ ↑ Case A-4 15 ℃ 62.3375 19.0124 ↑ ↑ Case A-5 16 ℃ 62.4699 24.7967 ↑ ↑ Case A-6 17 ℃ 62.0771 31.1759 ↑ ↑ Case A-7 18 ℃ 61.4934 37.4990 ↑ ↑ B: Chilled supply water temperature control Case B-1 6 ℃ 59.7390 6.3737 ↑ ↓ Case B-2 6.5 ℃ 59.2836 6.3954 ↑ ↓ Case B-3 7 ℃ 58.6665 6.4611 ↑ ↓ Case B-4 7.5 ℃ 57.5865 6.5847 ↓ ↓ Case B-5 8 ℃ 57.3055 6.8610 ↓ ↑ Case B-6 8.5 ℃ 57.3221 7.5532 ↓ ↑ Case B-7 9 ℃ 58.2929 10.3348 ↑ ↑ Note: ↑ represents improve; ↓ represents no improve. Research Paper Deep reinforcement learning optimal control strategy for temperature setpoint real-time reset in multi-zone building HVAC system Xi Fang a Guangcai Gong a \u204e Guannan Li b Liang Chun a Pei Peng a Wenqiang Li a Xing Shi a Xiang Chen a a College of Civil Engineering, Hunan University, Changsha 410082, PR China College of Civil Engineering Hunan University Changsha 410082 PR China College of Civil Engineering, Hunan University, Changsha 410082, PR China b School of Urban Construction, Wuhan University of Science and Technology, Wuhan 430065 PR China School of Urban Construction Wuhan University of Science and Technology Wuhan 430065 PR China School of Urban Construction, Wuhan University of Science and Technology, Wuhan 430065 PR China \u204e Corresponding author. Determining a proper trade-off between energy consumption and indoor thermal comfort is important for HVAC system control. Deep Q-learning (DQN) based multi-objective optimal control strategy is designed for temperature setpoint real-time reset to balance the energy consumption and indoor air temperature. In addition, this study develops an EnergyPlus-Python co-simulation testbed to evaluate DQN control strategy in a simulation environment. A case study experiment is conducted to evaluate the performance of DQN control strategy for real-time reset of supply air temperature and chilled supply water temperature setpoint in a multi-zone building VAV system. The developed EnergyPlus-Python co-simulation testbed is used to train and test the DQN control strategy for performance analysis. The applied DQN strategy leans to update control actions (i.e. temperature setpoint) through interaction with the simulation environment. Simulation results show that the DQN control strategy is effective in finding a proper trade-off between the energy consumption of HVAC system and indoor air temperature. Meanwhile, the DQN control strategy can find a proper temperature setpoint reset sequence in smaller training episodes, and the control actions can be stable after ten DQN training episodes. This study provides a preliminary direction of deep reinforcement learning control strategy for temperature setpoint real-time reset in multi-zone building HVAC systems. Keywords Deep reinforcement learning Multi-zone building Optimal control Temperature setpoint reset EnergyPlus-Python co-simulation Nomenclature a Action s State Q(s, a) State-action value Tin Indoor air temperature Sout Direct solar radiation T Chilled supply water temperature setpoint N Number of batch size r Reward G Cumulated reward Occ Occupancy Tout Outdoor air temperature Tsa_set Supply air temperature setpoint E Energy consumption Abbreviation HVAC Heating, ventilation and air-conditioning DQN Deep Q-learning PID Proportional integral derivative RL Reinforcement learning DRL Deep reinforcement learning DOE Department of Energy FMI Functional Mock-Up Interface MDP Markov Decision Process VAV Variable air volume RBC Rule based control MPC Model predictive control A3C Asynchronous Advantage Actor Critic BCVTB Building Control Virtual Test Bed LBNL Lawrence Berkeley National Laboratory FMU Functional Mock-up Unit AHU Air handling unit Greek symbols α Learning rate λ Weight of energy related terms ε Probability γ Discount factor β Weight of temperature related terms θ Neural network parameters 1 Introduction In recent years, energy and environmental issues have attracted widespread attention worldwide. Both the total global energy consumption and per capita energy consumption are showing a continuous growth trend. The Chinese government announced that carbon dioxide emissions will peak in 2030 and be carbon neutral in 2060. Building sector accounts for a large proportion of global energy use. At the same time, Heating, ventilation and air-conditioning (HVAC) systems are widely deployed in buildings and account for about 50% of the building energy use [1\u20135]. In the practical operation of building HVAC systems, most system parameters are set based on the experiences or design values, which commonly mismatch with the actual demand and lead to energy waste. The wasted energy consumption of building HVAC system can be as high as 20% due to the non-optimal operation setting strategy [6\u20139]. Therefore, developing an optimal control strategy for building HVAC systems is an important research content, which is of great significance to the realization of building energy conservation and emission reduction. Currently, most control strategy of building HVAC systems are focused on rule based control (RBC), proportional integral derivative (PID) and model predictive control (MPC) and some of their variants [10\u201317]. The RBC based control are usually static and determined by the experience of engineers and facility managers. It is not continuous control and may lead to mismatch of load supply and demand, resulting in energy waste. PID controller is cumbersome to tune the controller parameters. The control performance will degrade when the system operating conditions vary from the tuning conditions [18,19]. MPC-based control methods predicts the future state of system model to obtain the optimal control sequence by minimizing the cost function over a prediction time horizon [13,18]. Thus, MPC based control methods have been widely studied for HVAC system control, which have some significance for the energy saving of building HVAC system. Schirrer et al. [20] proposed a nonlinear modular MPC control strategy, which can simultaneously optimize the heating and cooling modes of low-energy office buildings. Simulation results show that the proposed MPC control scheme has better control performance and robustness than the classical rule-based control scheme. Hazyuk et al. [21] employed an optimal thermal control method for intermittent heating buildings based on MPC, and a simulation model of residential building is used to verify the effectiveness of the proposed MPC control method. Fiorentini et al. [22] developed a hybrid MPC control strategy for thermal energy management of residential buildings to optimize the schedule of available thermal resources and thermal comfort requirements. Simulation and experimental results show that the hybrid MPC method can achieve the performance optimization of the complex multi-mode HVAC system. Iroky et al. [23] analyzed the energy saving potential of MPC and weather forecast in building heating system by conducting a two-month experiment of a real building. The results show that the energy saving potential of MPC combined with weather forecasting can be up to 15%∼28%. The model-based control methods (e.g. MPC) need to construct models to capture building thermal dynamics for HVAC system control. Some studies have shown that MPC based HVAC control methods can achieve superior performance. However, it is not easy to create a simplified but sufficiently accurate building model in practice, as the indoor environment is complex affected by many factors, such as building envelope, building layout, building internal heat, and outdoor environment. When the model is not sufficient to accurately describe the building thermal dynamics and there is a large deviation, the control performance may deviate from expectations. These problems limit the practical application of model-based control methods for HVAC system control to a certain extent. The drawbacks of model-based control methods promote the development of model-free control methods, which do not need to construct models of building HVAC systems and can be effectively used for building HVAC system control and optimization analysis. Due to these advantages and great potential, model-free control strategies can be regarded as an opportunity to develop advanced and intelligent solutions to existing problems in HVAC control field. Some model-free control methods such as reinforcement learning (RL) have been proposed for building HVAC system control. RL obtains feedback state information and reward through interaction with the environment to update control actions on the environment [27,33\u201337]. Due to its powerful ability to handle interactions with complex environments, RL has been widely used in the control field, such as self-driving vehicle control and robot control [38\u201340]. Building HVAC system is a typical nonlinear, time-varying and uncertain complex system closely related to indoor and outdoor environmental conditions. RL is a feasible solution for optimal control of building HVAC system, so it has been extensively studied in recent years. Table 1 summaries related RL studies for optimal control of building HVAC system. Wei et al. [24] presented a deep Q-learning approach for optimal control of air flow rate in a building variable air volume (VAV) system. The presented method can reduce energy cost while maintaining the indoor air temperature within desired range. Zhang et al [25] deployed an Asynchronous Advantage Actor Critic (A3C) based deep reinforcement learning (DRL) control method for radiant heating system and verified the control performance in the actual air conditioning system environment. The proposed control framework includes four parts, HVAC modelling, model calibration, DRL training and DRL deployment. Results show that DRL control method can effectively achieve the 16.6% energy saving compared to RBC control over three-month period. Valladares et al. [26] proposed a deep Q-learning control method for building indoor thermal comfort, indoor air quality and energy consumption control. The proposed control method has superior PMV than the current control system, while reducing CO2 level by 10% and energy consumption by about 4%∼5%. Biemann et al. [27] conducted experiments to evaluate the control performance of four actor-critic algorithms for VAV control in a simulated data center environment. All the applied algorithms can reduce energy consumption by 10% compared to the model-based controller simultaneously by keeping the zone temperature within desired range. Qiu et al. [28] proposed a Q-learning method for central chilled water system control and COP optimization. Three-month simulation experiments were conducted to evaluate the control performance, results show that the model-free Q-learning controller can save 7%∼11% of the system energy consumption compared with the basic controller and local feedback controller. Zou et al. [29] implemented a deep deterministic policy gradient framework for optimal control of air handling units. The proposed framework can achieve 27%∼30% energy saving compared to the actual system energy consumption. Chen et al. [30] introduced a Q-learning control strategy for optimal control decisions of HVAC and window system on and off, which can reduce 13%∼ 23% lower energy consumption compared to traditional rule-based heuristic control strategy. Brandi et al. [31] conducted experiments to evaluate the adaptability of the proposed deep-Q-learning control algorithm in different scenarios. Results show that the energy saving ranges between 5%∼12% with the adaptive DRL control agent compared with the ruled-based control logic. Du et al. [32] applied a deep deterministic policy gradient (DDPG) method for a multi-zone residential HVAC system control, the DDPG based control strategy can reduce energy consumption by 15% compared with the DQN strategy. Meanwhile, the temperature setpoint reset of building HVAC system is an important research. In most HVAC system such as VAV system, there are a large number of temperature setpoint in the control loops. Temperature setpoint is commonly set to a fixed value based on the engineering experiences or design values, regardless of dynamic changes of environment and practical operation system, leading to energy waste in many systems when the temperature setpoint is not proper. These temperature setpoint can be optimized during the operation to improve the system performance [29]. Many studies have been conducted by optimal control algorithms to determine the optimal temperature setpoint of building HVAC systems. Lee et al. [41] developed a ANN based control model to optimize the AHU discharge air temperature set-point. Results show that the proposed control algorithms can reduce cooling energy consumption by 2%∼18.2% compared to a conventional fixed setpoint control strategy. Seong et al. [42] employed genetic algorithms to calculate the optimal control setpoint for supply air temperature of the VAV system. The total energy consumption can reduce up to 5.72% using the proposed optimal control strategy compared to \u2018normal\u2019 settings. Li et al. [43] proposed a real-time optimal control strategy using a multi-agent based distributed optimization method for indoor thermal and air quality control. The proposed strategy effectively balances thermal comfort, indoor air quality and energy use while reducing programming challenges. Raftery et al. [44] implemented a cost-responsive supply air temperature reset strategy in a multi-zone VAV system. The results indicated the presented control strategy could find a lower cost SAT setpoint under a wide range of operating and design conditions. From the literature review, the optimal control of the temperature setpoint reset in building VAV system can achieve great energy saving. And most studies of DRL control strategy are focused on the single-zone temperature setpoint reset scenario, and few studies systematically discuss the applicability of DRL control strategy for temperature setpoint reset in the multi-zone building VAV system. The Multi-zone building VAV system involves more complex building thermal dynamic modelling, high-dimensional state and action space, and it is more challenging and potential for DRL strategy of multi-zone VAV system control. Therefore, it is necessary to study the DRL control performance of temperature setpoint reset in multi-zone building VAV systems. In addition, the DRL control strategy in existing research for building HVAC control is generally implemented via Building Control Virtual Test Bed (BCVTB) in a OpenAI Gym environment, which causes some limitations in software interaction. Motivated by the above concerns, this study develops an EnergyPlus-Python co-simulation testbed for performance evaluation of DRL control strategy in a multi-zone building VAV system. DQN based multi-objective optimal control strategy is designed for temperature setpoint real-time reset to balance the energy consumption and indoor air temperature. A case study is conducted to evaluate the performance of the DQN control strategy for setpoint real-time reset of supply air temperature and chilled supply water temperature. Results show that the DQN control strategy can effectively find a proper trade-off between the energy consumption of HVAC system and indoor air temperature. This study provides a preliminary direction of DRL control strategy for temperature setpoint real-time reset in multi-zone building HVAC systems. 2 Methodology 2.1 Establishing EnergyPlus-Python co-simulation testbed EnergyPlus is a widely used open source building and HVAC simulation software developed by the U.S. Department of Energy (DOE) and Lawrence Berkeley National Laboratory (LBNL) [45]. However, EnergyPlus software has some limitation in development and optimization of HVAC system control algorithm. It is difficult and inconvenient to directly apply some advanced control algorithms in the built-in software, such as DRL based control strategy. To tackle this problem, a co-simulation testbed combined the building HVAC module and HVAC system control module should be established to realize the dynamic data transmission and interaction between these two modules. Python is an open source programming software, which is convenient to implement the neural network based DRL control algorithm. The Functional Mock-Up Interface (FMI) [46] is a standard that can provides a unified model interface for model exchange and co-simulation between multiple modelling and simulation software. Therefore, this study develops an EnergyPlus-Python co-simulation testbed with FMI standard for advanced control of HVAC system. The diagram of EnergyPlus-Python co-simulation testbed is shown in Fig. 1 . The building HVAC module is modeled by the EnergyPlus, and DQN based HVAC system control module is implemented by Python. EnergyPlus based building HVAC module is wrapped into a Functional Mock-up Unit (FMU) model with FMI standard using ExternalInterface and ExternalInterface:FunctionalMockupUnitExport:To:Schedule Objects of ExternalInterface Group. The original file is modified with an DQN controller to replace the built-in controller. PyFMI [47] is a Python package based on FMI Library which supports loading and interacting with FMU models for model exchange and co-simulation. The detailed implementation diagram of EnergyPlus-Python co-simulation testbed is depicted in Fig. 2 . EnergyPlus simulation model is first wrapped into the FMU model based on EnergyPlusToFMU [48]. Then, DQN agent send the actions to the wrapped FMU model and FMU model perform one step model simulation. Finally, the simulation state and obtained reward is returned to the DQN agent. The whole process is repeated until the simulation ends. The developed EnergyPlus-Python co-simulation testbed makes it more easily to apply some advanced control algorithms such as DQN to the built-in EnergyPlus simulation environment. The developed co-simulation testbed doesn\u2019t need to rely on BCVTB for performance evaluation of DRL control strategy in a OpenAI Gym environment, which is easier to debug and has better scalability. 2.2 Reinforcement learning 2.2.1 Markov Decision process Reinforcement learning (RL) is an important research field of machine learning. The standard RL mainly consist of environment, agent, action (A={a1 , a2 , a3 , \u2026, at ,\u2026}), reward (R={r1 , r2 , r3 , \u2026, rt , \u2026}), and state (S={s1 , s2 , s3 , \u2026, st , \u2026}). RL agent learns to execute continuous and optimal actions from interaction with a dynamic environment (e.g. building and HVAC system subject to changes in weather and indoor conditions). The basic principle of RL control is that when the system executes an action and obtains positive rewards from the environment, then the system will reinforce the action, otherwise the system will weaken the action in the later process. The goal is to maximize the cumulative rewards (e.g. building energy consumption) while meeting the actual demand (e.g. indoor thermal comfort) [10]. At time t, an agent receives a state st and a reward rt from the environment, the agent will execute an action at from a set of candidate actions based on the state and reward. Accordingly, the environment changes to the next state st+1 and gives the immediate reward for the next state rt+1 based on the actions at received from the RL agent. This process is repeated until the end. Then, a series of states, rewards and actions {s1 , r1 , a1 , \u2026, st , rt , at , \u2026} are obtained from this process, which can be seen as a Markov Decision Process (MDP). The Markov property of this sequence is reflected in that the state st+1 at time t + 1 can be completely determined by the state st and action at at time t, and has nothing to do with the previous historical state st, st-1, st-2. 2.2.2 Deep Q-learning Q-learning algorithm was proposed to solve incomplete MDP problems, which is an optimal control technique based on value function iteration and dynamic learning mechanism. Q-learning agent observes the state and reward received from the environment and update its policy based on the cumulated reward (defined in Equation (1)) in the future. Q-learning algorithm uses the state-action value function Q(s, a) to evaluate the expected reward of state-action pairs (s, a) and then choose the optimal action based on the Q values. The state-action value Q(s, a) also called Q value is defined in Equation (2). (1) G t = ∑ i = 0 ∞ γ i r t + i + 1 (2) Q ( s t , a t ) = E ( G t | s t , a t ) = E ( ∑ i = 0 ∞ γ i r t + i + 1 | s t , a t ) = E ( r t + 1 + γ ∑ i = 1 ∞ γ i - 1 r t + i + 1 | s t , a t ) = r t + 1 + γ E ( ∑ i = 1 ∞ γ i - 1 r t + i + 1 | s t , a t ) = r t + 1 + γ E ( G t + 1 | s t , a t ) = r t + 1 + γ Q ( s t + 1 , a t + 1 ) Where rt+i+ 1 is the reward at time t + i + 1, γ is the discount factor between (0, 1). In the RL training process, the agent is aimed to maximize the expected cumulated reward. According to the Bellman optimal equation, the optimal Q value Q ∗ ( s t , a t ) which represents the maximum cumulative reward can be estimated by Equation (3). Then, the Q value of DQN can be updated by Equation (4). (3) Q ∗ ( s t , a t ) = r t + 1 + γ max Q ( s t + 1 , a t + 1 ) (4) Q ( s t , a t ) ← Q ( s t , a t ) + α [ r t + γ max Q ( s t + 1 , a t + 1 ) - Q ( s t , a t ) ] The traditional Q-learning algorithms employ tables to store the Q values, which works well for smaller discrete state and action space. However, building HVAC systems normally have large scale and continuous state and action spaces, which may lead to dimension disaster in the practical application. Due to the powerful ability of deep neural networks to describe the complex and non-linear relationships with state information, RL employs deep neural networks to estimate the Q value. Deep Q-learning is a DRL algorithm that combines deep learning and reinforcement learning, the superiority of deep Q-learning for building HVAC control has been proven in many studies. Deep Q-learning uses a deep Q network (DQN) Q ( s , a ; θ ) to approximate the Q values instead of traditional Q-learning to address the dimensional disaster issue. Q values are approximated by the deep neural network shown in Fig. 3 . Then the Q values of each action in the current state can be estimated, which can greatly improve the store and calculation efficiency when selecting actions with the greedy strategy. 2.3 DQN based control model of building HVAC system RL used for optimal control of building HVAC system is first to define the control problem as a MDP. DQN based control model of building HVAC system diagram is shown in Fig. 4 . The building HVAC system is regarded as the Environment , the DQN control strategy is regarded as the agent . The design of system state, control actions and reward function are as following. \u2022 System state: The control action is determined by the state observation of the environment and HVAC system. In the DQN based optimal control strategy, the more comprehensive the influencing factors of state coverage, the more complete information that the agent can receive, and the closer the learned strategy is to the optimal strategy. However, too many dimensions mean too much state action space to explore, which will lead to too much time to learn the optimal system control action. State space should be defined by proper variables to represent the complete information. In this study, indoor environment state (occupancy and indoor air temperature), outdoor environment state (outdoor air temperature and direct solar radiation), HVAC system operating state (supply air temperature setpoint and chilled supply water temperature setpoint), are considered to determine the system control action. The system state variables of the DQN based control model are listed in Table 2 , i.e. state space S = [Occ , Tin , Tout , Sout , Tsa_set , Tcsw_set ]. \u2022 Control actions: Actions can be seen as the HVAC system controllable variables, such as the air volume, water volume and temperature setpoints. In this study, the supply air temperature and chilled supply water temperature setpoint are regarded as the DQN agent control actions. The supply air temperature setpoint can be varied from 12 ℃ to 18 ℃ with 1 ℃ step size. The chilled supply water temperature setpoint can be varied from 6 ℃ to 9 ℃ with 0.5 ℃step size. Hence, action space A = Tsa_set = {12 ℃, 13 ℃, 14 ℃, 15 ℃, 16 ℃, 17 ℃, 18 ℃} or A = Tcsw_set = {6 ℃, 6.5 ℃, 7 ℃, 7.5 ℃, 8 ℃, 8.5 ℃, 9 ℃} when there exists only a single controllable action, or A = Tsa_set × Tcsw_set when chilled supply water and supply air setpoint temperature are both controllable actions. In this study, the number of possible control actions is 49 as both the two temperature setpoint are controllable. \u2022 Reward function: DQN control strategy aims optimize the temperature setpoint (i.e. control action at ) to find a proper trade-off between the energy consumption of HVAC system and indoor air temperature. It is a typical multi-objective optimal control problem to balance these two terms. Therefore, energy consumption of HVAC system and indoor air temperature related terms are regarded as the reward function. The energy related term is the energy consumption of HVAC system devices (chiller, fan and pump). The temperature related term is the violation values of indoor air temperature deviated from the cooling temperature setpoint. The temperature related term is to balance the indoor heat and maintain the indoor air temperature in an acceptable range. The heat exchange with the external air, the heat of the solar radiation, the cold energy introduced by the HVAC system, the internal heat gain from human bodies and appliances are included in the overall thermal process to maintain indoor air temperature balance. Max-min normalization in Equation (5) is used to scale the state S to the range (0,1), therefore the energy and temperature related reward term are both dimensionless. The reward function works like a penalty, more energy and temperature penalty would be added to the function when the executed action is not appropriate and state deviate from the acceptable ranges. For the typical multi-objective optimal control problem to balance energy consumption of HVAC system and indoor air temperature, the reward function can be expressed as following: (5) S ¯ = S - S min S max - S min (6) r t = f ( e n e r g y , t e m p e r a t u r e ) = - λ E t - β ∑ i = 1 15 | T i t - T set | Occ = 1 0 Occ = 0 (7) E t = E chiller ( t ) + E fan ( t ) + E pump ( t ) Where Et represents the total energy consumption of HVAC system devices (chiller, fan and pump) at time t, Echiller (t), Efan (t), Epump (t) represent the energy consumption of chiller, fan and pump at time t, respectively. T i t represents the indoor air temperature of zone i at time t. Tset represents the cooling temperature setpoint. λ, β represent weight of energy and temperature related terms, respectively. Occ represent the occupancy, the occupancy is set to 1 from Monday to Saturday between 8:00 a.m. and 20:00p.m. and the other time is set to 0. 2.4 Proposed DQN framework for building HVAC system control The proposed DQN framework for building HVAC system control is aimed to optimize the total energy consumption of HVAC system device (chiller, fan and pump) while simultaneously maintaining the indoor air temperature with desired range, and attempts to find a trade-off between these two terms. The proposed framework is shown in Fig. 5 , which contains two main loops, including a control loop (red line loop) and a learning loop (blue line loop). The control loop is the DQN agent to obtain the necessary state information and decide control actions in a certain state, which consists of the exploration and exploitation phase. At the beginning of the DQN training process, the probability of exploration phase is very high due to the lack of experience, so most actions are taken randomly. The DQN agent learns to control the HVAC system and takes actions by trial and error. During this training process, the agent learns the reward associated with different state-action pairs. The cumulative reward would converge to a relatively stable value after a number of training episodes, and the agent starts to exploit the learned policy. During this transition from exploration to exploitation phase, the greedy strategy is used, ε called \u2018greedy factor\u2019 represents the probability of performing random actions in the exploration phase, (1-ε) represents the probability of exploiting the knowledge to predict the best reward action in the exploitation phase. After the DQN training process is over, then the DQN agent would always take the action which can obtain the best reward in the practical deployment (i.e. testing process in this study). The ε(n) probability defined is calculated based on the number of actions taken by the DQN agent [26] in Equation (8). It should be noted that the DQN agent only performs the optimal action during the occupied period (i.e. Occ = 1), and performs a fixed action during the non-occupied period (i.e. Occ = 0). The nth action a(n) taken by the DQN agent during the occupied period can be expressed as Equation (9). (8) ε ( n ) = ε min + ( 1 - ε min ) · exp - ε decay · n (9) a ( n ) = arg max Q a ∈ A ( s , a ) ε > ε ( n ) R andom a ∈ A ε ⩽ ε ( n ) Where n represents the number of control actions taken by the DQN agent. εmin represents the minimum exploration probability. εdecay denotes the rate at which the factor will decay. Fig. 6 shows the ε(n) probability values with the number of control actions. The learning loop is to update DQN weight parameter from the past experience learned by the agent. This process occurs when the experience memory M has stored enough experience to update the DQN weight parameter. The DQN is trained with the mini-batch sample{s1 , r1 , a1 , \u2026, st , rt , at ,\u2026} stored in the experience memory M to minimize the error between the target Q values of Q ̂ ( s , a ; θ - ) network and output Q values of Q ( s , a ; θ ) network. It should be noted that weight parameter θ - of Q ̂ ( s , a ; θ - ) network is copied by the weight parameter θ of Q ( s , a ; θ ) network for every m days. Mean square error between the target Q-values in Equation (10) and the estimated Q-values of Q ( s , a ; θ ) network are used as the loss function, which can be calculated by Equation (11). Weight parameter in the DQN are updated by the gradient descent method by Equation (12). (10) Q ̂ ∗ ( s t , a i , t ; θ - ) = r t + 1 + γ max Q ̂ ( s t + 1 , a i , t + 1 ; θ - ) (11) L oss = 1 N ∑ i = 1 N Q ̂ ∗ ( s t , a i , t ; θ - ) - Q ( s t , a i , t ; θ ) 2 (12) θ = θ - α ∂ L oss ∂ θ Where N represents the number of batch size, α represent the learning rate. 2.5 Overall flowchart of this study The overall flowchart of this study is conducted as the following three steps shown in Fig. 7 . It mainly consists of three steps, EnergyPlus-Python co-simulation testbed development, DQN based HVAC control problem formulation and DQN based control performance evaluation. (1) EnergyPlus-Python co-simulation testbed development: the first step is to develop the EnergyPlus-Python co-simulation testbed for the performance evaluation of DQN control algorithm in a simulation environment. Details on the co-simulation testbed development are described in Section 2.1 . (2) DQN based HVAC control problem formulation: the second step of the overall process is aimed to design the main components of DQN based control model of building HVAC system. The detailed descriptions of the problem formulation are provided in Section 2.3 . (3) DQN based control performance evaluation: the final step is to evaluate the control performance of DQN control algorithm, and analyses the applicability of the DQN control strategy for the temperature setpoint reset. Detailed results of the control performance evaluation are provided in Section 3.4. 3 Results and discussions 3.1 Simulation environment description In this study, the building HVAC system is modeled by the EnergyPlus, and DQN based HVAC system control algorithm is implemented by Python. EnergyPlus based building HVAC system simulation environment is wrapped into a Functional Mock-up Unit (FMU) model with FMI. The whole simulation process was implemented in the developed EnergyPlus-Python co-simulation testbed. The developed co-simulation testbed can overcome the limitations of control logics inherent in EnergyPlus. The interaction and data exchange between the two software is dynamic as shown in Fig. 8 . DQN agent obtains the state st received from the EnergyPlus simulator and then in turn applies the control action at on it. This process is repeated until the simulation is over. In this work, the simulation time step of EnergyPlus simulator and control time step of DQN agent are both set to 10 min, i.e. Δt = 10 min. Therefore, a control action occurs at every simulation time step during the occupied period. U.S. DOE has developed some commercial reference models (EnergyPlus models) for building energy simulation analysis [49]. In this study, we use a multi-zone office reference building model (ASHRAE901_OfficeLarge_STD2019_Tampa.idf) to evaluate the performance of the applied DQN algorithms for HVAC system control, the 3D SketchUp building model for co-simulation testing environment is shown in Fig. 9 . The building model is simulated with the weather data obtained from the reference weather file (USA_FL_Tampa.Intl.AP.722110_TMY3.epw). The large office reference building is severed by VAV system for summer refrigeration, including chilled water system, cooling water system, air handling unit (AHU). The two red dot respectively represents the supply air temperature (i.e. Tsa_set) and the chilled supply water temperature (i.e. Tcsw_set) of this VAV system. The schematics of multi-zone building VAV system is shown in Fig. 10 . In this study, the basement zone is not considered, so fifteen zones of the large office building are included for results evaluation. The indoor cooling temperature is set to 24 ℃ and the HVAC system is set to operate from 7:00 am to 20:00 pm by modifying the original IDF file. The construction properties, detailed internal loads (lighting, equipment, and occupants) and HVAC system parameter settings of the reference building can be obtained in the IDF model and has been described in [50,51]. Fig. 11 shows the outdoor air temperature and direct solar radiation during the training process (i.e. July 1st to July 31st) and testing process (i.e. August 1st to August 31st). It can be seen that the outdoor air temperature and direct solar radiation have similar pattern in this two process. 3.2 Simulation settings In this study, all experiments are performed on an Intel Xeon(R) Gold 6226R processor with 128 GB RAM and a GeForce RTX 3090 GPU to evaluate the control performance of the DQN algorithm. EnergyPlus is used for building HVAC simulation modelling, the DQN control strategy is implemented in Python 3.6 and deep learning framework Pytorch 1.7. It should be noted that EnergyPlus is only used for control performance evaluation to replace the real building HVAC system environment. During the practical application and deployment phase, EnergyPlus based physical model is not needed for implementing a DQN control algorithms. In our experiment settings, building HVAC simulation model built in EnergyPlus interacts with the DQN control algorithms implemented in Python through FMI, the detailed implementation has been depicted in Section 2.1 . The whole simulation period is set from July 1st to August 31st. The training process includes one month, from July 1st to July 31st (i.e. 6 × 24 × 31 = 4464 simulation steps), and the testing process is from August 1st to August 31st (4464 simulation steps). The control period is set from Monday to Saturday between 8:00 a.m. and 20:00p.m., i.e. 73 × 27 = 1971 control steps each month. The DQN control strategy aims to obtain an optimal temperature setpoint real-time reset sequence, which can minimize the total energy consumption of HVAC system and simultaneously maintain the indoor air temperature within a desired range. A case study experiment is conducted to evaluate the performance of the DQN control strategy for setpoint real-time reset of supply air temperature and chilled supply water temperature in a building VAV system, the detailed performance evaluation and results analysis are described in Section 3.4. 3.3 DQN training hyper-parameter setting To obtain an optimal control performance in the deployment phase (i.e. testing process) by the DQN control strategy, the near optimal hyper-parameters of DQN model should be first determined during the training process. Fig. 12 shows the DQN control performance comparison of different hyper-parameter configurations during the training process, in a four-quadrant visualization figure considering the average energy consumption and temperature violations of each simulation step. The black dashed line denotes the minimum value of the average energy consumption and temperature violations with different hyper-parameter configurations. The intersection of the two dashed lines can be seen as the optimal performance point that the system can theoretically achieve by the optimal control strategy. The dots near the intersection can be regarded as the near optimal control region. Then the dot closed to the intersection is selected as the near optimal hyper-parameters of DQN model. It can be seen that different hyper-parameter configurations have great effect on the DQN control performance. The trained DQN control agent can find a proper trade-off between the energy consumption and indoor air temperature violations within the selected model hyper-parameter. The detailed hyper-parameter configurations used for DQN training are listed in Table 3 . 3.4 Performance evaluation and results analysis of DQN control strategy 3.4.1 Energy consumption and temperature violations results of fixed temperature setpoint This section presents the performance and results analysis of DQN control strategy for setpoint real-time reset of supply air temperature and chilled supply water temperature in a multi-zone building VAV system during the testing process (i.e. August 1st to August 31st). To explore the impact of supply air temperature and chilled supply water temperature setpoint on the energy consumption of HVAC system and indoor air temperature, the energy consumption of HVAC system and indoor air temperature distribution results are first analyzed under different temperature setpoint during the testing process. Fig. 13 shows the indoor air temperature distribution of each simulation time step when the supply air temperature setpoint is fixed at 12 ℃ to 18 ℃ (take three of the fifteen zones as an example). The blue vertical solid line denotes the indoor cooling temperature setpoint, the red dashed line represents an acceptable indoor air temperature range from 22 ℃ to 26 ℃. It can be clearly seen that the indoor air temperature increase as the supply air temperature setpoint increases. The indoor air temperature varies in an acceptable temperature range from 22 ℃ to 26 ℃ when the supply air temperature setpoint is not too high (12 ℃∼14 ℃). The indoor air temperature shows a significant increase and exceeds the acceptable range when the supply air temperature setpoint increases from 15 ℃ to 18 ℃. Therefore, the supply air temperature setpoint has a great influence on the indoor air temperature. Moreover, the cumulative temperature violations of testing process can be obtained by accumulating the deviations of indoor air temperature from the indoor cooling temperature setpoint at each simulation time step. Fig. 14 shows the energy consumption and cumulative temperature violations results when the supply air temperature setpoint is fixed at 12 ℃ to 18 ℃. It can be seen that the energy consumption of the fan shows a steady increase trend as the supply air temperature setpoint increase, while that of the chiller and pump shows an opposite trend. It is mainly because the supply air temperature setpoint increases, the supply air volume would also increase to provide the same cooling capacity, leading to an increase in the energy consumption of fan. Simultaneously, temperature difference between the chilled supply and return water decrease as the supply air temperature setpoint increases, the energy consumption of chiller would decrease. The cumulative energy consumption first increases and then decreases with the supply air temperature setpoint increasing from 12 ℃ to 18 ℃. The cumulative temperature violations show a monotonous increase trend as the supply air temperature setpoint increases. It is mainly because the supply air volume would increase as the supply air temperature setpoint increases. When the supply air volume is increased to the maximum design value, the indoor load demand cannot be met, which would lead to the increase of the indoor air temperature. The cumulative energy consumption and temperature violations both reach a minimum value of 115.6317 MWh and 1.2735 × 104 ℃ when the supply air temperature setpoint is 12 ℃. Fig. 15 shows the indoor air temperature distribution of each simulation time step when the chilled supply water temperature setpoint is fixed at 6 ℃ to 9 ℃ during the testing period. It can be seen that the indoor air temperature shows a slight increase trend as the chilled supply water temperature setpoint increases. The indoor air temperature varies in an acceptable temperature range from 22 ℃ to 26 ℃ when the chilled supply water temperature setpoint increases from 6 ℃ to 9 ℃. The chilled supply water temperature setpoint has little effect on the indoor air temperature. Similarly, the cumulative temperature violations can be obtained by accumulating the deviations of indoor air temperature from the indoor cooling temperature setpoint at each simulation time step. Fig. 16 shows the energy consumption and cumulative temperature violations results when the chilled supply water temperature setpoint is fixed at 6 ℃ to 9 ℃. It can be seen that the energy consumption of the pump shows a steady increasing trend as the chilled supply water temperature setpoint increases, while the chiller shows an opposite trend, and the fan has a smaller change. The main reason is that the chilled supply water temperature setpoint increases, the chilled supply water volume will also increase to provide the same cooling capacity, leading to the increase in the energy consumption of pump. Simultaneously, the energy consumption of chiller will decrease as the chilled supply water temperature setpoint increases. The cumulative energy consumption first decreases and then increases with the chilled supply water temperature setpoint varying from 6 ℃ to 9 ℃. The minimum value of cumulative energy consumption is 112.9492 MWh when the chilled supply water temperature setpoint is 8 ℃. The cumulative temperature violations show a slight increasing trend as the supply air temperature setpoint increases from 6 ℃ to 8.5 ℃, then there is a sudden increase when the temperature setpoint increase to 9 ℃. It is mainly because the supply air volume increase as the chilled supply water temperature setpoint increases to 9 ℃. When the supply air volume is increased to the maximum design value, the indoor load demand cannot be met, which would lead to sudden increase of the indoor air temperature. The minimum value of cumulative temperature violations is 1.2563 × 104 ℃ when the chilled supply water temperature setpoint is 6 ℃. According to the energy consumption and temperature violations result analysis under different fixed temperature setpoint, it can be seen that the total energy consumption and temperature violations both maintain in a low level (i.e. near optimal control region) when the supply air temperature setpoint is 12 ℃ and the chilled supply water temperature setpoint is between 7.5 ℃ and 8.5 ℃. 3.4.2 Results analysis of the DQN control strategy Fig. 17 shows the average energy consumption and temperature violations of each simulation step during the 30 training episodes. The average energy consumption and temperature violations show a decrease trend with the training episodes going on and then both gradually converge to a stable value. It can be clearly seen that the average energy consumption is reduced to about 54.5 kWh and the average temperature violation is reduced to 10 ℃ after 10 training episodes, and respectively maintain small fluctuations around these two values in the subsequent training episodes. That is the DQN control strategy can be stable after 10 training episode. The DQN control actions (i.e. temperature setpoint) in the different training episodes are shown in Fig. 18 . As it is shown in Fig. 18, in the beginning of DQN training process (e.g. (a) episode #1 and (b) episode #5), the supply air temperature and chilled supply water temperature setpoint both change randomly and then gradually maintain stable values at 12 ℃ and 7.5 ℃ after some training episodes (e.g. (c) episode #20 and (d) episode #30). This is mainly because the DQN agent randomly chooses the control actions in the exploration phase and gradually converge to stable control actions after gaining enough experience in the exploitation phase. The cumulative count of DQN control actions at the first ten episodes during the training process is shown in Fig. 19 . For the supply air temperature setpoint, the count of temperature setpoint shows a random result at the first seven training episodes, then the count of 12 ℃ temperature setpoint always accounts for the largest proportion after seven training episodes. For the chilled supply water temperature setpoint, the count of temperature setpoint also shows a similar random result at the first seven episodes, then the count of 7.5 ℃ temperature setpoint accounts for the largest proportion after seven training episodes. While the supply air temperature and chilled supply water temperature setpoint still both show some random changes as the agent maintains a small probability of exploration to explore new knowledge with the training process going on. After the DQN training process, the DQN control performance would be evaluated in the testing process. Fig. 20 shows the cumulative count of DQN control actions at the first ten episodes during the testing process. For the supply air temperature setpoint, the count of temperature setpoint only shows a difference at the third episode and 14 ℃ temperature setpoint accounts for the largest proportion at this episode, then the count of 12 ℃ temperature setpoint always accounts for 100% after some episodes. For the chilled supply water temperature setpoint, the count of temperature setpoint also shows changes at the first seven episodes, then the count of 7.5 ℃ temperature setpoint always accounts for 100% after seven episodes. The supply air temperature and chilled supply water temperature setpoint respectively stabilizes at 7.5 ℃ and 12 ℃ after some episodes. The temperature setpoint of testing process results are consistent with the training process results, which valid the robustness and great potential of DQN control strategy for temperature setpoint reset. Fig. 21 shows the control performance comparison of fixed and DQN based temperature setpoint control during the testing test process, in a four-quadrant visualization figure considering the average energy consumption and temperature violations of each simulation step. The black dashed line denotes the minimum value of the average energy consumption and temperature violations of the different fixed temperature setpoint. The intersection of the two dashed lines can be seen as the optimal performance point that the system can achieve. The dots near the intersection can be regarded as the near optimal temperature setpoint region. The black dot denotes the DQN control point, which is near the optimal performance point. It can be seen that the trained DQN control agent can find a proper trade-off between the energy consumption and indoor air temperature violations within the selected supply air temperature and chilled supply water temperature setpoint. The well trained DQN control strategy shows a powerful learning capability to maintain the lower energy consumption and temperature violations by choosing proper temperature setpoint. Fig. 22 show the indoor air temperature of DQN control strategy during a week. When the temperature setpoint is stable after the DQN training process is over, indoor air temperature during the occupied period (i.e. Occ = 1) keep a small fluctuation around the cooling temperature setpoint (i.e. the blue line) and remains in a desirable temperature range (i.e. the red line). Table 4 shows the control performance comparison of 14 fixed temperature setpoint control cases and DQN control strategy during the testing process. It can be seen that the average energy consumption of DQN control strategy is lower than that of the 11 fixed temperature setpoint control cases, accounting for 11/14 (i.e. Case A-1, Case A-2, Case A-3, Case A-4, Case A-5, Case A-6, Case A-7, Case B-1, Case B-2, Case B-3, Case B-7), while simultaneously maintain desirable temperature violations. These results reveal the effectiveness of the DQN control strategy for temperature setpoint reset. 3.5 Discussion Determining a proper trade-off between energy consumption and indoor thermal comfort is important for HVAC system control. Especially, temperature setpoint of HVAC systems has great impacts on the above two terms connected with the buildings. For example, an increase in the chilled supply water temperature setpoint will lead to the increase in the energy consumption of pump under cooling condition, as well as a decrease in the energy consumption of chiller. It is a typical \u2018small temperature and difference large flow, large flow and small temperature difference\u2019 trade-off problem in the practical operation of HVAC system. The temperature setpoint is generally set based on the experiences or design values regardless of the system and environmental dynamic changes, which may cause great energy waste in practical system operation. Therefore, there is great energy saving potential for the practical operation of HVAC system by optimizing the temperature setpoint. In this study, DQN based multi-objective optimal control strategy is designed for temperature setpoint real-time reset to balance the energy consumption and indoor air temperature, and attempts to find a trade-off between these two terms. The multi-objective optimal control problem in this study was relatively simple, not involving too many control actions, local controllable devices and other energy systems such as renewable energy sources. DRL generally suit to control scenario of higher degree freedom, which will show a more energy saving potential in complicated and comprehensive scenarios. This study is to valid the effectiveness of the applied DQN control strategy in the developed EnergyPlus-Python co-simulation testbed in the temperature setpoint reset scenario, and provide a DRL control algorithms evaluation platform for building HVAC control. 4 Conclusions In this study, DQN based multi-objective optimal control strategy is designed for temperature setpoint real-time reset to balance the energy consumption and indoor air temperature. A case study experiment is conducted to evaluate the performance of the proposed DQN strategy for real-time reset of supply air temperature and chilled supply water temperature setpoint in a multi-zone building VAV system. An EnergyPlus-Python co-simulation testbed is developed to train and test the DQN control strategy for performance analysis. Main conclusions can be obtained as follows: (1) An EnergyPlus-Python co-simulation testbed is developed based on the FMI standard, which allows to more easily evaluate the performance of advanced model-free based DRL control algorithms in a simulation environment. (2) DQN based multi-objective optimal control strategy can effectively find a proper temperature setpoint reset sequence to achieve the trade-off between energy consumption of the HVAC system and indoor air temperature in a multi-zone building VAV system. (3) Hyper-parameter configurations have great effect on the DQN control performance. The well trained DQN control strategy is more energy efficient than most fixed temperature setpoint cases, accounting for 11/14 of all fixed temperature setpoint comparison cases, while simultaneously maintain desirable temperature violations. (4) DQN control strategy can find a proper temperature setpoint reset sequence in a smaller training episodes, the control actions (i.e. temperature setpoint) can be stable after ten DQN training episodes, which shows the great robustness and potential of DRL control strategy for temperature setpoint reset. DRL for HVAC system optimal control is a very complex problem, some limitations should be improved and studied in the future work. For example, the control scenario in this study is relatively simple, not involving too many control actions. There should be greater energy saving potential when there exist more controllable variables of HVAC system for the DQN control agent, such as supply air volume of the ventilation system, water mass flow and lower level system control, e.g. frequency of pump, and damper position. The stronger the coupling relationship and nonlinear interaction relationship between control variables of HVAC system, the DRL can show more powerful ability. How to apply DRL to complex high-dimensional states action spaces remain a challenging problem. In addition, the repetitive training of DQL is really time consuming. the well-trained DQN control strategy can be transferred to the new building, HVAC system and climate zone to work out this problem. Moreover, the applied DQN control strategy for temperature setpoint reset are not deployed to a real building HVAC system. It is desirable to deploy the DQN control strategy to a real building and evaluate the practical control performance in the future work. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements The Hunan Provincial Innovation Foundation for Postgraduate Studies (Grant no. QL20210107), the Hunan Provincial Research and Development Plan of Key Areas (Grant no. 2020DK2003) and the Hunan Provincial Commercialization and Industrialization Plan of Scientific and Technological Achievements (Grant no. 2020GK2077) provided financial assistance for this study. Thanks to Dr. Jiangyu Wang and Dr. Zhiang Zhang for their help in the development of the co-simulation platform. References [1] C. Cui T. Wu M. Hu J.D. Weir X. Li Short-term building energy model recommendation system: A meta-learning approach Appl. Energy 172 2016 251 263 Cui C, Wu T, Hu M, Weir JD, Li X, Short-term building energy model recommendation system: A meta-learning approach, Applied Energy. 172 (2016) 251-63. [2] G. Li Q. Yao C. Fan C. Zhou G. Wu Z. Zhou X.i. Fang An explainable one-dimensional convolutional neural networks based fault diagnosis method for building heating, ventilation and air conditioning systems Build. Environ. 203 2021 108057 Li G, Yao Q, Fan C, Zhou C, Wu G, Zhou Z, et al, An explainable one-dimensional convolutional neural networks based fault diagnosis method for building heating, ventilation and air conditioning systems, Building and Environment. 203 (2021), 108057. [3] W. Li G. Gong H. Fan P. Peng L. Chun X.i. Fang A clustering-based approach for \u201ccross-scale\u201d load prediction on building level in HVAC systems Appl. Energy 282 2021 116223 Li W, Gong G, Fan H, Peng P, Chun L, Fang X, A clustering-based approach for \u201ccross-scale\u201d load prediction on building level in HVAC systems, Applied Energy. 282 (2021), 116223. [4] X.i. Fang G. Gong G. Li L. Chun W. Li P. Peng A hybrid deep transfer learning strategy for short term cross-building energy prediction Energy. 215 2021 119208 Fang X, Gong G, Li G, Chun L, Li W, Peng P, A hybrid deep transfer learning strategy for short term cross-building energy prediction, Energy. 215 (2021), 119208. [5] E. Bellos C. Tzivanidis Multi-objective optimization of a solar assisted heat pump-driven by hybrid PV Appl. Therm. Eng. 149 2019 528 535 Bellos E, Tzivanidis C, Multi-objective optimization of a solar assisted heat pump-driven by hybrid PV, Applied Thermal Engineering. 149 (2019) 528-35. [6] C. Fan J. Wang W. Gang S. Li Assessment of deep recurrent neural network-based strategies for short-term building energy predictions Appl. Energy 236 2019 700 710 Fan C, Wang J, Gang W, Li S, Assessment of deep recurrent neural network-based strategies for short-term building energy predictions, Applied Energy. 236 (2019) 700-10. [7] J. Wang S. Li H. Chen Y. Yuan Y. Huang Data-driven model predictive control for building climate control: Three case studies on different buildings Build. Environ. 160 2019 106204 Wang J, Li S, Chen H, Yuan Y, Huang Y, Data-driven model predictive control for building climate control: Three case studies on different buildings, Building and Environment. 160 (2019), 106204. [8] L. Zhang Data-driven building energy modeling with feature selection and active learning for data predictive control Energy Build. 252 2021 111436 Zhang L, Data-driven building energy modeling with feature selection and active learning for data predictive control, Energy and Buildings. 252 (2021), 111436. [9] X.i. Fang G. Gong G. Li L. Chun P. Peng W. Li A general multi-source ensemble transfer learning framework integrate of LSTM-DANN and similarity metric for building energy prediction Energy Build. 252 2021 111435 Fang X, Gong G, Li G, Chun L, Peng P, Li W, A general multi-source ensemble transfer learning framework integrate of LSTM-DANN and similarity metric for building energy prediction, Energy and Buildings. 252 (2021), 111435. [10] A. Kathirgamanathan M. De Rosa E. Mangina D.P. Finn Data-driven predictive control for unlocking building energy flexibility: A review Renew. Sustain. Energy Rev. 135 2021 110120 Kathirgamanathan A, De Rosa M, Mangina E, Finn DP, Data-driven predictive control for unlocking building energy flexibility: A review. Renewable and Sustainable Energy Reviews, 135 (2021), 110120. [11] F. Oldewurtel A. Parisio C.N. Jones D. Gyalistras M. Gwerder V. Stauch B. Lehmann M. Morari Use of model predictive control and weather forecasts for energy efficient building climate control Energy Build. 45 2012 15 27 Oldewurtel F, Parisio A, Jones CN, Gyalistras D, Gwerder M, Stauch V, et al, Use of model predictive control and weather forecasts for energy efficient building climate control, Energy and Buildings. 45 (2012) 15-27. [12] K. Amasyali N.M. El-Gohary A review of data-driven building energy consumption prediction studies Renew. Sustain. Energy Rev. 81 2018 1192 1205 Amasyali K, El-Gohary NM, A review of data-driven building energy consumption prediction studies, Renewable and Sustainable Energy Reviews. 81 (2018) 1192-205. [13] A. Afram F. Janabi-Sharifi Review of modeling methods for HVAC systems Appl. Therm. Eng. 67 1-2 2014 507 519 Afram A, Janabi-Sharifi F, Review of modeling methods for HVAC systems, Applied Thermal Engineering. 67 (2014) 507-19. [14] G. Halhoul Merabet M. Essaaidi M. Ben Haddou B. Qolomany J. Qadir M. Anan A. Al-Fuqaha M.R. Abid D. Benhaddou Intelligent building control systems for thermal comfort and energy-efficiency: A systematic review of artificial intelligence-assisted techniques Renew. Sustain. Energy Rev. 144 2021 110969 Halhoul Merabet G, Essaaidi M, Ben Haddou M, Qolomany B, Qadir J, Anan M, et al, Intelligent building control systems for thermal comfort and energy-efficiency: A systematic review of artificial intelligence-assisted techniques, Renewable and Sustainable Energy Reviews. 144 (2021), 110969. [15] A. Beghi L. Cecchinato Modelling and adaptive control of small capacity chillers for HVAC applications Appl. Therm. Eng. 31 6-7 2011 1125 1134 Beghi A, Cecchinato L, Modelling and adaptive control of small capacity chillers for HVAC applications, Applied Thermal Engineering. 31 (2011) 1125-34. [16] A.A. Farooq A. Afram N. Schulz F. Janabi-Sharifi Grey-box modeling of a low pressure electric boiler for domestic hot water system Appl. Therm. Eng. 84 2015 257 267 Farooq AA, Afram A, Schulz N, Janabi-Sharifi F, Grey-box modeling of a low pressure electric boiler for domestic hot water system, Applied Thermal Engineering. 84 (2015) 257-67. [17] B. Delač B. Pavković K. Lenić D. Mađerić Integrated optimization of the building envelope and the HVAC system in nZEB refurbishment Appl. Therm. Eng. 211 2022 118442 Delač B, Pavković B, Lenić K, Mađerić D, Integrated optimization of the building envelope and the HVAC system in nZEB refurbishment, Applied Thermal Engineering. 211 (2022), 118442. [18] A. Afram F. Janabi-Sharifi Theory and applications of HVAC control systems \u2013 A review of model predictive control (MPC) Build. Environ. 72 2014 343 355 Afram A, Janabi-Sharifi F, Theory and applications of HVAC control systems \u2013 A review of model predictive control (MPC), Building and Environment. 72 (2014) 343-55. [19] S.M. Attaran R. Yusof H. Selamat A novel optimization algorithm based on epsilon constraint-RBF neural network for tuning PID controller in decoupled HVAC system Appl. Therm. Eng. 99 2016 613 624 Attaran SM, Yusof R, Selamat H, A novel optimization algorithm based on epsilon constraint-RBF neural network for tuning PID controller in decoupled HVAC system, Applied Thermal Engineering. 99 (2016) 613-24. [20] A. Schirrer M. Brandstetter I. Leobner S. Hauer M. Kozek Nonlinear model predictive control for a heating and cooling system of a low-energy office building Energy Build. 125 2016 86 98 Schirrer A, Brandstetter M, Leobner I, Hauer S, Kozek M, Nonlinear model predictive control for a heating and cooling system of a low-energy office building, Energy and Buildings. 125 (2016) 86-98. [21] I. Hazyuk C. Ghiaus D. Penhouet Optimal temperature control of intermittently heated buildings using Model Predictive Control: Part II \u2013 Control algorithm Build. Environ. 51 2012 388 394 Hazyuk I, Ghiaus C, Penhouet D, Optimal temperature control of intermittently heated buildings using Model Predictive Control: Part II \u2013 Control algorithm, Building and Environment. 51 (2012) 388-94. [22] M. Fiorentini J. Wall Z. Ma J.H. Braslavsky P. Cooper Hybrid model predictive control of a residential HVAC system with on-site thermal energy generation and storage Appl. Energy 187 2017 465 479 Fiorentini M, Wall J, Ma Z, Braslavsky JH, Cooper P, Hybrid model predictive control of a residential HVAC system with on-site thermal energy generation and storage, Applied Energy. 187 (2017) 465-79. [23] J. Široký F. Oldewurtel J. Cigler S. Prívara Experimental analysis of model predictive control for an energy efficient building heating system Appl. Energy 88 9 2011 3079 3087 Široký J, Oldewurtel F, Cigler J, Prívara S, Experimental analysis of model predictive control for an energy efficient building heating system, Applied Energy. 88 (2011) 3079-87. [24] T. Wei Y. Wang Q. Zhu Deep reinforcement learning for building HVAC control Proceedings of the 54th annual design automation conference 2017 1 6 Wei T, Wang Y, Zhu Q, Deep reinforcement learning for building HVAC control, Proceedings of the 54th annual design automation conference. (2017) 1-6. [25] Zhang Z, Lam KP, Practical Implementation and Evaluation of Deep Reinforcement Learning Control for a Radiant Heating System, 2018 ACM BuildSys. (2018). [26] W. Valladares M. Galindo J. Gutiérrez W.-C. Wu K.-K. Liao J.-C. Liao K.-C. Lu C.-C. Wang Energy optimization associated with thermal comfort and indoor air control via a deep reinforcement learning algorithm Build. Environ. 155 2019 105 117 Valladares W, Galindo M, Gutiérrez J, Wu W-C, Liao K-K, Liao J-C, et al, Energy optimization associated with thermal comfort and indoor air control via a deep reinforcement learning algorithm, Building and Environment. 155 (2019) 105-17. [27] M. Biemann F. Scheller X. Liu L. Huang Experimental evaluation of model-free reinforcement learning algorithms for continuous HVAC control Appl. Energy 298 2021 117164 Biemann M, Scheller F, Liu X, Huang L, Experimental evaluation of model-free reinforcement learning algorithms for continuous HVAC control, Applied Energy. 298 (2021), 117164. [28] S. Qiu Z. Li Z. Li J. Li S. Long X. Li Model-free control method based on reinforcement learning for building cooling water systems: Validation by measured data-based simulation Energy Build. 218 2020 110055 Qiu S, Li Z, Li Z, Li J, Long S, Li X, Model-free control method based on reinforcement learning for building cooling water systems: Validation by measured data-based simulation, Energy and Buildings. 218 (2020), 110055. [29] Z. Zou X. Yu S. Ergan Towards optimal control of air handling units using deep reinforcement learning and recurrent neural network Build. Environ. 168 2020 106535 Zou Z, Yu X, Ergan S, Towards optimal control of air handling units using deep reinforcement learning and recurrent neural network, Building and Environment. 168 (2020), 106535. [30] Y. Chen L.K. Norford H.W. Samuelson A. Malkawi Optimal control of HVAC and window systems for natural ventilation through reinforcement learning Energy Build. 169 2018 195 205 Chen Y, Norford LK, Samuelson HW, Malkawi A, Optimal control of HVAC and window systems for natural ventilation through reinforcement learning, Energy and Buildings. 169 (2018) 195-205. [31] S. Brandi M.S. Piscitelli M. Martellacci A. Capozzoli Deep reinforcement learning to optimise indoor temperature control and heating energy consumption in buildings Energy Build. 224 2020 110225 Brandi S, Piscitelli MS, Martellacci M, Capozzoli A, Deep reinforcement learning to optimise indoor temperature control and heating energy consumption in buildings, Energy and Buildings. 224 (2020), 110225. [32] Y. Du H. Zandi O. Kotevska K. Kurte J. Munk K. Amasyali E. Mckee F. Li Intelligent multi-zone residential HVAC control strategy based on deep reinforcement learning Appl. Energy 281 2021 116117 Du Y, Zandi H, Kotevska O, Kurte K, Munk J, Amasyali K, et al, Intelligent multi-zone residential HVAC control strategy based on deep reinforcement learning, Applied Energy. 281 (2021), 116117. [33] J.R. Vázquez-Canteli S. Ulyanin J. Kämpf Z. Nagy Fusing TensorFlow with building energy simulation for intelligent energy management in smart cities Sustainable Cities and Society. 45 2019 243 257 Vázquez-Canteli JR, Ulyanin S, Kämpf J, Nagy Z, Fusing TensorFlow with building energy simulation for intelligent energy management in smart cities, Sustainable Cities and Society. 45 (2019) 243-57. [34] L. Wen K. Zhou J. Li S. Wang Modified deep learning and reinforcement learning for an incentive-based demand response model Energy. 205 2020 118019 Wen L, Zhou K, Li J, Wang S, Modified deep learning and reinforcement learning for an incentive-based demand response model, Energy. 205 (2020), 118019. [35] Z. Wang T. Hong Reinforcement learning for building controls: The opportunities and challenges Appl. Energy 269 2020 115036 Wang Z, Hong T, Reinforcement learning for building controls: The opportunities and challenges, Applied Energy. 269 (2020), 115036. [36] R. Jia M. Jin K. Sun T. Hong C. Spanos Advanced Building Control via Deep Reinforcement Learning Energy Procedia 158 2019 6158 6163 Jia R, Jin M, Sun K, Hong T, Spanos C, Advanced Building Control via Deep Reinforcement Learning, Energy Procedia. 158 (2019) 6158-63. [37] T. Yang L. Zhao W. Li J. Wu A.Y. Zomaya Towards healthy and cost-effective indoor environment management in smart homes: A deep reinforcement learning approach Appl. Energy 300 2021 117335 Yang T, Zhao L, Li W, Wu J, Zomaya AY, Towards healthy and cost-effective indoor environment management in smart homes: A deep reinforcement learning approach, Applied Energy. 300 (2021), 117335. [38] R. Jiang Z. Wang B. He Y. Zhou G. Li Z. Zhu A data-efficient goal-directed deep reinforcement learning method for robot visuomotor skill Neurocomputing. 462 2021 389 401 Jiang R, Wang Z, He B, Zhou Y, Li G, Zhu Z, A data-efficient goal-directed deep reinforcement learning method for robot visuomotor skill, Neurocomputing. 462 (2021) 389-401. [39] N. Nasurudeen Ahamed P. Karthikeyan A Reinforcement Learning Integrated in Heuristic search method for self-driving vehicle using blockchain in supply chain management, International Journal of Intelligent Networks. 1 2020 92 101 Nasurudeen Ahamed N, Karthikeyan P, A Reinforcement Learning Integrated in Heuristic search method for self-driving vehicle using blockchain in supply chain management, International Journal of Intelligent Networks. 1 (2020) 92-101. [40] C. Kouppas M. Saada Q. Meng M. King D. Majoe Hybrid autonomous controller for bipedal robot balance with deep reinforcement learning and pattern generators Rob. Auton. Syst. 146 2021 103891 Kouppas C, Saada M, Meng Q, King M, Majoe D, Hybrid autonomous controller for bipedal robot balance with deep reinforcement learning and pattern generators, Robotics and Autonomous Systems. 146 (2021), 103891. [41] J.M. Lee S.H. Hong B.M. Seo K.H. Lee Application of artificial neural networks for optimized AHU discharge air temperature set-point and minimized cooling energy in VAV system Appl. Therm. Eng. 153 2019 726 738 Lee JM, Hong SH, Seo BM, Lee KH, Application of artificial neural networks for optimized AHU discharge air temperature set-point and minimized cooling energy in VAV system, Applied Thermal Engineering. 153 (2019) 726-38. [42] N.-C. Seong J.-H. Kim W. Choi Optimal Control Strategy for Variable Air Volume Air-Conditioning Systems Using Genetic Algorithms Sustainability. 11 2019 5122 Seong N-C, Kim J-H, Choi W, Optimal Control Strategy for Variable Air Volume Air-Conditioning Systems Using Genetic Algorithms, Sustainability. 11 (2019), 5122. [43] W. Li S. Wang C. Koo A real-time optimal control strategy for multi-zone VAV air-conditioning systems adopting a multi-agent based distributed optimization method Appl. Energy 287 2021 116605 Li W, Wang S, Koo C, A real-time optimal control strategy for multi-zone VAV air-conditioning systems adopting a multi-agent based distributed optimization method, Applied Energy. 287 (2021), 116605. [44] P. Raftery S. Li B. Jin M. Ting G. Paliaga H. Cheng Evaluation of a cost-responsive supply air temperature reset strategy in an office building Energy Build. 158 2018 356 370 Raftery P, Li S, Jin B, Ting M, Paliaga G, Cheng H, Evaluation of a cost-responsive supply air temperature reset strategy in an office building, Energy and Buildings. 158 (2018) 356-70. [45] EnergyPlus. https://energyplus.net. [46] FMI. https://fmi-standard.org. [47] PyFMI. https://jmodelica.org/pyfmi/index.html. [48] EnergyPlusToFMU. https://simulationresearch.lbl.gov/fmu/EnergyPlus/export/index.html. [49] Deru M, Field K, Studer D, Benne K, Griffith B, Torcellini P. U.S, Department of Energy commercial reference building models of the national building stock. (2011). [50] K.U. Ahn C.S. Park Application of deep Q-networks for model-free optimal control balancing between different HVAC systems, Science and Technology for the Built Environment. 26 1 2020 61 74 Ahn KU, Park CS, Application of deep Q-networks for model-free optimal control balancing between different HVAC systems, Science and Technology for the Built Environment. 26 (2020) 61-74. [51] S. Huang W. Zuo D. Vrabie R. Xu Modelica-based system modeling for studying control-related faults in chiller plants and boiler plants serving large office buildings, Journal of Building Engineering. 44 2021 102654 Huang S, Zuo W, Vrabie D, Xu R, Modelica-based system modeling for studying control-related faults in chiller plants and boiler plants serving large office buildings, Journal of Building Engineering. 44 (2021),102654.",
    "scopus-id": "85129699415",
    "coredata": {
        "eid": "1-s2.0-S1359431122005038",
        "dc:description": "Determining a proper trade-off between energy consumption and indoor thermal comfort is important for HVAC system control. Deep Q-learning (DQN) based multi-objective optimal control strategy is designed for temperature setpoint real-time reset to balance the energy consumption and indoor air temperature. In addition, this study develops an EnergyPlus-Python co-simulation testbed to evaluate DQN control strategy in a simulation environment. A case study experiment is conducted to evaluate the performance of DQN control strategy for real-time reset of supply air temperature and chilled supply water temperature setpoint in a multi-zone building VAV system. The developed EnergyPlus-Python co-simulation testbed is used to train and test the DQN control strategy for performance analysis. The applied DQN strategy leans to update control actions (i.e. temperature setpoint) through interaction with the simulation environment. Simulation results show that the DQN control strategy is effective in finding a proper trade-off between the energy consumption of HVAC system and indoor air temperature. Meanwhile, the DQN control strategy can find a proper temperature setpoint reset sequence in smaller training episodes, and the control actions can be stable after ten DQN training episodes. This study provides a preliminary direction of deep reinforcement learning control strategy for temperature setpoint real-time reset in multi-zone building HVAC systems.",
        "openArchiveArticle": "false",
        "prism:coverDate": "2022-07-25",
        "openaccessUserLicense": null,
        "prism:aggregationType": "Journal",
        "prism:url": "https://api.elsevier.com/content/article/pii/S1359431122005038",
        "dc:creator": [
            {
                "@_fa": "true",
                "$": "Fang, Xi"
            },
            {
                "@_fa": "true",
                "$": "Gong, Guangcai"
            },
            {
                "@_fa": "true",
                "$": "Li, Guannan"
            },
            {
                "@_fa": "true",
                "$": "Chun, Liang"
            },
            {
                "@_fa": "true",
                "$": "Peng, Pei"
            },
            {
                "@_fa": "true",
                "$": "Li, Wenqiang"
            },
            {
                "@_fa": "true",
                "$": "Shi, Xing"
            },
            {
                "@_fa": "true",
                "$": "Chen, Xiang"
            }
        ],
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/article/pii/S1359431122005038"
            },
            {
                "@_fa": "true",
                "@rel": "scidir",
                "@href": "https://www.sciencedirect.com/science/article/pii/S1359431122005038"
            }
        ],
        "dc:format": "application/json",
        "openaccessType": null,
        "pii": "S1359-4311(22)00503-8",
        "prism:volume": "212",
        "articleNumber": "118552",
        "prism:publisher": "Elsevier Ltd.",
        "dc:title": "Deep reinforcement learning optimal control strategy for temperature setpoint real-time reset in multi-zone building HVAC system",
        "prism:copyright": "© 2022 Elsevier Ltd. All rights reserved.",
        "openaccess": "0",
        "prism:issn": "13594311",
        "dcterms:subject": [
            {
                "@_fa": "true",
                "$": "Deep reinforcement learning"
            },
            {
                "@_fa": "true",
                "$": "Multi-zone building"
            },
            {
                "@_fa": "true",
                "$": "Optimal control"
            },
            {
                "@_fa": "true",
                "$": "Temperature setpoint reset"
            },
            {
                "@_fa": "true",
                "$": "EnergyPlus-Python co-simulation"
            }
        ],
        "openaccessArticle": "false",
        "prism:publicationName": "Applied Thermal Engineering",
        "openaccessSponsorType": null,
        "prism:pageRange": "118552",
        "pubType": "fla",
        "prism:coverDisplayDate": "25 July 2022",
        "prism:doi": "10.1016/j.applthermaleng.2022.118552",
        "prism:startingPage": "118552",
        "dc:identifier": "doi:10.1016/j.applthermaleng.2022.118552",
        "openaccessSponsorName": null
    },
    "objects": {"object": [
        {
            "@category": "standard",
            "@height": "270",
            "@width": "578",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "42426",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "326",
            "@width": "533",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr10.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "27426",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "441",
            "@width": "533",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr11.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "91412",
            "@ref": "gr11",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "279",
            "@width": "373",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr12.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "25963",
            "@ref": "gr12",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "456",
            "@width": "774",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr13.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "68531",
            "@ref": "gr13",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "447",
            "@width": "689",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr14.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "79132",
            "@ref": "gr14",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "454",
            "@width": "774",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr15.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "64922",
            "@ref": "gr15",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "447",
            "@width": "689",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr16.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "78811",
            "@ref": "gr16",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "317",
            "@width": "534",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr17.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "37416",
            "@ref": "gr17",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "555",
            "@width": "774",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr18.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "89756",
            "@ref": "gr18",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "495",
            "@width": "374",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr19.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "52647",
            "@ref": "gr19",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "322",
            "@width": "533",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr2.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "36222",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "494",
            "@width": "373",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr20.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "44554",
            "@ref": "gr20",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "289",
            "@width": "373",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr21.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "29554",
            "@ref": "gr21",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "230",
            "@width": "373",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr22.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "28295",
            "@ref": "gr22",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "201",
            "@width": "373",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr3.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "21941",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "286",
            "@width": "533",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr4.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "26974",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "350",
            "@width": "622",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr5.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "67526",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "282",
            "@width": "373",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr6.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "20694",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "265",
            "@width": "578",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr7.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "49869",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "159",
            "@width": "373",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr8.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "12359",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "267",
            "@width": "311",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr9.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "26901",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@height": "102",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "7823",
            "@ref": "gr1",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "134",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr10.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "6001",
            "@ref": "gr10",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "198",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr11.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "21698",
            "@ref": "gr11",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr12.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "7178",
            "@ref": "gr12",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "129",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr13.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "8363",
            "@ref": "gr13",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "142",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr14.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "9502",
            "@ref": "gr14",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "129",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr15.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "7173",
            "@ref": "gr15",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "142",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr16.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "9254",
            "@ref": "gr16",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "130",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr17.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "5810",
            "@ref": "gr17",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "157",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr18.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "10431",
            "@ref": "gr18",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "124",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr19.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "6604",
            "@ref": "gr19",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "132",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr2.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "7222",
            "@ref": "gr2",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "123",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr20.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "5506",
            "@ref": "gr20",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "212",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr21.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "8225",
            "@ref": "gr21",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "135",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr22.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "10561",
            "@ref": "gr22",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "118",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr3.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "8040",
            "@ref": "gr3",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "117",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr4.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "5078",
            "@ref": "gr4",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "123",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr5.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "9618",
            "@ref": "gr5",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "216",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr6.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "5802",
            "@ref": "gr6",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "100",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr7.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "9246",
            "@ref": "gr7",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "94",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr8.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "5036",
            "@ref": "gr8",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "191",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr9.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "25739",
            "@ref": "gr9",
            "@mimetype": "image/gif"
        },
        {
            "@category": "high",
            "@height": "1197",
            "@width": "2559",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr1_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "236886",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1443",
            "@width": "2362",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr10_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "158951",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1955",
            "@width": "2362",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr11_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "597864",
            "@ref": "gr11",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1236",
            "@width": "1654",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr12_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "147170",
            "@ref": "gr12",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2019",
            "@width": "3428",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr13_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "385371",
            "@ref": "gr13",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1980",
            "@width": "3051",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr14_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "473722",
            "@ref": "gr14",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2011",
            "@width": "3427",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr15_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "344513",
            "@ref": "gr15",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1980",
            "@width": "3051",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr16_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "471210",
            "@ref": "gr16",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1402",
            "@width": "2363",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr17_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "243039",
            "@ref": "gr17",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2455",
            "@width": "3425",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr18_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "490844",
            "@ref": "gr18",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2191",
            "@width": "1656",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr19_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "311085",
            "@ref": "gr19",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1425",
            "@width": "2362",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr2_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "178169",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2191",
            "@width": "1654",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr20_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "291310",
            "@ref": "gr20",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1281",
            "@width": "1654",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr21_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "161819",
            "@ref": "gr21",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1019",
            "@width": "1654",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr22_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "165697",
            "@ref": "gr22",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "892",
            "@width": "1653",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr3_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "107806",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1266",
            "@width": "2362",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr4_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "141811",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1240",
            "@width": "2205",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr5_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "301378",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1252",
            "@width": "1654",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr6_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "103475",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1172",
            "@width": "2559",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr7_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "288174",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "707",
            "@width": "1654",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr8_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "59598",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1183",
            "@width": "1378",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-gr9_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "171069",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si1.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11815",
            "@ref": "si1",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si10.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3698",
            "@ref": "si10",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si11.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "24844",
            "@ref": "si11",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si12.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "32468",
            "@ref": "si12",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si13.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "9365",
            "@ref": "si13",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si14.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1920",
            "@ref": "si14",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si15.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1411",
            "@ref": "si15",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si16.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "25264",
            "@ref": "si16",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si17.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "24869",
            "@ref": "si17",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si18.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "8518",
            "@ref": "si18",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si2.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "33451",
            "@ref": "si2",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si3.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "9508",
            "@ref": "si3",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si4.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "21477",
            "@ref": "si4",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si5.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "24422",
            "@ref": "si5",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si6.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "8248",
            "@ref": "si6",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si7.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11059",
            "@ref": "si7",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si8.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "37903",
            "@ref": "si8",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-si9.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "21321",
            "@ref": "si9",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1359431122005038-am.pdf?httpAccept=%2A%2F%2A",
            "@multimediatype": "Acrobat PDF file",
            "@type": "AAM-PDF",
            "@size": "2418027",
            "@ref": "am",
            "@mimetype": "application/pdf"
        }
    ]},
    "link": {
        "@rel": "abstract",
        "@href": "https://api.elsevier.com/content/abstract/scopus_id/85129699415"
    }
}}