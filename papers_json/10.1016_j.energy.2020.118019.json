{"full-text-retrieval-response": {
    "scopus-eid": "2-s2.0-85086479731",
    "originalText": "serial JL 271090 291210 291702 291711 291731 291877 291878 31 Energy ENERGY 2020-06-05 2020-06-05 2020-06-12 2020-06-12 2020-07-06T14:56:01 1-s2.0-S0360544220311269 S0360-5442(20)31126-9 S0360544220311269 10.1016/j.energy.2020.118019 S300 S300.1 FULL-TEXT 1-s2.0-S0360544220X00120 2022-06-22T04:55:30.259886Z 0 0 20200815 2020 2020-06-05T16:33:13.566395Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid highlightsabst primabst ref 0360-5442 03605442 true 205 205 C Volume 205 30 118019 118019 118019 20200815 15 August 2020 2020-08-15 2020 Full Length Articles article fla © 2020 Elsevier Ltd. All rights reserved. MODIFIEDDEEPLEARNINGREINFORCEMENTLEARNINGFORINCENTIVEBASEDDEMANDRESPONSEMODEL WEN L 1 Introduction 2 Demand response model 2.1 Energy service provider\u2019s profits 2.2 End users\u2019 profits 3 Modified deep learning model for forecasting 3.1 Recurrent neural network 3.2 Modified deep learning model based on RNN (MDL-RNN) 3.2.1 Inputs and model structure 3.2.2 Model setup 3.2.3 Modified forecasting results 3.2.4 Evaluation metrics 4 Reinforcement learning for incentive rates optimization 5 Results and discussions 5.1 Data 5.2 Modified deep learning-based forecasting results 5.3 Incentive rate optimization based on reinforcement learning 5.3.1 Parameters setup 5.3.2 Convergence of Q-value 5.3.3 Results of different EUs with different λ 5.3.4 Results of same EU with different λ 5.3.5 Short-term incentive-based DR program 6 Conclusions CRediT authorship contribution statement Acknowledgement Appendix A A. 1 The convergence of Q-value A. 2 The discomfort cost do not change any more when λ 2 > 0.6 References GHAZVINI 2015 786 799 M KHALILI 2019 92 104 T FENG 2020 119035 Z FENG 2017 210 219 Z HAIDER 2016 166 178 H YU 2016 702 710 M DIEKERHOF 2018 6018 6029 M YAN 2018 411 419 X RAHMANIANDEBILI 2017 577 581 M INTERNATIONALCONFERENCECOMPUTINGNETWORKINGCOMMUNICATIONSICNC ENERGYMANAGEMENTENDUSERSMODELINGREACTIONAGENCOSPOINTVIEW MONFARED 2019 274 285 H SRINIVASAN 2017 132 143 D GHASEMKHANI 2019 4988 4998 A LI 2016 739 749 Y ASADINEJAD 2017 215 223 A RAHMANIANDEBILI 2016 115 124 M RAHMANIANDEBILI 2016 352 362 M ERDINC 2019 1476 1487 O LI 2016 3112 3121 Z SHAHRYARI 2018 205 214 E YU 2017 267 279 M RAHMANIANDEBILI 2019 M PLANNINGOPERATIONPLUGINELECTRICVEHICLES DU 2020 117591 G SUTTON 2018 R REINFORCEMENTLEARNINGINTRODUCTION VAZQUEZCANTELI 2019 1072 1089 J COSTANZO 2016 81 90 G ARIF 2016 25 36 A WANG 2016 5109 5119 H MAHAPATRA 2017 2812 C MARINESCU 2017 9 A LU 2019 6629 6639 R LU 2019 937 949 R FANG 2015 1025 1037 X ASADINEJAD 2018 26 36 A WANG 2015 510 519 Y YU 2016 1488 1497 M FENG 2020 124627 Z NIU 2020 04020008 W MIKOLOV 2010 T ELEVENTHANNUALCONFERENCEINTERNATIONALSPEECHCOMMUNICATIONASSOCIATION RECURRENTNEURALNETWORKBASEDLANGUAGEMODEL YAN 2012 746 756 Z GERS 1999 F LEARNINGFORGETCONTINUALPREDICTIONLSTM CHUNG 2014 J EMPIRICALEVALUATIONGATEDRECURRENTNEURALNETWORKSSEQUENCEMODELING GUO 2018 1186 1200 Z RAHMAN 2018 372 385 A WANG 2019 10 20 Y PATRO 2015 S NORMALIZATIONAPREPROCESSINGSTAGE GIROSI 1995 219 269 F SRIVASTAVA 2014 1929 1958 N KINGMA 2014 D ADAMAMETHODFORSTOCHASTICOPTIMIZATION LU 2018 220 230 R KAELBLING 1996 237 285 L LIU 2019 6436 6445 T PETERS 2008 1180 1190 J HUYS 2015 2634 2641 Q PENG 1994 226 232 J KUMAR 2015 14 R SCHULMAN 2017 J EQUIVALENCEBETWEENPOLICYGRADIENTSSOFTQLEARNING YU 2016 51 56 M IEEEINTERNATIONALCONFERENCESMARTGRIDCOMMUNICATIONSSMARTGRIDCOMM INCENTIVEBASEDDEMANDRESPONSEAPPROACHFORAGGREGATEDDEMANDSIDEPARTICIPATION WENX2020X118019 WENX2020X118019XL 2022-06-12T00:00:00.000Z 2022-06-12T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ © 2020 Elsevier Ltd. All rights reserved. 2022-06-11T21:30:00.368Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/aggregated-refined National Natural Science Foundation of China 71822104 NSFC National Natural Science Foundation of China http://data.elsevier.com/vocabulary/SciValFunders/501100001809 http://sws.geonames.org/1814991/ China Scholarship Council CSC China Scholarship Council http://data.elsevier.com/vocabulary/SciValFunders/501100004543 http://sws.geonames.org/1814991/ ESP ESP European Society for Photobiology http://data.elsevier.com/vocabulary/SciValFunders/100015669 http://sws.geonames.org/6695072/ Demand response (DR) is an important strategy to address these problems. In DR, EUs would change their electricity consumption patterns by reducing or shifting electricity demand when they receive induced signals from ESP [5]. In smart grid, advanced metering infrastructure can support bidirectional communication among GO, ESP and EUs [6]. Besides, smart appliances that can be scheduled to perform their tasks during a time period specified by EUs, have been widely adopted in buildings [7]. This has made DR to be a promising way to promote supply-demand balance, improve power system stability, as well as reduce financial risks of ESP. In general, DR can be divided into price-based DR and incentive-based DR. Price-based DR is to shift EUs\u2019 peak electricity demand to off-peak periods by implementing specific tariffs including time-of-use (TOU) pricing, critical peak pricing, and real-time pricing [8]. Rahmani-Andebili and Shen [9] investigated a price-based energy management method to minimize the cost of generation company. To reduce the difference of electricity demand between peak and valley periods, a hybrid price-based DR program was proposed in Ref. [10]. Srinivasan et al. [11] developed a dynamic pricing strategy based on game theory and achieved peak electricity demand reduction by 10% and 5% for residential and commercial users respectively.Table 3 shows that the MDL-RNN model performs well in forecasting wholesale electricity price, PV power output, and EUs\u2019 power load. At the same time, the MDL-RNN model is superior to conventional methods, such as simple ANN, support vector machine (SVM), and extreme learning machine (ELM). It can learn the time dependencies and nonlinearity in time series data. In addition, it can be noted that the MDL-RNN model achieves better performance in forecasting PV power output and wholesale electricity price than EUs\u2019 power load. This is due to the fact that EUs\u2019 power load is of higher volatility and fluctuation which will increase the difficulty in learning the relationship between the input variables and the output power load.This work is supported by the National Natural Science Foundation of China (No. 71822104), and the China Scholarship Council. This work is supported by the National Natural Science Foundation of China (No. 71822104 ), and the China Scholarship Council . item S0360-5442(20)31126-9 S0360544220311269 1-s2.0-S0360544220311269 10.1016/j.energy.2020.118019 271090 2020-08-12T10:48:46.634323Z 2020-08-15 1-s2.0-S0360544220311269-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/MAIN/application/pdf/78419b0799ba6bdd9db1fcc567cc6815/main.pdf main.pdf pdf true 2344392 MAIN 15 1-s2.0-S0360544220311269-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/PREVIEW/image/png/d03b79dbee118a79050304ecf09e21ec/main_1.png main_1.png png 53819 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0360544220311269-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr3/DOWNSAMPLED/image/jpeg/b87b9ed2c2c9f58c2393431fe07dccb6/gr3.jpg gr3 gr3.jpg jpg 78202 747 532 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr1/DOWNSAMPLED/image/jpeg/62c67278306d4f04efcd7e9a80b7923d/gr1.jpg gr1 gr1.jpg jpg 77401 506 534 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr10/DOWNSAMPLED/image/jpeg/af458471d7bb688d35974b5c5adbb96f/gr10.jpg gr10 gr10.jpg jpg 81735 909 378 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr11.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr11/DOWNSAMPLED/image/jpeg/ffcfeba4b21c3e78aab840ac8ddda4b9/gr11.jpg gr11 gr11.jpg jpg 88970 946 381 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr6/DOWNSAMPLED/image/jpeg/afed982eddea0eb075f8f67d68156b27/gr6.jpg gr6 gr6.jpg jpg 27745 308 381 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr7/DOWNSAMPLED/image/jpeg/c9c6556f8b7e0a6bb4d06ebc8e1644ba/gr7.jpg gr7 gr7.jpg jpg 97031 1022 350 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr4/DOWNSAMPLED/image/jpeg/98afaac6467a1a5d1e85582f946579a2/gr4.jpg gr4 gr4.jpg jpg 73951 1021 354 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr12.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr12/DOWNSAMPLED/image/jpeg/dd44bc1d9523b6733453120480a1ff13/gr12.jpg gr12 gr12.jpg jpg 28205 276 379 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr2/DOWNSAMPLED/image/jpeg/e3fd8df168b1ac20d8186ecc356f17f1/gr2.jpg gr2 gr2.jpg jpg 21849 233 542 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr5/DOWNSAMPLED/image/jpeg/5e27a99ae05119aa176b475bd04de5a6/gr5.jpg gr5 gr5.jpg jpg 33354 297 380 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr8/DOWNSAMPLED/image/jpeg/2e1775cc6a81f823f4bbcc45098f0959/gr8.jpg gr8 gr8.jpg jpg 26144 284 387 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr9/DOWNSAMPLED/image/jpeg/8798031a4ed1558c82e55f17cbc7fd4e/gr9.jpg gr9 gr9.jpg jpg 55399 670 382 IMAGE-DOWNSAMPLED 1-s2.0-S0360544220311269-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr3/THUMBNAIL/image/gif/9f080f6a3e8de4ad67cdfd0e863dc465/gr3.sml gr3 gr3.sml sml 6843 164 117 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr1/THUMBNAIL/image/gif/acc9bfb179771832cb210aa704de4a37/gr1.sml gr1 gr1.sml sml 11637 164 173 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr10/THUMBNAIL/image/gif/98df32bd2eff9b2bc87beed33bb4eb20/gr10.sml gr10 gr10.sml sml 4190 164 68 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr11.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr11/THUMBNAIL/image/gif/6aea32e4ebde2b105c0cd1b115d521a2/gr11.sml gr11 gr11.sml sml 4774 164 66 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr6/THUMBNAIL/image/gif/a3567fe8cad5b8081cf1b5eabc426e5c/gr6.sml gr6 gr6.sml sml 7361 164 202 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr7/THUMBNAIL/image/gif/b7ed0dbd04af4bbe3093c8e88066e444/gr7.sml gr7 gr7.sml sml 4209 163 56 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr4/THUMBNAIL/image/gif/ddae999ad2d72a05c3975eebf911b200/gr4.sml gr4 gr4.sml sml 3108 162 56 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr12.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr12/THUMBNAIL/image/gif/c617d96e0e05e8c8db08d863393feec9/gr12.sml gr12 gr12.sml sml 7970 159 219 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr2/THUMBNAIL/image/gif/7d315ef4f3c2bcc1a7d0cdcd903e073d/gr2.sml gr2 gr2.sml sml 4449 94 219 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr5/THUMBNAIL/image/gif/88f77139f155350a24ea05120314a986/gr5.sml gr5 gr5.sml sml 8425 164 209 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr8/THUMBNAIL/image/gif/026b6a7dfce207fb78b68c0424462335/gr8.sml gr8 gr8.sml sml 6217 161 219 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr9/THUMBNAIL/image/gif/cf46d8887649b0456b678a8b20e457f4/gr9.sml gr9 gr9.sml sml 4087 163 93 IMAGE-THUMBNAIL 1-s2.0-S0360544220311269-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr3/HIGHRES/image/jpeg/162ef2a09081073657d18967e8a5f108/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 527949 3305 2355 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr1/HIGHRES/image/jpeg/90d4b617011495e9b6e8aedaa6eaf31a/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 629840 2242 2367 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr10_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr10/HIGHRES/image/jpeg/b7275b2c2e45e4479e32b19308fdaf11/gr10_lrg.jpg gr10 gr10_lrg.jpg jpg 542328 4024 1673 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr11_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr11/HIGHRES/image/jpeg/07e43c039031bf913fc8951422bebe99/gr11_lrg.jpg gr11 gr11_lrg.jpg jpg 541881 4195 1689 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr6/HIGHRES/image/jpeg/dfc7409ea637ceef0bf01d93e9877c7a/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 222062 1365 1686 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr7/HIGHRES/image/jpeg/01f006afb9f71ced4ca5c0130b6e664c/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 823485 4528 1551 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr4/HIGHRES/image/jpeg/5bd3aa9d8fed1a6f17e718c41a268604/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 539644 4528 1570 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr12_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr12/HIGHRES/image/jpeg/cb456f383754186cbff41c1ad76470e8/gr12_lrg.jpg gr12 gr12_lrg.jpg jpg 191027 1223 1681 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr2/HIGHRES/image/jpeg/0fca368cf7f8c592858aa5db074f08f3/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 149785 1031 2402 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr5/HIGHRES/image/jpeg/47e3f76ffaf122295143b0f8c67474eb/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 256896 1318 1684 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr8/HIGHRES/image/jpeg/fe273b52f6a3166d3f271bdb65275389/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 182277 1259 1714 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-gr9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/gr9/HIGHRES/image/jpeg/bffc67b91cb45f28f6aff9278a83b9b2/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 386201 2971 1693 IMAGE-HIGH-RES 1-s2.0-S0360544220311269-si51.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/5dd8b65ecb42998ec175987643da8db7/si51.svg si51 si51.svg svg 49724 ALTIMG 1-s2.0-S0360544220311269-si9.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/f275b2a36ac2213bcbb0f18b5d15fc04/si9.svg si9 si9.svg svg 12883 ALTIMG 1-s2.0-S0360544220311269-si27.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/83a7d3017c08a6f08f63b323b6ee8896/si27.svg si27 si27.svg svg 4817 ALTIMG 1-s2.0-S0360544220311269-si60.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/fd586e4af8255003548923fadff21215/si60.svg si60 si60.svg svg 7295 ALTIMG 1-s2.0-S0360544220311269-si46.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/604e6f593dacaf08cd90b3cbe4481929/si46.svg si46 si46.svg svg 5715 ALTIMG 1-s2.0-S0360544220311269-si6.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/cd118dd42c7f0ec3de1be2bf4ac227a5/si6.svg si6 si6.svg svg 7841 ALTIMG 1-s2.0-S0360544220311269-si42.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/d2112648a673d788a5ea09804920a7c3/si42.svg si42 si42.svg svg 11377 ALTIMG 1-s2.0-S0360544220311269-si15.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/e1a105c394a4d4584b59a8feac62febb/si15.svg si15 si15.svg svg 16800 ALTIMG 1-s2.0-S0360544220311269-si16.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/d23c83733beadbf890b3314c8b52971c/si16.svg si16 si16.svg svg 1780 ALTIMG 1-s2.0-S0360544220311269-si5.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/0e919831e8e4287f08507bb2de207391/si5.svg si5 si5.svg svg 7051 ALTIMG 1-s2.0-S0360544220311269-si65.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/e67a911ab2904a5b6a02b634d7c2934d/si65.svg si65 si65.svg svg 2919 ALTIMG 1-s2.0-S0360544220311269-si2.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/f2a36114c07a08aaa8200e3783e3289f/si2.svg si2 si2.svg svg 4078 ALTIMG 1-s2.0-S0360544220311269-si63.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/b8a1ae40bede93ae5c3863ee99a964fe/si63.svg si63 si63.svg svg 21076 ALTIMG 1-s2.0-S0360544220311269-si55.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/26657f0395fc03dca8515f044076814e/si55.svg si55 si55.svg svg 32565 ALTIMG 1-s2.0-S0360544220311269-si20.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/8e856c2fa9015e751290d7febf58e007/si20.svg si20 si20.svg svg 36856 ALTIMG 1-s2.0-S0360544220311269-si34.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/daa93925a99173d34baeb8ef60aad195/si34.svg si34 si34.svg svg 5646 ALTIMG 1-s2.0-S0360544220311269-si48.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/f7c1a73a0b10814e67775d67c598ca10/si48.svg si48 si48.svg svg 2975 ALTIMG 1-s2.0-S0360544220311269-si1.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/afdd03c2b53eb7697b4cac73f1036aaa/si1.svg si1 si1.svg svg 31299 ALTIMG 1-s2.0-S0360544220311269-si4.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/e5949571e2935ccdade8a77b5a12c685/si4.svg si4 si4.svg svg 4633 ALTIMG 1-s2.0-S0360544220311269-si3.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/1cf5aa8308239cb079e71213d96534b0/si3.svg si3 si3.svg svg 5738 ALTIMG 1-s2.0-S0360544220311269-si61.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/c2c2a1e5e64007f792008836bb12fa7a/si61.svg si61 si61.svg svg 17598 ALTIMG 1-s2.0-S0360544220311269-si26.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/46474654e5d14a12dd72ebc1d74ebbe7/si26.svg si26 si26.svg svg 5660 ALTIMG 1-s2.0-S0360544220311269-si37.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/d326fff00af8479c49f4c22ff71e2ab1/si37.svg si37 si37.svg svg 4741 ALTIMG 1-s2.0-S0360544220311269-si45.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/b6ecdb692ab8a66ee9bb2a5649340454/si45.svg si45 si45.svg svg 29595 ALTIMG 1-s2.0-S0360544220311269-si62.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/b367884639db5348898155ee043b0bd9/si62.svg si62 si62.svg svg 11051 ALTIMG 1-s2.0-S0360544220311269-si49.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/3b7ea2ef1d11a19165b0d6519d31d691/si49.svg si49 si49.svg svg 6627 ALTIMG 1-s2.0-S0360544220311269-si31.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/277c253e584815bb60f2662e5342fb4e/si31.svg si31 si31.svg svg 1076 ALTIMG 1-s2.0-S0360544220311269-si33.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/d8a577474be50ba6047e8f392c30af94/si33.svg si33 si33.svg svg 22114 ALTIMG 1-s2.0-S0360544220311269-si38.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/b1398a9ddb0d53a4ad6f00a57f94785f/si38.svg si38 si38.svg svg 4918 ALTIMG 1-s2.0-S0360544220311269-si29.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/37a0c7124e9384c901f8cd798454664c/si29.svg si29 si29.svg svg 11041 ALTIMG 1-s2.0-S0360544220311269-si57.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/fb2eaa329ad4e43815793cf532548caa/si57.svg si57 si57.svg svg 26748 ALTIMG 1-s2.0-S0360544220311269-si59.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/8285bdadd2b32012e03bd129e124f6d3/si59.svg si59 si59.svg svg 36721 ALTIMG 1-s2.0-S0360544220311269-si13.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/0565d572f34cc8a42a3baf41a595ef0b/si13.svg si13 si13.svg svg 21500 ALTIMG 1-s2.0-S0360544220311269-si43.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/895926689ccfc1a0a135574d9f574bce/si43.svg si43 si43.svg svg 5214 ALTIMG 1-s2.0-S0360544220311269-si28.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/51111aefa5de95e4d09430938223994f/si28.svg si28 si28.svg svg 10376 ALTIMG 1-s2.0-S0360544220311269-si22.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/3db1d1653a8c09d6ca232ddae6360d14/si22.svg si22 si22.svg svg 15360 ALTIMG 1-s2.0-S0360544220311269-si14.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/e74a3f8aa2cf5e2fcea5d5917f72ab18/si14.svg si14 si14.svg svg 26209 ALTIMG 1-s2.0-S0360544220311269-si58.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/aa45d192d0e6ca700fa922111a7c5f57/si58.svg si58 si58.svg svg 30096 ALTIMG 1-s2.0-S0360544220311269-si23.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/62b6954efdc08bb8cf5c6197443f05d5/si23.svg si23 si23.svg svg 10308 ALTIMG 1-s2.0-S0360544220311269-si47.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/9d1474079c9dcc7ebc86a1ea3255ec4e/si47.svg si47 si47.svg svg 3437 ALTIMG 1-s2.0-S0360544220311269-si10.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/2d16042af8b58aba6a6710a13ab6075b/si10.svg si10 si10.svg svg 5311 ALTIMG 1-s2.0-S0360544220311269-si40.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/ae75584a1407a72ff457f74163128e65/si40.svg si40 si40.svg svg 10113 ALTIMG 1-s2.0-S0360544220311269-si36.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/0735c18e6c2bb46290668b84927b5b57/si36.svg si36 si36.svg svg 2965 ALTIMG 1-s2.0-S0360544220311269-si17.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/29034dfc49c6d68e9c4c3dcaa1a33fd7/si17.svg si17 si17.svg svg 28580 ALTIMG 1-s2.0-S0360544220311269-si21.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/a5931258386131e5631dd553c364438a/si21.svg si21 si21.svg svg 9002 ALTIMG 1-s2.0-S0360544220311269-si12.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/971257507b58facf409b84978175d2b0/si12.svg si12 si12.svg svg 8945 ALTIMG 1-s2.0-S0360544220311269-si32.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/a6b403ff99dc7b0af834efb1e8fece1b/si32.svg si32 si32.svg svg 21009 ALTIMG 1-s2.0-S0360544220311269-si64.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/99035b08123d06954f68c9f7c733df90/si64.svg si64 si64.svg svg 26771 ALTIMG 1-s2.0-S0360544220311269-si7.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/9e2ed550ed4b67cfe0cceffb00921f28/si7.svg si7 si7.svg svg 42765 ALTIMG 1-s2.0-S0360544220311269-si44.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/2ba6f50f1c3ac667421df2a5cc963e47/si44.svg si44 si44.svg svg 24253 ALTIMG 1-s2.0-S0360544220311269-si19.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/365bc46d738326206fdfeb438fe6f915/si19.svg si19 si19.svg svg 29374 ALTIMG 1-s2.0-S0360544220311269-si41.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/0b997280d370397b8c9582726a1a34c8/si41.svg si41 si41.svg svg 23732 ALTIMG 1-s2.0-S0360544220311269-si8.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/f7665a5f4c4f343c85c0d18b9b3d9af6/si8.svg si8 si8.svg svg 17166 ALTIMG 1-s2.0-S0360544220311269-si30.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/fe53374f7868ca8273c6627f82f32dff/si30.svg si30 si30.svg svg 23201 ALTIMG 1-s2.0-S0360544220311269-si39.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/9640849fec80a6aea76396112606ff6c/si39.svg si39 si39.svg svg 4075 ALTIMG 1-s2.0-S0360544220311269-si54.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/ec4d3bb9afce5077b076d6be5b0ea152/si54.svg si54 si54.svg svg 35705 ALTIMG 1-s2.0-S0360544220311269-si24.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/6ea66b8fe4bf658edf34c8c92f53e17f/si24.svg si24 si24.svg svg 8420 ALTIMG 1-s2.0-S0360544220311269-si53.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/6387ecccea7174dc1b9b5feee45b649b/si53.svg si53 si53.svg svg 35843 ALTIMG 1-s2.0-S0360544220311269-si35.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/419509c720499006b91afa2d1dda9af4/si35.svg si35 si35.svg svg 3367 ALTIMG 1-s2.0-S0360544220311269-si18.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/dc67c08258963f02e0a743f2a0549248/si18.svg si18 si18.svg svg 32563 ALTIMG 1-s2.0-S0360544220311269-si56.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/d2c8dd168509f1ed86f877980bf3c31c/si56.svg si56 si56.svg svg 27958 ALTIMG 1-s2.0-S0360544220311269-si50.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/a2fc20f8e8add29251b2cf4b2a51d039/si50.svg si50 si50.svg svg 7226 ALTIMG 1-s2.0-S0360544220311269-si25.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/d2709e4782228bbbf50d33eb85d31f81/si25.svg si25 si25.svg svg 11024 ALTIMG 1-s2.0-S0360544220311269-si11.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/f2bcda670b18669d3e3c6bc780f8636b/si11.svg si11 si11.svg svg 3759 ALTIMG 1-s2.0-S0360544220311269-si52.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0360544220311269/STRIPIN/image/svg+xml/6a63fcee45c7b0592b0bbdfc27b72f61/si52.svg si52 si52.svg svg 32816 ALTIMG 1-s2.0-S0360544220311269-am.pdf am am.pdf pdf 779054 AAM-PDF https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:1028DWMGZ8D/MAIN/application/pdf/3f4ea5656a25bbfe8e2790318735a6ec/am.pdf EGY 118019 118019 S0360-5442(20)31126-9 10.1016/j.energy.2020.118019 Elsevier Ltd Fig. 1 Schematic of a hierarchical electricity market. Fig. 1 Fig. 2 Schematic of RL to find the optimal incentive rates. Fig. 2 Fig. 3 Flowchart of IDR-MDLRL algorithm. Fig. 3 Fig. 4 Distributions of Δ t in forecasting wholesale electricity price, PV power output, and EU 1\u2019s power load. Fig. 4 Fig. 5 Forecasting results of wholesale electricity price from July 23, 2018 to July 29, 2018. Fig. 5 Fig. 6 Forecasting results of PV power output from July 23, 2018 to July 29, 2018. Fig. 6 Fig. 7 Power load forecasting results of three EUs from July 23, 2018 to July 29, 2018. Fig. 7 Fig. 8 Convergence of Q-value to acquire optimal incentive rates for EU 2 with different λ. Fig. 8 Fig. 9 Convergence of Q-value to acquire optimal incentive rates for different EUs. Fig. 9 Fig. 10 Results of different EUs when λ = 0.1. Fig. 10 Fig. 11 Results of EU 2 with different λ 2. Fig. 11 Fig. 12 Real load demand of EUs. Fig. 12 Table 1 Inputs of the MDL-RNN model. Table 1 Forecasting targets Inputs EUs load Month, week, day, hour, temperature, humidity, wind speed, historical load PV power output Month, day, hour, humid, temperature, global horizontal radiation, diffuse horizontal radiation, historical PV power output Wholesale market price Month, week, day, hour, holiday, historical wholesale market price Table 2 Ranges of hyper-parameters. Table 2 Hyper-parameters Range Neuron number of layers 2, 3 and 4 [10, 200] Neurons type of layer 2, 3 [LSTM, GRU, SimpleRNN] Activation function of layer 4 [Sigmoid, ReLU] Dropout of layer 2, 3, and 4 [0,1] Table 3 Quantitative evaluation of forecasting results. Table 3 MDL-RNN ANN SVM ELM MAE MAPE MAE MAPE MAE MAPE MAE MAPE Price 3.31 0.096 5.88 0.153 8.19 0.391 6.28 0.159 PV 0.11 0.039 0.17 0.106 0.16 0.101 0.29 0.249 Load 1 0.25 0.129 0.55 0.173 0.59 0.185 0.36 0.131 Load 2 0.14 0.111 0.69 0.379 0.72 0.385 0.38 0.161 Load 3 0.28 0.137 0.36 0.382 0.38 0.394 0.31 0.154 Table 4 Parameters of RL model. Table 4 Parameters Value Discomfort parameter μ 1/μ 2/μ 3 1/2/3 Discomfort parameter ω i 1 Maximum electricity reduction Δ E max 0.3E ij Minimum incentive rate α min 0.3p min Maximum incentive rate α max p min Table 5 Electricity elasticity in different hours. Table 5 Period Elasticity(ξ j ) 0 am\u20136 am, 22 pm\u201323 pm 0.5 7 am - 16 pm 0.3 17 pm\u201321 pm 0.1 Table 6 Cost benefit analysis of end users. Table 6 λ 0.1 0.5 0.9 users EU 1 EU 2 EU 3 EU 1 EU 2 EU 3 EU 1 EU 2 User3 μ n 1 2 3 1 2 3 1 2 3 DR resources (kWh) 7.01 6.44 2.27 9.12 13.12 3.13 9.12 13.19 3.13 Incentive income (￠) 8.34 6.72 2.74 12.03 17.57 4.41 12.03 17.69 4.40 Discomfort cost (￠) 8.49 9.51 2.93 11.53 24.68 4.29 11.53 24.88 4.29 Profit 1 (￠) −6.81 −7.89 −2.36 0.25 −3.56 0.06 9.67 13.43 3.53 Solar power income (￠) 6.56 49.93 100.22 6.56 49.93 100.22 6.56 49.93 100.22 Profit 2 (￠) −0.25 42.04 97.86 6.81 46.37 100.28 16.23 63.36 103.75 Table 7 Cost benefit analysis of energy service provider. Table 7 λ 0.1 0.5 0.9 Gross income of DR (￠) 50.05 76.05 76.23 Cost of DR (￠) 17.80 34.01 34.12 Profit (￠) 32.25 42.04 42.11 Table 8 Financial analysis of EU 2 with different λ 2. Table 8 λ 2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 DR resources (kWh) 6.44 7.96 9.82 12.02 13.12 13.19 13.19 13.19 13.19 Incentive income (￠) 6.72 8.86 11.88 15.70 17.56 17.68 17.68 17.68 17.68 Discomfort cost (￠) 9.51 12.44 16.44 21.82 24.68 24.88 24.88 24.88 24.88 Profit 1 (￠) −7.89 −8.18 −7.95 −6.81 −3.56 0.66 4.91 9.17 13.43 PV income (￠) 49.93 49.93 49.93 49.93 49.93 49.93 49.93 49.93 49.93 Profit 2 (￠) 42.04 41.75 41.98 43.12 46.37 50.59 54.84 59.10 63.36 Table 9 Cost benefit analysis of energy service provider. Table 9 λ 2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Gross income of DR (￠) 21.41 25.71 30.96 36.93 39.56 39.72 39.72 39.72 39.72 Cost of DR (￠) 6.72 8.86 11.88 15.70 17.56 17.68 17.68 17.68 17.68 Profit (￠) 14.69 16.85 19.08 21.23 22.00 22.04 22.04 22.04 22.04 Table 10 Benefits of energy service provider implementing the short-term DR program. Table 10 EUs 1 2 3 Total Cost of DR (￠) 6.898 8.869 4.007 19.774 Cost without DR (￠) 15.599 21.332 8.315 45.246 Peak electricity demand under DR (kWh) 2.726 4.840 1.303 8.869 Peak electricity demand without DR (kWh) 3.304 5.723 1.661 10.688 Total electricity demand reduction (kWh) 4.284 5.776 2.294 12.354 Modified deep learning and reinforcement learning for an incentive-based demand response model Lulu Wen Conceptualization Methodology Data curation Software Visualization Formal analysis Writing - original draft a b c Kaile Zhou Conceptualization Methodology Resources Visualization Writing - review & editing Project administration Supervision a b ∗ Jun Li Resources Writing - review & editing d Shanyong Wang Writing - review & editing e a School of Management, Hefei University of Technology, Hefei, 230009, China School of Management Hefei University of Technology Hefei 230009 China . School of Management, Hefei University of Technology, Hefei 230009, China b Key Laboratory of Process Optimization and Intelligent Decision-making of Ministry of Education, Hefei University of Technology, Hefei, 230009, China Key Laboratory of Process Optimization and Intelligent Decision-making of Ministry of Education Hefei University of Technology Hefei 230009 China . Key Laboratory of Process Optimization and Intelligent Decision-making of Ministry of Education, Hefei University of Technology, Hefei 230009, China c Lawrence Berkeley National Laboratory, 1 Cyclotron Road, CA, 94720, USA Lawrence Berkeley National Laboratory 1 Cyclotron Road CA 94720 USA . Lawrence Berkeley National Laboratory, 1 Cyclotron Road, CA 94720, USA d School of Economics, Hefei University of Technology, Hefei, 230009, China School of Economics Hefei University of Technology Hefei 230009 China . School of Economics, Hefei University of Technology, Hefei 230009, China e University of Science and Technology of China, Hefei, 230026, China University of Science and Technology of China Hefei 230026 China . University of Science and Technology of China, Hefei 230026, China ∗ Corresponding author. School of Management, Hefei University of Technology, Hefei, 230009, China. School of Management Hefei University of Technology Hefei 230009 China Incentive-based demand response (DR) program can induce end users (EUs) to reduce electricity demand during peak period through rewards. In this study, an incentive-based DR program with modified deep learning and reinforcement learning is proposed. A modified deep learning model based on recurrent neural network (MDL-RNN) was first proposed to identify the future uncertainties of environment by forecasting day-ahead wholesale electricity price, photovoltaic (PV) power output, and power load. Then, reinforcement learning (RL) was utilized to explore the optimal incentive rates at each hour which can maximize the profits of both energy service providers (ESPs) and EUs. The results showed that the proposed modified deep learning model can achieve more accurate forecasting results compared with some other methods. It can support the development of incentive-based DR programs under uncertain environment. Meanwhile, the optimized incentive rate can increase the total profits of ESPs and EUs while reducing the peak electricity demand. A short-term DR program was developed for peak electricity demand period, and the experimental results show that peak electricity demand can be reduced by 17%. This contributes to mitigating the supply-demand imbalance and enhancing power system security. Keywords Demand response Modified deep learning Reinforcement learning Smart grid 1 Introduction Since the participators of wholesale electricity market usually have difficulty in acquiring detailed market information, end users (EUs) usually face the market uncertainty and the financial risks of buying electricity at real-time prices [1]. Thus, energy service providers (ESPs) which can monitor the market effectively, start to participate into wholesale market on behalf the EUs. As the connectors between grid operator (GO) and EUs, ESPs purchase electricity from GO and sell electricity to EUs for profits. They can help EUs reduce energy expenditure and reduce the risks of market uncertainties, but they always face the revenue risk [2]. In addition, the imbalance between electricity supply and demand can bring high risks for power system operation [3]. Therefore, ESPs have to establish effective measures to manage their financial risks, and they should also take the responsibility of keeping supply-demand balance to improve power system stability and reliability [4]. Demand response (DR) is an important strategy to address these problems. In DR, EUs would change their electricity consumption patterns by reducing or shifting electricity demand when they receive induced signals from ESP [5]. In smart grid, advanced metering infrastructure can support bidirectional communication among GO, ESP and EUs [6]. Besides, smart appliances that can be scheduled to perform their tasks during a time period specified by EUs, have been widely adopted in buildings [7]. This has made DR to be a promising way to promote supply-demand balance, improve power system stability, as well as reduce financial risks of ESP. In general, DR can be divided into price-based DR and incentive-based DR. Price-based DR is to shift EUs\u2019 peak electricity demand to off-peak periods by implementing specific tariffs including time-of-use (TOU) pricing, critical peak pricing, and real-time pricing [8]. Rahmani-Andebili and Shen [9] investigated a price-based energy management method to minimize the cost of generation company. To reduce the difference of electricity demand between peak and valley periods, a hybrid price-based DR program was proposed in Ref. [10]. Srinivasan et al. [11] developed a dynamic pricing strategy based on game theory and achieved peak electricity demand reduction by 10% and 5% for residential and commercial users respectively. Incentive-based DR programs generally present certain rewards for EUs to reduce their electricity demand during specific periods [12]. They can be dispatched more flexibly than price-based DR programs, and thereby ESP can get the required DR resources more easily. In addition, EUs have high initiative to participate in the incentive-based DR programs since they can get the rewards more directly [13]. For example, in 2017, the peak electricity demand reductions by incentive-based DR programs accounted for 93% of the total peak electricity demand reduction in USA [14]. Up to now, many research efforts have focused on developing different incentive-based DR programs. Rahmani-Andebili established a nonlinear incentive-based DR model and a nonlinear price-based DR model which were implemented in four different power markets [15]. It revealed that the DR programs can shift part of the electricity demand and save energy, while may lead to different demand pattern with different responsive load behavioral model. In Ref. [16], a nonlinear incentive-based DR and TOU-based DR were used in unit commitment problem by considering the nonlinear behaviors of residential customers. Erdinc et al. [17] proposed a credits-based incentive approach for EUs to decrease the critical load demands and maintain the balance between supply and demand during peak electricity demand periods, wherein the uncertainty of the ambient temperature variations were taken into account. Li et al. [18] developed a dynamic coupon incentive-based DR program for distributed energy system with multiple load aggregators, and a fairness function was defined to guarantee that aggregators are rewarded. In Ref. [19], an improved incentive-based DR model was presented, in which the elasticity depends not only on the electricity price, but also on time and customer type. Besides, Yu et al. [20] proposed an incentive-based DR model from the perspective of GO to dispatch DR resources, and then a two-loop Stackelberg game was constructed to capture interactions among GO, ESP, and EUs. In addition, in Ref. [21], the incentives for drivers of plug-in electric vehicles were optimized by fleet management, and the charging demand was transferred to off-peak period from peak period. However, most of the existing related studies are based on traditional model-based methods, including stochastic programming, game theory, and mixed integer linear programming. It is difficult to choose appropriate models for an actual energy system and identify corresponding parameters that are EUs-dependent. Besides, many assumptions were made in these model-based methods which may be not applicable to real-world situations. In addition, few studies have considered the uncertainty of both electricity price and power load when developing incentive-based DR program. Therefore, some traditional models may be ineffective in volatile market environment. Also, some existing research work just focused on a single EU and ignored the impact of multiple EUs with different characteristics on the incentive-based DR. In recent years, artificial intelligence (AI) based methods have been widely used in decision making problems [22]. Reinforcement learning (RL) is a typical AI-based method, which has excellent performance in solving the problem of maximizing returns or achieving specific goals through learning strategies in the interaction between agents and environment [23]. RL is a model-free algorithm, and it has been widely used in smart energy management [22,24]. For example, in Ref. [25], RL was applied to control the building climate under dynamic pricing, in which the sequential decision making problem was converted to a Markov decision problem. Arif et al. [26] investigated the load scheduling of plug-in electric vehicles using RL considering different dynamic price schemes, thereby to minimize the total energy costs while meeting the electricity demand of users. Wang et al. [27] proposed a RL-based model to investigate the optimal energy trading among microgrids, where each microgrid chooses a strategy individually and randomly to trade the energy in an independent market and maximizes its average revenue. In addition, Mahapatra et al. [28] developed an improved RL algorithm to manage home appliances, with the aim of reducing the power load during peak period, promoting energy conserving, and reducing the carbon footprint of residential dwellings. In Ref. [29], a multi-agents RL was developed for a real-world smart grid scenario in which the forecasting method was used to identify non-stationary electricity demand of EUs. To deal with the uncertainty of electricity prices, Lu et al. [30] forecasted market price using artificial neural network (ANN), and then a multi-agents RL was used to make optimal decisions for the operation of different home appliances. Similarly, in Ref. [31], the power load and wholesale electricity price were forecasted using ANN, and then the optimal incentives were acquired by RL based on the forecasting results. However, few of above studies have considered the uncertainties of users\u2019 load demand and the power purchase cost of ESP at the same time. The forecasting methods in these works also have certain limitation in obtaining more accurate results. Besides, the DERs and their uncertainties were rarely taken into account when developing incentive-based DR models. Therefore, to bridge these research gaps, this study proposed an incentive-based DR model based on modified deep learning (MDL) and RL, enabling the ESP to get required DR resources with minimum costs and reducing the electricity bills of EUs. As a result, it can promote supply-demand balance and improve power system reliability. To reduce the uncertainties of external environment, a modified deep learning model based on recurrent neural network (MDL-RNN) was developed to forecast day-ahead wholesale electricity price, PV power output, and power load respectively. Then, RL was used to obtain the optimal incentive rate for each EU while maximizing the total profits of ESP and EUs. The contributions of this study are as follows: (1) An incentive-based DR model based on MDL and RL was proposed and the optimal incentive rate at each hour can be autonomously learned by the interactions between the ESP and EUs; (2) The uncertainties of environment were considered by accurate forecasting of the day-ahead wholesale market price, PV power output, and EUs power load with the proposed MDL-RNN model, which achieved better performance; (3) The diversity of EUs was taken into consideration and a theoretical proof on the relationship between the attitudes of EUs towards energy saving and the optimal incentive rates was given; (4) A short-term DR program was presented for peak electricity demand period to enhance the security of power system operation. The remainder of the study is organized as follows. Section 2 presents the incentive-based DR model. Section 3 introduces the proposed MDL-RNN model for forecasting wholesale market price, PV power output, and EUs\u2019 power load. Section 4 provides the RL method to determine the optimal incentive rates at each hour. The experimental results and discussions are given in Section 5. Section 6 presents the conclusions. 2 Demand response model Fig. 1 shows the schematic of a hierarchical electricity market. There are mainly three kinds of participators in the electricity market, i.e. GO, ESP, and EUs. ESP purchases electricity from GO according to wholesale electricity price, and then sells electricity to EUs at retail electricity price. Meanwhile, ESP has to help GO to ensure electricity supply-demand balance and reduce peak electricity demand while pursuing maximum profit. As shown in Fig. 1, the incentive-based DR program is implemented in retail market to reduce peak electricity demand for the better balance of supply and demand, while maximizing the total profits of ESP and EUs. The solar power also was considered in the incentive-based DR program. 2.1 Energy service provider\u2019s profits By giving EUs certain rewards, ESP can procure required DR resources from EUs, and reduce the cost of electricity purchasing from wholesale market. Here, the reduced electricity purchase cost minus the rewards for EUs is regarded as the profit of ESP, as described in Eq. (1). Therefore, ESP can obtain maximum profits by setting optimal incentive rates for EUs. (1) p r o f i t e s p = ∑ i = 1 n ∑ j = 1 h ( p j − α i j ) Δ E i j where i represents the i-th EU, n is the total number of EUs, j denotes j-th hour, h is the last hour of a day, p j is the wholesale electricity price at hour j, Δ E i j is the reduced electricity demand of user i at hour j in response to the incentives, and α i j is the incentive rate for EU i at hour j. In addition, α i j cannot be less than α min or exceed α max , and this constraint is usually determined by electricity trading market and regulatory authority [32]. 2.2 End users\u2019 profits EUs can get rewards when they response to the incentive of ESP to reduce electricity demand, but they will also have to bear the discomfort caused by the reduction of electricity demand. Hence, as shown in Eq. (2), the profits of EUs mainly come from the difference between the electricity reduction rewards and the discomfort cost, and the income that EUs sell their residual solar power in wholesale electricity market. In particular, EUs were assumed to first consume solar power, and the incentive rate is set to 0 when EUs\u2019 electricity demand can be met by solar power. (2) p r o f i t e u = ∑ i = 1 n ∑ j = 1 h [ λ i ⋅ α i j ⋅ Δ E i j − ( 1 − λ i ) ⋅ c o s t i j ( Δ E i j ) + p j ⋅ P V i j ] (3) Δ E i j = E i j ⋅ ξ j ⋅ α i j − α min α min In Eq. (2), λ is the weight parameter which represents the attitude of EUs towards incentive reward and discomfort cost. A small λ i denotes that the EU i prefer comfort than incentive reward. In contrast, a big λ i represents that the EU i believe that incentive reward is more important than comfort. c o s t i j ( Δ E i j ) is the discomfort cost of EU i at hour j when the electricity demand of EU i is reduced by Δ E i j , and PV ij represents the amount of solar power sold to GO by EU i at hour j. Here, p j is the tariff of solar power feed-in to power system and is set to be equal to wholesale electricity price in this study. In Eq. (3), E i j is the actual electricity demand of EU i at hour j, ξ j is the elasticity coefficient that represents the ratio of electricity demand variation to incentive variation [33]. In addition, the electricity demand reduction Δ E i j should be within a range [34]. It cannot exceed the upper bound Δ E max and be less than lower bound 0. Δ E max is determined by the characteristics of EUs and the capacity of power generation. The discomfort cost of EU i at hour j is a quadratic function of Δ E i j , which is defined as Eq. (4) [35]. (4) c o s t i j ( Δ E i j ) = μ i 2 ( Δ E i j ) 2 + ω i ⋅ Δ E i j In Eq. (6), μ i and ω i are discomfort parameters. They are positive and EUs-dependent [20]. For the same amount of electricity reduction, the discomfort degree of different EUs may be different. This is due to that different EUs have different household appliances and electricity consumption characteristics. Bigger μ i and ω i mean that EU i will suffer from more discomfort even when reducing the same electricity demand as EUs who have smaller μ and ω. Next, the objective of the DR model is to maximize the total profits of ESP and EUs, as shown in Eq. (5). (5) max ( p r o f i t e s p + p r o f i t e u ) Then, the day-ahead incentive rates at each hour for every EU were optimized by MDL-RNN and RL. 3 Modified deep learning model for forecasting To overcome the uncertainties of environment, an MDL-RNN model which has good forecasting performance, was proposed to forecast wholesale electricity price, PV power output, and EUs power load respectively. 3.1 Recurrent neural network There have been some many research efforts on time series forecasting [36,37]. As a variant of ANN, recurrent neural network (RNN) is a recursive neural network which adopts sequence data as input, and it has been more and more used in time series forecasting [38]. RNN has the property of memory, parameters sharing, and Turing completeness, so it can learn the non-linear characteristics of time series data with high efficiency [39]. However, simple RNN is vulnerable to gradient explosion or vanishing during training. To deal with these problems, some novel cells were proposed to replace original neurons in RNN, such as long short-term memory (LSTM) unit [40] and gated recurrent unit (GRU) etc. [41]. 3.2 Modified deep learning model based on RNN (MDL-RNN) Considering the superior ability of deep learning model in modeling nonlinear relationship and the excellent performance of RNN in learning time dependencies, an MDL-RNN model is proposed to forecast wholesale market price, PV power output, and EUs power load. 3.2.1 Inputs and model structure The selection of input variables is critical for improving the forecasting accuracy [42]. In this paper, the inputs of the MDL-RNN model were chosen based on the guideline of previous work [43], and they were also limited by the availability of related data. The inputs include three kinds of variables: time variables (month, week, day, hour, and holiday), environment variables (temperature, humidity, wind speed, global horizontal radiation, and diffuse horizontal radiation), and historical variable. The inputs of the MDL-RNN model for forecasting different targets are shown in Table 1 . To obtain more accurate forecasting results, the MDL-RNN adopts a 5-layers network which includes one input layer, two GRU-RNN layers, one simple hidden layer, and one output layer. It has been demonstrated that multi-layers networks usually have better forecasting performance [44]. The input layer has 24 input vectors which once adopts 24-h time series data, and each input vector includes time variables, environment variables, and historical variable. This has improved forecasting accuracy because the periods of wholesale electricity price, PV power output, and EUs power load are 24-h. 3.2.2 Model setup In order to obtain better forecasting results, some setups were made in the training process of MDL-RNN model. First, the training data was preprocessed by min-max normalization to eliminate dimension and improve calculation efficiency [45]. For a given variable x, its normalization can be expressed as (6) x k \u2032 = x k − x min x max − x min where x k is a value of variable x, x min is the maximum value of x, and x max is the minimum value of x. Then, weight decay regularization was used to solve the overfitting problem by adding regularization term to cost function [46]. Meanwhile, dropout was also employed in the MDL-RNN model [47]. At last, the Adam gradient descent algorithm was used to train the MDL-RNN model through back-propagation due to its fast convergence speed [48]. In addition, there are some other hyper-parameters that need to be set, such as neuron number of layer 2 and layer 3, the neurons type of layer 2 and layer 3, the activation function of layer 4, and the dropout of layer 2, layer 3, and layer 4. Table 2 shows the range of these hyper-parameters. Next, a global optimized method Hyperopt was used to determine the most suitable value of hyper-parameters until the optimal MDL-RNN model was obtained. 3.2.3 Modified forecasting results The forecasting results affect the optimization of incentive rates. However, absolutely accurate forecasting results cannot be obtained. Therefore, a modified method was employed to further improve the forecasting performance. As shown in Eq. (7), Δ t was assumed to obey normal distribution. (7) Δ t = y t , t r u e − y t , f o r e c a s t y t , f o r e c a s t ∼ N ( μ , σ 2 ) Then, the modified forecasting results can be obtained as shown in Eq. (8). (8) y t , t r u e = ( 1 + Δ t ) × y t , f o r e c a s t = E [ ( 1 + Δ t ) × y t , f o r e c a s t ] = E [ ( 1 + Δ t ) × y t , f o r e c a s t ] = ( 1 + μ ) × y t , f o r e c a s t In real scenarios, the final forecasting model was obtained by learning from historical data. When the related variables are input into the MDL-RNN model, the future targets (i.e. wholesale market price, PV power output, and power load) can be output. However, the actual future targets cannot be acquired in advance, and thus the distribution of Δ t cannot be identified. Therefore, the distribution of Δ t in training process was used to replace it. 3.2.4 Evaluation metrics The forecasting results were evaluated by two common metrics, i.e. mean absolute error (MAE) and mean absolute percentage error (MAPE). Their definitions are shown in Eq. (9) and Eq. (10) respectively. (9) MAE = ∑ t = 1 T | y t , t r u e − y t , f o r e c a s t | T (10) MAPE = 100 % T ∑ t = 1 T | y t , t r u e − y t , f o r e c a s t y t , t r u e | In Eq. (9) and Eq. (10), t represents the time step, T is the total time step, y t , t r u e is the true value at time step t, and y t , f o r e c a s t is the forecasting value at time step t. 4 Reinforcement learning for incentive rates optimization As an agent-based machine learning method, RL can learn the optimal actions (i.e. optimal policy) by the iterations between agent and environment. With the optimal policy, the agent can get the biggest reward. In this paper, RL was used to explore the optimal incentive rates at each hour of a day to obtain the maximal total profits of ESP and EUs. Fig. 2 shows the schematic of RL to find the optimal incentive rates. In Fig. 2, the agent represents ESP and the environment represents EUs. When ESP gives EUs incentive (i.e. action), EUs response to the incentive and reduce their electricity demand. Then, ESP will get the reduced electricity demand from EUs (i.e. state), and the profits of ESP and EUs (i.e. reward) can be obtained. Then, the iterations will continue until reaching the maximal profits of ESP and EUs. Generally, RL can be formalized as a Markov Decision Process (MDP) which contains three elements: state S i j ∈ S ( Δ E i j ) , action A i j ∈ A ( α i j ) , and reward R i j ( S i j , A i j ) , where i is the i-th EU, j is the j-th hour of a day, S i j is the reduced electricity demand of EU i at hour j, A i j is the incentive rate for EU i at hour j, and R i j ( S i j , A i j ) is the current reward of EU i at hour j. In RL model, the state transition only relies on the current state and current action, and thus the profits and the electricity demand reduction only rely on the current incentive rate. Then, the MDP can be expressed as Eq. (11) in which H denotes the final hour of a day, R i 1 ( S i 1 , A i 1 ) is the reward of EU i at hour 1, and R i h ( S i h , A i h ) is the reward of EU i at the final hour of a day. (11) S i 1 , A i 1 , R i 1 ( S i 1 , A n 1 ) ; S i 2 , A i 2 , R i 2 ( S i 2 , A i 2 ) ⋯ ⋯ S i , h , A i , h , R i h ( S i h , A i h ) . Considering the long-term returns, future reward has to be taken into account besides current reward [24]. The future reward will decay at a discount rate ρ , so the cumulative discounted reward of EU i at the first hour and hour l can be described as Eq. (12) and Eq. (13) respectively. (12) R i 1 = R i 1 ( S i 1 , A i 1 ) + ρ ⋅ R i 2 ( S i 2 , A i 2 ) + ⋯ + ρ h − 1 ⋅ R i h ( S i h , A i h ) (13) R i l = R ( S i l , A i l ) + ρ ⋅ R ( S i , l + 1 , A i , l + 1 ) + ⋯ + ρ h − l ⋅ R ( S i h , A i h ) In Eq. (12) and Eq. (13), ρ ∈ [ 0,1 ] indicates that agent pursues current reward or strive for future reward. When ρ = 0 , the agent only consider the current reward, and when ρ > 0 the agent will consider both current and future rewards. In this paper, ρ is set as 0.9 which is a common value in RL modeling [49]. R n l is the reward of EU i at hour l, S i l is the electricity demand reduction of EU i at hour l, A i l is the incentive rate for EU i at hour l, and R ( S i l , A i l ) is the current reward of EU i at hour l. The solution of MDP is to find the optimal policy which can maximize the cumulative discounted reward, and then the optimal actions and states corresponding to the optimal policy can be obtained. Therefore, Eq. (12) can be transformed into Eq. (14). (14) R i j = R ( S i j , A i j ) + ρ ⋅ max R i , j + 1 Eq. (14) satisfies the Bellman equation which is usually solved by finding approximate solution [50]. The approximate solution can be found through policy based approaches (e.g. policy gradient algorithm) or value based approaches (e.g. Q-learning and Sarsa) [51]. Some other methods combining policy gradient based algorithm and value based algorithm can also solve the Bellman equation (e.g. Actor-Critic) [52]. In addition, these methods can be divided into model-based approach and model-free approach according to whether the dynamics of the system (i.e. transition probabilities between states) are known [53]. In the model-free method, the agent finds the optimal policy without determining transition probabilities between the states, but the model-based method is on the contrary. As for the RL model in this paper, the dynamics of the system are known. Thus, model-free method is more suitable to solve the model. Q-learning is a model-free and off-policy method which has been widely used to solve RL model due to its simplicity [54]. Besides, it can learn from environment directly without knowing the environment, and that is why Q-learning was chosen to solve the proposed RL model. In a simple Q-learning example, a table is established and the state-action values (i.e. Q-values) are stored in it. For a Q-value Q ( S i j , A i j ) , it will be updated at each iteration to optimize the result until acquiring the maximum discounted reward R i j . Then, Eq. (14) can be transformed into Eq. (15). (15) Q i j = Q ( S i j , A i j ) + ρ ⋅ max Q i , j + 1 At each hour, the ESP provides an incentive rate for EUs. EUs will reduce their electricity demand for rewards, and then the corresponding Q-value (i.e. action and state) will be updated as Eq. (16). (16) Q i j = ( 1 − θ ) Q i j + θ [ Q ( s i j , a i j ) + ρ ⋅ max Q i , j + 1 ] In Eq. (16), θ ∈ [ 0,1 ] is the learning rate which represents to what extent the new knowledge overrides old knowledge [24]. If θ = 0 , the agent learns nothing. If θ = 1 , all previous knowledge is lost. To balance the old knowledge and new knowledge, θ should be set as decimal between 0 and 1. In practice, θ is usually set to 0.1. After several iterations, the Q-value will converge to the optimal value which corresponds to the optimal policy of MDP. Then, the optimal incentive rates at each hour for every EU can be obtained. The algorithm of the proposed incentive-based DR program based on MDL and RL (IDR-MDLRL) is shown in Fig. 3 . As shown in Fig. 3, the modified forecasting results will be input into RL model to overcome the uncertainties of the environment. In the RL model, the action was chosen by ε-greedy policy which can realize exploration and exploitation mechanism. It is because that the agent cannot acquire maximum reward by only exploiting the already known knowledge. The agent is supposed to explore new knowledge for better reward. ε is generally set to a decimal between 0 and 1 [55]. A big ε denotes that the agent tends to explore new actions, and a small ε means that agent tends to exploit current actions. ε was set to 0.1 in the proposed IDR-MDLRL model as it was a widely used value in RL modeling [56]. 5 Results and discussions 5.1 Data The experimental data were all obtained from public data sources. The power load data comes from Dataport which provides the data that ranges from electricity market operations to appliance-level EUs behavioral research [57]. The building types of EUs include apartment, mobile home, single-family home, sales and town home. The hourly load data (i.e. average load in an hour) from January 1, 2018 00:00 am to July 29, 2018 23:00 pm of three users in Austin, Texas, USA was chosen randomly for experiments. Meanwhile, the environment data was acquired from Mesowest which provides free detailed environment data throughout the USA [58]. The training period of load forecasting is from January 1, 2018 00:00 am to July 22, 2018 23:00 pm, and the testing period is from July 23, 2018 00:00 am to July 29, 2018 23:00 pm. The hourly wholesale electricity price data (i.e. average price in an hour) was obtained from PJM by Data Miner 2 [59]. PJM is one of the electric industry leaders in reliable operations and efficient wholesale electricity markets in the USA. It provides rich data sources about electric power system operation and wholesale electricity markets. The wholesale electricity price data from January 1, 2018 00:00 am to July 29, 2018 23:00 pm was used in the wholesale electricity price forecasting. The training period and testing period division is the same as that in power load forecasting. DKA Solar Center is a demonstration facility for commercialized solar technologies operating in the arid solar conditions of Alice Springs, Central Australia [60]. It provides free access to PV power output data and related environment data for researchers all over the world. The hourly solar power output data (i.e. average output in an hour) of a PV panel whose rated output power is 5.5 kW was used in the experiments, and the division of training and testing data is the same as that in the forecasting of load and wholesale electricity price. It should be pointed out that the hourly data represents the average value in each hour. Meanwhile, although wholesale electricity price, PV power output, and power load data come from different data sources, the experiment results will not be affected as they are only used to simulate real-world situations. 5.2 Modified deep learning-based forecasting results In this section, the proposed MDL-RNN model was used to forecast wholesale electricity price, PV power output, and EUs\u2019 power load respectively. After training and testing, we obtained the optimal forecasting model which has the minimum forecasting errors. Then, the modified method was used to further improve forecasting accuracy. Fig. 4 (a)-(c) are the distributions of Δ t in forecasting wholesale electricity price, PV power output, and EU 1\u2019s power load. It can be seen from Fig. 4 that Δ t generally obey normal distribution. By using more historical data to train the MDL-RNN model, the distribution of Δ t will be more stable and the forecasting can be further improved. Fig. 5 shows the forecasting results of wholesale electricity price from July 23, 2018 to July 29, 2018. Fig. 6 shows the forecasting results of PV power output from July 23, 2018 to July 29, 2018. Fig. 7 (a)-(c) presents the load forecasting results of three different EUs from July 23, 2018 to July 29, 2018. Table 3 shows the evaluation results of MDL-RNN in forecasting wholesale electricity price, PV power output, and EUs power load by two common metrics (i.e. MAE and MAPE). It should be noted that we just calculate the MAPE of PV power output at daytime when PV system is on operation. As shown in Fig. 5 and Table 3, the forecasting errors of wholesale electricity price are small, although there are many fluctuations in the profile. From Fig. 6, it can be found that the PV power output present periodicity. It increases smoothly with the enhancement of illumination and reaches the maximum power output at around 13:00 pm when sunlight is the strongest. Besides, we find from Table 3 that the MDL-RNN model achieved best performance (MAE: 0.11, MAPE: 0.039) in forecasting PV power output as its profiles are smoother and more regular than other profiles. From Fig. 7, it can be seen that the power loads of these three EUs are of high volatility and show different characteristics. Meanwhile, there are basically two load peaks in the morning and evening over which EUs tend to consume more electricity due to their living needs. We can also find from Table 3 that the forecasting errors are small in forecasting the power load of different EUs. It illustrates that the MDL-RNN model has great capability in forecasting complex and nonlinear power load. In addition, compared with the forecasting in Ref. [31], the proposed MDL-RNN method achieve less MAE value. Table 3 shows that the MDL-RNN model performs well in forecasting wholesale electricity price, PV power output, and EUs\u2019 power load. At the same time, the MDL-RNN model is superior to conventional methods, such as simple ANN, support vector machine (SVM), and extreme learning machine (ELM). It can learn the time dependencies and nonlinearity in time series data. In addition, it can be noted that the MDL-RNN model achieves better performance in forecasting PV power output and wholesale electricity price than EUs\u2019 power load. This is due to the fact that EUs\u2019 power load is of higher volatility and fluctuation which will increase the difficulty in learning the relationship between the input variables and the output power load. 5.3 Incentive rate optimization based on reinforcement learning The day-ahead forecasting results were regarded as the inputs of the RL model to reduce the impact of environment uncertainties. But the forecasting hourly PV power output and EUs\u2019 power load data have to be first converted to hourly power generation and hourly electricity demand data. In this section, the forecasting results on July 23, 2018 were selected as a detailed case study. The incentive rates at each hour were optimized by the proposed RL model for each EU to maximize the total profits of ESP and EUs. 5.3.1 Parameters setup Table 4 shows the parameters of RL model including the discomfort parameters, the upper bound of electricity reduction, the minimum incentive rate, and the maximum incentive rate, which were referenced from Refs. [20]. Table 5 presents the electricity elasticity at different hours [61]. The electricity elasticity reflects the impact of incentive variation on electricity demand variation. The elasticity period can be divided into three parts corresponding to valley, mid-peak, and peak periods respectively. It should be noted that the values of parameters will not affect the mechanism of our RL model in essence. 5.3.2 Convergence of Q-value During the iterations of RL, Q-value will gradually converge to the maximum value which corresponds to the maximum profits of ESP and EUs. Fig. 8 shows the Q-value profile of EU 2 to acquire optimal incentive rates under different λ. As shown in Fig. 8, the start Q-value is very small as the agent has very limited knowledge on choosing the best actions which will bring optimal reward. After several iterations, the agent can learn from previous experience to determine the optimal action and the Q-value tends to be stable. It can be also found from Fig. 8 that the optimal Q-value will grow with the increase of λ. It is because that EU places a higher premium on the reward than discomfort cost when λ is larger, and thus the total profits of ESP and EUs increase with λ. Fig. 9 (a)-(b) shows the convergence of Q-value for different EUs. When λ=0.9, EUs are willing to reduce their electricity demand to obtain rewards and even almost neglect the incurred discomfort costs. It can be seen from Fig. 9 that the maximum Q-value of EU 2 (μ 2 = 2, ω 2 = 1) is larger than that of others. It is because that the discomfort cost paprameter μ 2 is less than that of EU 3 (μ 3 = 3). Meanwhile, the overall electricity consumption of EU 2 is relatively higher than that of others. Hence, EU 2 has more poetntial to response to incentives and reduce their electricity demand for the rewards. When λ=0.1, the EUs place higher premium on discomfort cost than the reward provided by ESP. This leads to less electricity demand reduction and small Q-value as shown in Fig. 9. Moreover, the discomfort cost has more influence on the profits of EUs under this circumstance. Thereby, it can be found that the maximal Q-value of EU 1 is more than that of EU 2. In addition, from Figs. 8 and 9, it can be seen that Q-value follows a fluctuating ascending trend, and still fluctuates when converging to optimal Q-value. It is caused by the ε-greedy policy which makes the agent explore new knowledge while exploiting acquired konledge during iterations. The convergence of Q-value will be proofed theoretically in Appendix A.1. 5.3.3 Results of different EUs with different λ First, in order to explore how EUs response to the optimal incentive rate at each hour obtained by the proposed RL model, the incentive rate profiles and electricty demand reduction of different EUs with the same λ value (λ = 0.1) were presented in Fig. 10 . In Fig. 10, the blue line represents the optimal incentive rates, the red line is the day-ahead wholesale electricity price, the yellow part is the original electricity demand, and the green part denotes actual electricity consumption when the EUs response to the incentive-based DR program. It can be seen that the actual electricity demand is low for EU 1 and even equal to 0 for EU 2 and EU 3 at noon. It is because that each EU is assumed to install the same PV panels which can provide enough electricity for their usage and sell extra solar power in wholesale electricity market over that time period. Meanwhile, ESP will also not provide incentive for EUs when their actual electricity demand is 0. In addition, it can be expected that EU 3 will has less electricity demand reduction when it has same original electricity demand as EU 1 or EU 2. The reason is that EU 3 has larger discomfort parameter μ 3 = 3 which denotes that EU 3 possess more conservative attitude towards incentive reward. From Fig. 10, what can be also found is that the incentive rates vary with wholesale market price changes. During lower wholesale market price period, ESP will provide less incentive to reduce EUs\u2019 electricity demand. Nevertheless, electricity supply is insufficient over higher wholesale market price period, and ESP is more incline to induce EUs to reduce electricity demand by higher incentive rate. This will promote the reliability and stability of power system, and also bring certain profits for ESP and EUs. The objective of the proposed RL model is to maximize the total profits of ESP and EUs. This can balance the benefits of ESP and EUs and encourage EUs to participate into the incentive-based DR program. The cost benefit analysis of EUs and ESP was carried out as shown in Tables 6 and 7 respectively. In Table 6, profit 2 represents the total profits of EUs that is calculated by Eq. (2), and profit 1 equals profit 2 subtract the selling income of solar power. Since EUs first consume solar power and ESP provides the unmet electricity demand, the selling income of solar power is fixed for each EU with different λ. It can be seen that EU 3 gained the maximum income (100.22￠) by selling extra solar power to GO, and EU 1 obtained the minimum income (6.56￠) because its electricity demand is relatively higher during daytime. With the increase of λ, EUs prefer incentive reward to comfort, and they are more active to reduce electricity consumption. Therefore, it can be found that profit 1 and profit 2 of each EU are gradually increasing. Here, it can be noticed that the procured DR resources, incentive income, and discomfort cost do not increase when λ>0.5. It is because that the EUs prefer reward than comfort. This also conforms to the actual situation that EUs tend to enjoy better comfort than reward. Table 7 shows the profits of ESP which was calculated by Eq. (1). The gross income of DR means the reduced electricity purchase cost of ESP, and the cost of DR denotes the rewards for EUs in the incentive-based DR program. It can be seen that cost of DR grows with the increase of λ. However, with the increase of λ, ESP will get more DR resources and profits. At the same time, it can be found that the increase of ESP\u2019s profit is not obvious when λ changes from 0.5 to 0.9. In a real scenario, ESP will not raise the incentive rate anymore when the EUs place higher premium on comfort than reward. The detailed explanation will be given in next Section. 5.3.4 Results of same EU with different λ Fig. 11 shows the results of EU 2 adopting different λ 2 (0.1, 0.5, and 0.9). As we can see form Fig. 11, the profiles of incentive rate show the same trend as wholesale electricity price. A big λ 2 denotes that EU 2 pursues the reward provided by ESP. To improve the profits, ESP would raise the incentive rate to procure more DR resources. However, the ESP cannot further reduce the electricity demand if λ 2 > 0.5 as the EU obtained the maximal electricity reduction at each time step. At the same time, the ESP will not raise the incentive rate anymore. To further explore the relationship between responsive resources and λ 2, more values of λ 2 were tested and the cost benefit analysis of EU 2 is shown in Table 9. In Table 8 , it can be found that the incentive income and the discomfort cost of EU 2 are increasing with the increase of λ 2, but do not change when λ 2 is more than 0.6. However, the profit 1 and profit 2 always increase with λ 2. The profit 1 is negative when λ 2 < 0.6 . The reason is that the final discomfort cost is more than the final reward. As for ESP, it can be seen from Table 9 that the gross income of DR, cost, and profits stop increasing when λ 2 ≥ 0.6 as ESP cannot acquire more DR resources. This can be proved theoretically as shown in Appendix A.2. 5.3.5 Short-term incentive-based DR program Incentive-based DR programs are effective methods to reduce EUs\u2019 electricity demand during peak electricity demand period rather than all over a day. This contributes to promoting the balance between supply and demand and ensuring the security of power system operation in real time. Besides, more accurate results of short-term forecasting can be obtained as more accurate environmental variables in the next few hours can be acquired, such as temperature and light intensity. Therefore, a short-term DR program which can also be called an emergency DR program, was developed using the proposed IDR-MDLRL algorithm. Fig. 12 shows the actual load demand profiles of three EUs and their total load demand profile. As shown in Fig. 12, the load demands in daytime are low as the solar systems deployed in EUs side can provide enough solar power. It can be seen that the peak load demand occurs at evening corresponding to 17:00 pm - 22:00 pm. The ESP would like to reduce the total electricity demand to ensure the security of power system by providing rewards for EUs. Once receiving the incentive rates form ESP, EUs will response to short-term DR program and sacrifice a part of discomfort for the rewards. Besides, EUs are of great potential to response to DR program at that time due to the high electricity price. To guarantee the necessary electricity demand for normal life, they can shift the peak electricity demand to other periods. For example, EUs can schedule their washing machine to work at deep night rather than during the peak period. What should be noticed is that p min is the minimum wholesale market price over 17:00 pm - 22:00 pm, not the minimum value of the day. The benefits of ESP implementing the short-term incentive-based DR program are show in Table 10 . In the short-term DR program, we just considered the worst scenario, i.e. λ is set to 0.1 and μ is set to 3. In this scenario, EUs prefer comfort than the reward, and the unit discomfort cost is more than the unit reward incurred by the electricity demand reduction. The cost of DR represents the payments to EUs by ESP to obtain required DR resources. The cost without DR is the payments by ESP to GO for purchasing the same resources from GO. As it can be seen from Table 10, the cost for obtaining required resources was reduced by 25.472 ￠. Besides, the peak electricity demand which represents the maximal electricity demand during 17:00 pm - 22:00 pm, decreased to 8.869 kWh, almost a 17% reduction. The total electricity demand reduction also achieved a reduction of 12.354 kWh. It can be expected that higher reduction of peak electricity demand and total electricity demand can be achieved if other better scenarios are taken into consideration. 6 Conclusions This study proposed an incentive-based DR program based on deep learning and reinforcement learning for smart grid operation. The complexities and uncertainties of environment were considered by forecasting wholesale electricity price, PV power output, and power load with a DL-RNN model using a modified method. Then, a model-free method, RL, was employed to find the day-ahead optimal incentive rates at each hour for each EU. Particularly, a short-term incentive-based DR program was proposed to reduce electricity demand during peak electricity demand periods. The experimental results show that the peak electricity demand was reduced by 17%. This shows that the proposed incentive-based DR program contributes to balancing supply-demand and improving power system reliability. It also provides an effective way to implement incentive-based DR program in uncertain and dynamic environment. In future work, we will collect real-world data to quantify the parameters and investigate the relationships among EU-dependent parameters, socioeconomic backgrounds and weather conditions. In addition, the interactions among multiple ESPs, EUs and the electricity elasticity will be further explored. CRediT authorship contribution statement Lulu Wen: Conceptualization, Methodology, Data curation, Software, Visualization, Formal analysis, Writing - original draft. Kaile Zhou: Conceptualization, Methodology, Resources, Visualization, Writing - review & editing, Project administration, Supervision. Jun Li: Resources, Writing - review & editing. Shanyong Wang: Writing - review & editing. Declaration of competing interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgement This work is supported by the National Natural Science Foundation of China (No. 71822104), and the China Scholarship Council. Appendix A A. 1 The convergence of Q-value From Eq. (1), Eq. (3), Eq. (4), Eq. (6), and Eq. (9), the total profits of EUs and ESP can be obtained as follows. p r o f i t s u m = ∑ i = 1 n ∑ j = 1 h [ ( p j − α i j ) Δ E i j + λ i ⋅ α i j ⋅ Δ E i j − ( 1 − λ i ) ⋅ [ μ i 2 Δ E i j 2 + ω i ⋅ Δ E i j ] + p j ⋅ P V i j ] = ∑ i = 1 n ∑ j = 1 h [ ( p j − α i j ) E i j ⋅ ξ j ⋅ ( α i j − α min ) α min + λ i ⋅ α i j ⋅ E i j ⋅ ξ j ⋅ ( α i j − α min ) α min − ( 1 − λ i ) ⋅ [ μ i 2 ⋅ E i j 2 ⋅ ξ j 2 ⋅ ( α i j − α min ) 2 α 2 min + ω i E i j ⋅ ξ j ⋅ ( α i j − α min ) α min ] + p j ⋅ P V i j ] = ∑ i = 1 n ∑ j = 1 h { − [ E i j ⋅ ξ j ⋅ ( 1 − λ i ) α min + μ i 2 E i j 2 ⋅ ξ j 2 ⋅ ( 1 − λ i ) α 2 min ] α i j 2 + [ E i j ⋅ ξ j ⋅ p j α min + E i j ⋅ ξ j ⋅ α min ⋅ ( 1 − λ i ) α min + μ i ⋅ E i j 2 ⋅ ξ j 2 ⋅ ( 1 − λ i ) α min − ω i ⋅ E i j ⋅ ξ j ⋅ ( 1 − λ i ) α min ] α i j + [ ω i ⋅ E i j ⋅ ξ j ⋅ ( 1 − λ i ) − E i j ⋅ ξ j ⋅ p j − μ i 2 E i j 2 ⋅ ξ j 2 ⋅ ( 1 − λ i ) + p j ⋅ P V i j ] } Thus, the total profits of EUs and ESP is a quadratic function of incentive rate α i j . Since 1 > λ i > 0,1 − λ > 0 , α min > 0 , E i j > 0 , ξ j > 0 , p j > 1 , μ i > 0 , ω i = 1 , it can be easily obtained that A = − [ E i j ⋅ ξ j ⋅ ( 1 − λ i ) α min + μ i 2 E i j 2 ⋅ ξ j 2 ⋅ ( 1 − λ i ) α min 2 ] < 0 B = [ E i j ⋅ ξ j ⋅ p j α min + E i j ⋅ ξ j ⋅ α min ⋅ ( 1 − λ i ) α min + μ i ⋅ E i j 2 ⋅ ξ j 2 ⋅ ( 1 − λ i ) α min − ω i ⋅ E i j ⋅ ξ j ⋅ ( 1 − λ i ) α min ] > 0 − B 2 A > 0 Therefore, the opening of the parabola is down, and the symmetry axis is on the right. From above, it can be found that the total profits of EUs and ESP increase with incentive rates and then decrease with incentive rates. In other words, the total profits can get the maximum value within the range of incentive rates, and thus the Q-value will converge to optimal value. A. 2 The discomfort cost do not change any more when λ 2 > 0.6 From Eq. (2), Eq. (4), and Eq. (5), it can be obtained that 0.3 p min ≤ α i j ≤ p min and 0 ≤ Δ E i j ≤ 0.3 E i j , thus 0 ≤ E i j ⋅ ξ j ⋅ α i j − α min α min ≤ 0.3 E i j . Therefore, 0.3 p min ≤ α i j ≤ ( 0.3 ξ j + 1 ) ∗ 0.3 p min . From above, it can be seen that the incentive rate α i j is within certain range. When λ i is growing, it means that EU i regard incentive reward as more important than comfort. Therefore, in the learning of RL, the agent will improve incentive rate at each hour to acquire more DR resources for rewards. But α i j has reached the maximum value when λ 2 ≥ 0.6 , and thus the DR resources, incentive income, and discomfort cost which just correlate with α i j , will not change as shown in Table 8. This has also proved the results in Section 5.3.3 where the increase of ESP\u2019s profit is not obvious when λ changes from 0.5 to 0.9. References [1] M.A.F. Ghazvini P. Faria S. Ramos H. Morais Z. Vale Incentive-based demand response programs designed by asset-light retail electricity providers for the day-ahead market Energy 82 2015 786 799 Ghazvini MAF, Faria P, Ramos S, Morais H, Vale Z. Incentive-based demand response programs designed by asset-light retail electricity providers for the day-ahead market. Energy. 2015;82:786-799. [2] T. Khalili A. Jafari M. Abapour B. Mohammadi-Ivatloo Optimal battery technology selection and incentive-based demand response program utilization for reliability improvement of an insular microgrid Energy 169 2019 92 104 Khalili T, Jafari A, Abapour M, Mohammadi-Ivatloo B. Optimal battery technology selection and incentive-based demand response program utilization for reliability improvement of an insular microgrid. Energy. 2019;169:92-104. [3] Z-k Feng W-j Niu X. Cheng J-y Wang S. Wang Z-g Song An effective three-stage hybrid optimization method for source-network-load power generation of cascade hydropower reservoirs serving multiple interconnected power grids J Clean Prod 246 2020 119035 Feng Z-k, Niu W-j, Cheng X, Wang J-y, Wang S, Song Z-g. An effective three-stage hybrid optimization method for source-network-load power generation of cascade hydropower reservoirs serving multiple interconnected power grids. Journal of Cleaner Production. 2020;246:119035. [4] Z-k Feng W-j Niu C-t Cheng J-z Zhou Peak shaving operation of hydro-thermal-nuclear plants serving multiple power grids by linear programming Energy 135 2017 210 219 Feng Z-k, Niu W-j, Cheng C-t, Zhou J-z. Peak shaving operation of hydro-thermal-nuclear plants serving multiple power grids by linear programming. Energy. 2017;135:210-219. [5] H.T. Haider O.H. See W. Elmenreich A review of residential demand response of smart grid Renew Sustain Energy Rev 59 2016 166 178 Haider HT, See OH, Elmenreich W. A review of residential demand response of smart grid. Renewable and Sustainable Energy Reviews. 2016;59:166-178. [6] M. Yu S.H. Hong Supply\u2013demand balancing for power management in smart grid: a Stackelberg game approach Appl Energy 164 2016 702 710 Yu M, Hong SH. Supply-demand balancing for power management in smart grid: A Stackelberg game approach. Applied Energy. 2016;164:702-710. [7] M. Diekerhof F. Peterssen A. Monti Hierarchical distributed robust optimization for demand response services IEEE Transactions on Smart Grid 9 2018 6018 6029 Diekerhof M, Peterssen F, Monti A. Hierarchical distributed robust optimization for demand response services. IEEE Transactions on Smart Grid. 2018;9:6018-6029. [8] X. Yan Y. Ozturk Z. Hu Y. Song A review on price-driven residential demand response Renew Sustain Energy Rev 96 2018 411 419 Yan X, Ozturk Y, Hu Z, Song Y. A review on price-driven residential demand response. Renewable and Sustainable Energy Reviews. 2018;96:411-419. [9] M. Rahmani-Andebili H. Shen Energy management of end users modeling their reaction from a GENCO\u2019s point of view International conference on computing, networking and communications (ICNC) 2017 IEEE 577 581 2017 Rahmani-Andebili M, Shen H. Energy management of end users modeling their reaction from a GENCO\u2019s point of view. 2017 International Conference on Computing, Networking and Communications (ICNC): IEEE; 2017. p. 577-581. [10] H.J. Monfared A. Ghasemi A. Loni M. Marzband A hybrid price-based demand response program for the residential micro-grid Energy 185 2019 274 285 Monfared HJ, Ghasemi A, Loni A, Marzband M. A hybrid price-based demand response program for the residential micro-grid. Energy. 2019;185:274-285. [11] D. Srinivasan S. Rajgarhia B.M. Radhakrishnan A. Sharma H. Khincha Game-Theory based dynamic pricing strategies for demand side management in smart grids Energy 126 2017 132 143 Srinivasan D, Rajgarhia S, Radhakrishnan BM, Sharma A, Khincha H. Game-Theory based dynamic pricing strategies for demand side management in smart grids. Energy. 2017;126:132-143. [12] A. Ghasemkhani L. Yang J. Zhang Learning-based demand response for privacy-preserving users IEEE Transactions on Industrial Informatics 15 9 2019 4988 4998 Ghasemkhani A, Yang L, Zhang J. Learning-based Demand Response for Privacy-Preserving Users. IEEE Transactions on Industrial Informatics. 2019; 15(9):4988-4998. [13] Y.-C. Li S.H. Hong Real-time demand bidding for energy management in discrete manufacturing facilities IEEE Trans Ind Electron 64 2016 739 749 Li Y-C, Hong SH. Real-time demand bidding for energy management in discrete manufacturing facilities. IEEE Transactions on Industrial Electronics. 2016;64:739-749. [14] A. Asadinejad K. Tomsovic Optimal use of incentive and price based demand response to reduce costs and price volatility Elec Power Syst Res 144 2017 215 223 Asadinejad A, Tomsovic K. Optimal use of incentive and price based demand response to reduce costs and price volatility. Electric Power Systems Research. 2017;144:215-223. [15] M. Rahmani-andebili Modeling nonlinear incentive-based and price-based demand response programs and implementing on real power markets Elec Power Syst Res 132 2016 115 124 Rahmani-andebili M. Modeling nonlinear incentive-based and price-based demand response programs and implementing on real power markets. Electric Power Systems Research. 2016;132:115-124. [16] M. Rahmani-Andebili Nonlinear demand response programs for residential customers with nonlinear behavioral models Energy Build 119 2016 352 362 Rahmani-Andebili M. Nonlinear demand response programs for residential customers with nonlinear behavioral models. Energy and Buildings. 2016;119:352-362. [17] O. Erdinc A. Taşcikaraoğlu N.G. Paterakis J.P. Catalão Novel incentive mechanism for end-users enrolled in DLC-based demand response programs within stochastic planning context IEEE Trans Ind Electron 66 2019 1476 1487 Erdinc O, Tascikaraoglu A, Paterakis NG, Catalao JP. Novel incentive mechanism for end-users enrolled in DLC-based demand response programs within stochastic planning context. IEEE Transactions on Industrial Electronics. 2019;66:1476-1487. [18] Z. Li S. Wang X. Zheng F. De Leon T. Hong Dynamic demand response using customer coupons considering multiple load aggregators to simultaneously achieve efficiency and fairness IEEE Transactions on Smart Grid 9 2016 3112 3121 Li Z, Wang S, Zheng X, De Leon F, Hong T. Dynamic demand response using customer coupons considering multiple load aggregators to simultaneously achieve efficiency and fairness. IEEE Transactions on Smart Grid. 2016;9:3112-3121. [19] E. Shahryari H. Shayeghi B. Mohammadi-Ivatloo M. Moradzadeh An improved incentive-based demand response program in day-ahead and intra-day electricity markets Energy 155 2018 205 214 Shahryari E, Shayeghi H, Mohammadi-Ivatloo B, Moradzadeh M. An improved incentive-based demand response program in day-ahead and intra-day electricity markets. Energy. 2018;155:205-214. [20] M. Yu S.H. Hong Incentive-based demand response considering hierarchical electricity market: a Stackelberg game approach Appl Energy 203 2017 267 279 Yu M, Hong SH. Incentive-based demand response considering hierarchical electricity market: A Stackelberg game approach. Applied Energy. 2017;203:267-279. [21] M. Rahmani-Andebili Planning and operation of plug-in electric vehicles 2019 Springer Rahmani-Andebili M. Planning and Operation of Plug-In Electric Vehicles: Springer; 2019. [22] G. Du Y. Zou X. Zhang T. Liu J. Wu D. He Deep reinforcement learning based energy management for a hybrid electric vehicle Energy 2020 117591 Du G, Zou Y, Zhang X, Liu T, Wu J, He D. Deep reinforcement learning based energy management for a hybrid electric vehicle. Energy. 2020:117591. [23] R.S. Sutton A.G. Barto Reinforcement learning: an introduction 2018 MIT press Sutton RS, Barto AG. Reinforcement learning: An introduction: MIT press; 2018. [24] J.R. Vázquez-Canteli Z. Nagy Reinforcement learning for demand response: a review of algorithms and modeling techniques Appl Energy 235 2019 1072 1089 Vazquez-Canteli JR, Nagy Z. Reinforcement learning for demand response: a review of algorithms and modeling techniques. Applied Energy. 2019;235:1072-1089. [25] G.T. Costanzo S. Iacovella F. Ruelens T. Leurs B.J. Claessens Experimental analysis of data-driven control for a building heating system Sustainable Energy, Grids and Networks 6 2016 81 90 Costanzo GT, Iacovella S, Ruelens F, Leurs T, Claessens BJ. Experimental analysis of data-driven control for a building heating system. Sustainable Energy, Grids and Networks. 2016;6:81-90. [26] A. Arif M. Babar T.I. Ahamed E. Al-Ammar P. Nguyen I.R. Kamphuis Online scheduling of plug-in vehicles in dynamic pricing schemes Sustainable Energy, Grids and Networks 7 2016 25 36 Arif A, Babar M, Ahamed TI, Al-Ammar E, Nguyen P, Kamphuis IR, et al. Online scheduling of plug-in vehicles in dynamic pricing schemes. Sustainable Energy, Grids and Networks. 2016;7:25-36. [27] H. Wang T. Huang X. Liao H. Abu-Rub G. Chen Reinforcement learning in energy trading game among smart microgrids IEEE Trans Ind Electron 63 2016 5109 5119 Wang H, Huang T, Liao X, Abu-Rub H, Chen G. Reinforcement learning in energy trading game among smart microgrids. IEEE Transactions on Industrial Electronics. 2016;63:5109-5119. [28] C. Mahapatra A. Moharana V. Leung Energy management in smart cities based on Internet of Things: peak demand reduction and energy savings Sensors 17 2017 2812 Mahapatra C, Moharana A, Leung V. Energy management in smart cities based on Internet of Things: Peak demand reduction and energy savings. Sensors. 2017;17:2812. [29] A. Marinescu I. Dusparic S. Clarke Prediction-based multi-agent reinforcement learning in inherently non-stationary environments ACM Trans Autonom Adapt Syst 12 2017 9 Marinescu A, Dusparic I, Clarke S. Prediction-based multi-agent reinforcement learning in inherently non-stationary environments. ACM Transactions on Autonomous and Adaptive Systems (TAAS). 2017;12:9. [30] R. Lu S.H. Hong M. Yu Demand response for home energy management using reinforcement learning and qrtificial neural network IEEE Transactions on Smart Grid 10 6 2019 6629 6639 Lu R, Hong SH, Yu M. Demand response for home energy management using reinforcement learning and qrtificial neural network. IEEE Transactions on Smart Grid. 2019;10(6): 6629-6639.. [31] R. Lu S.H. Hong Incentive-based demand response for smart grid with reinforcement learning and deep neural network Appl Energy 236 2019 937 949 Lu R, Hong SH. Incentive-based demand response for smart grid with reinforcement learning and deep neural network. Applied Energy. 2019;236:937-949. [32] X. Fang Q. Hu F. Li B. Wang Y. Li Coupon-based demand response considering wind power uncertainty: a strategic bidding model for load serving entities IEEE Trans Power Syst 31 2015 1025 1037 Fang X, Hu Q, Li F, Wang B, Li Y. Coupon-based demand response considering wind power uncertainty: A strategic bidding model for load serving entities. IEEE Transactions on Power Systems. 2015;31:1025-1037. [33] A. Asadinejad A. Rahimpour K. Tomsovic H. Qi C-f Chen Evaluation of residential customer elasticity for incentive based demand response programs Elec Power Syst Res 158 2018 26 36 Asadinejad A, Rahimpour A, Tomsovic K, Qi H, Chen C-f. Evaluation of residential customer elasticity for incentive based demand response programs. Electric Power Systems Research. 2018;158:26-36. [34] Y. Wang X. Ai Z. Tan L. Yan S. Liu Interactive dispatch modes and bidding strategy of multiple virtual power plants based on demand response and game theory IEEE Transactions on Smart Grid 7 2015 510 519 Wang Y, Ai X, Tan Z, Yan L, Liu S. Interactive dispatch modes and bidding strategy of multiple virtual power plants based on demand response and game theory. IEEE Transactions on Smart Grid. 2015;7:510-519. [35] M. Yu R. Lu S.H. Hong A real-time decision model for industrial load management in a smart grid Appl Energy 183 2016 1488 1497 Yu M, Lu R, Hong SH. A real-time decision model for industrial load management in a smart grid. Applied Energy. 2016;183:1488-1497. [36] Z-k Feng W-j Niu Z-y Tang Z-q Jiang Y. Xu Y. Liu Monthly runoff time series prediction by variational mode decomposition and support vector machine based on quantum-behaved particle swarm optimization J Hydrol 583 2020 124627 Feng Z-k, Niu W-j, Tang Z-y, Jiang Z-q, Xu Y, Liu Y, et al. Monthly runoff time series prediction by variational mode decomposition and support vector machine based on quantum-behaved particle swarm optimization. Journal of Hydrology. 2020;583:124627. [37] W-j Niu Z-k Feng Y-b Chen H-r Zhang C-t Cheng Annual streamflow time series prediction using extreme learning machine based on gravitational search algorithm and variational mode decomposition J Hydrol Eng 25 2020 04020008 Niu W-j, Feng Z-k, Chen Y-b, Zhang H-r, Cheng C-t. Annual streamflow time series prediction using extreme learning machine based on gravitational search algorithm and variational mode decomposition. Journal of Hydrologic Engineering. 2020;25:04020008. [38] T. Mikolov M. Karafiát L. Burget J. Černocký S. Khudanpur Recurrent neural network based language model Eleventh annual conference of the international speech communication association 2010 Mikolov T, Karafiat M, Burget L, Cernocky J, Khudanpur S. Recurrent neural network based language model. Eleventh Annual Conference of the International Speech Communication Association 2010. [39] Z. Yan J. Wang Model predictive control of nonlinear systems with unmodeled dynamics based on feedforward and recurrent neural networks IEEE Transactions on Industrial Informatics 8 2012 746 756 Yan Z, Wang J. Model predictive control of nonlinear systems with unmodeled dynamics based on feedforward and recurrent neural networks. IEEE Transactions on Industrial Informatics. 2012;8:746-756. [40] F.A. Gers J. Schmidhuber F. Cummins Learning to forget: continual prediction with LSTM 1999 Gers FA, Schmidhuber J, Cummins F. Learning to forget: Continual prediction with LSTM. 1999. [41] J. Chung C. Gulcehre K. Cho Y. Bengio Empirical evaluation of gated recurrent neural networks on sequence modeling 2014 arXiv preprint arXiv:14123555 Chung J, Gulcehre C, Cho K, Bengio Y. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:14123555. 2014. [42] Z. Guo K. Zhou X. Zhang S. Yang A deep learning model for short-term power load and probability density forecasting Energy 160 2018 1186 1200 Guo Z, Zhou K, Zhang X, Yang S. A deep learning model for short-term power load and probability density forecasting. Energy. 2018;160:1186-1200. [43] A. Rahman V. Srikumar A.D. Smith Predicting electricity consumption for commercial and residential buildings using deep recurrent neural networks Appl Energy 212 2018 372 385 Rahman A, Srikumar V, Smith AD. Predicting electricity consumption for commercial and residential buildings using deep recurrent neural networks. Applied Energy. 2018;212:372-385. [44] Y. Wang D. Gan M. Sun N. Zhang Z. Lu C. Kang Probabilistic individual load forecasting using pinball loss guided LSTM Appl Energy 235 2019 10 20 Wang Y, Gan D, Sun M, Zhang N, Lu Z, Kang C. Probabilistic individual load forecasting using pinball loss guided LSTM. Applied Energy. 2019;235:10-20. [45] S. Patro K.K. Sahu Normalization: a preprocessing stage 2015 arXiv preprint arXiv:150306462 Patro S, Sahu KK. Normalization: A preprocessing stage. arXiv preprint arXiv:150306462. 2015. [46] F. Girosi M. Jones T. Poggio Regularization theory and neural networks architectures Neural Comput 7 1995 219 269 Girosi F, Jones M, Poggio T. Regularization theory and neural networks architectures. Neural Computation. 1995;7:219-269. [47] N. Srivastava G. Hinton A. Krizhevsky I. Sutskever R. Salakhutdinov Dropout: a simple way to prevent neural networks from overfitting J Mach Learn Res 15 2014 1929 1958 Srivastava N, Hinton G, Krizhevsky A, Sutskever I, Salakhutdinov R. Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research. 2014;15:1929-1958. [48] D.P. Kingma J. Ba Adam: a method for stochastic optimization 2014 arXiv preprint arXiv:14126980 Kingma DP, Ba J. Adam: A method for stochastic optimization. arXiv preprint arXiv:14126980. 2014. [49] R. Lu S.H. Hong X. Zhang A dynamic pricing demand response algorithm for smart grid: reinforcement learning approach Appl Energy 220 2018 220 230 Lu R, Hong SH, Zhang X. A dynamic pricing demand response algorithm for smart grid: reinforcement learning approach. Applied Energy. 2018;220:220-230. [50] L.P. Kaelbling M.L. Littman A.W. Moore Reinforcement learning: a survey J Artif Intell Res 4 1996 237 285 Kaelbling LP, Littman ML, Moore AW. Reinforcement learning: A survey. Journal of Artificial intelligence research. 1996;4:237-285. [51] T. Liu X. Hu W. Hu Y. Zou A heuristic planning reinforcement learning-based energy management for power-split plug-in hybrid electric vehicles IEEE Transactions on Industrial Informatics 15 12 2019 6436 6445 Liu T, Hu X, Hu W, Zou Y. A heuristic planning reinforcement learning-based energy management for power-split plug-in hybrid electric vehicles. IEEE Transactions on Industrial Informatics. 2019;15(12):6436-6445. [52] J. Peters S. Schaal Natural actor-critic Neurocomputing 71 2008 1180 1190 Peters J, Schaal S. Natural actor-critic. Neurocomputing. 2008;71:1180-1190. [53] Q.J. Huys A. Cruickshank P. Seriès Reward-based learning, model-based and model-free Encyclopedia of Computational Neuroscience 2015 2634 2641 Huys QJ, Cruickshank A, Series P. Reward-based learning, model-based and model-free. Encyclopedia of Computational Neuroscience. 2015:2634-1641. [54] J. Peng R.J. Williams Incremental multi-step Q-learning Machine Learning Proceedings 1994 226 232 Elsevier; 1994 Peng J, Williams RJ. Incremental multi-step Q-learning. Machine Learning Proceedings 1994: Elsevier; 1994. p. 226-232. [55] R. Kumar B. Moseley S. Vassilvitskii A. Vattani Fast greedy algorithms in mapreduce and streaming ACM Transactions on Parallel Computing (TOPC) 2 2015 14 Kumar R, Moseley B, Vassilvitskii S, Vattani A. Fast greedy algorithms in mapreduce and streaming. ACM Transactions on Parallel Computing (TOPC). 2015;2:14. [56] J. Schulman X. Chen P. Abbeel Equivalence between policy gradients and soft q-learning 2017 arXiv preprint arXiv:170406440 Schulman J, Chen X, Abbeel P. Equivalence between policy gradients and soft q-learning. arXiv preprint arXiv:170406440. 2017. [57] Dataport. Pecan Street Inc. Available: https://dataport.cloud/ Dataport. Pecan Street Inc. Available: https://dataport.cloud/. [58] MesoWest. University of Utah Department of Atmospheric Sciences Available: http://mesowest.utah.edu/ MesoWest. University of Utah Department of Atmospheric Sciences. Available: http://mesowest.utah.edu/. [59] PJM. Available http://dataminer2.pjm.com/list PJM. Available: http://dataminer2.pjm.com/list. [60] DKASC Available: http://dkasolarcentre.com.au DKASC. Available: http://dkasolarcentre.com.au. [61] M. Yu S.H. Hong J.B. Kim Incentive-based demand response approach for aggregated demand side participation IEEE international conference on smart grid communications (SmartGridComm) 2016 IEEE 51 56 2016 Yu M, Hong SH, Kim JB. Incentive-based demand response approach for aggregated demand side participation. 2016 IEEE International Conference on Smart Grid Communications (SmartGridComm): IEEE; 2016. p. 51-56.",
    "scopus-id": "85086479731",
    "coredata": {
        "eid": "1-s2.0-S0360544220311269",
        "dc:description": "Incentive-based demand response (DR) program can induce end users (EUs) to reduce electricity demand during peak period through rewards. In this study, an incentive-based DR program with modified deep learning and reinforcement learning is proposed. A modified deep learning model based on recurrent neural network (MDL-RNN) was first proposed to identify the future uncertainties of environment by forecasting day-ahead wholesale electricity price, photovoltaic (PV) power output, and power load. Then, reinforcement learning (RL) was utilized to explore the optimal incentive rates at each hour which can maximize the profits of both energy service providers (ESPs) and EUs. The results showed that the proposed modified deep learning model can achieve more accurate forecasting results compared with some other methods. It can support the development of incentive-based DR programs under uncertain environment. Meanwhile, the optimized incentive rate can increase the total profits of ESPs and EUs while reducing the peak electricity demand. A short-term DR program was developed for peak electricity demand period, and the experimental results show that peak electricity demand can be reduced by 17%. This contributes to mitigating the supply-demand imbalance and enhancing power system security.",
        "openArchiveArticle": "false",
        "prism:coverDate": "2020-08-15",
        "openaccessUserLicense": null,
        "prism:aggregationType": "Journal",
        "prism:url": "https://api.elsevier.com/content/article/pii/S0360544220311269",
        "dc:creator": [
            {
                "@_fa": "true",
                "$": "Wen, Lulu"
            },
            {
                "@_fa": "true",
                "$": "Zhou, Kaile"
            },
            {
                "@_fa": "true",
                "$": "Li, Jun"
            },
            {
                "@_fa": "true",
                "$": "Wang, Shanyong"
            }
        ],
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/article/pii/S0360544220311269"
            },
            {
                "@_fa": "true",
                "@rel": "scidir",
                "@href": "https://www.sciencedirect.com/science/article/pii/S0360544220311269"
            }
        ],
        "dc:format": "application/json",
        "openaccessType": null,
        "pii": "S0360-5442(20)31126-9",
        "prism:volume": "205",
        "articleNumber": "118019",
        "prism:publisher": "Elsevier Ltd.",
        "dc:title": "Modified deep learning and reinforcement learning for an incentive-based demand response model",
        "prism:copyright": "© 2020 Elsevier Ltd. All rights reserved.",
        "openaccess": "0",
        "prism:issn": "03605442",
        "dcterms:subject": [
            {
                "@_fa": "true",
                "$": "Demand response"
            },
            {
                "@_fa": "true",
                "$": "Modified deep learning"
            },
            {
                "@_fa": "true",
                "$": "Reinforcement learning"
            },
            {
                "@_fa": "true",
                "$": "Smart grid"
            }
        ],
        "openaccessArticle": "false",
        "prism:publicationName": "Energy",
        "openaccessSponsorType": null,
        "prism:pageRange": "118019",
        "pubType": "fla",
        "prism:coverDisplayDate": "15 August 2020",
        "prism:doi": "10.1016/j.energy.2020.118019",
        "prism:startingPage": "118019",
        "dc:identifier": "doi:10.1016/j.energy.2020.118019",
        "openaccessSponsorName": null
    },
    "objects": {"object": [
        {
            "@category": "standard",
            "@height": "747",
            "@width": "532",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr3.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "78202",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "506",
            "@width": "534",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "77401",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "909",
            "@width": "378",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr10.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "81735",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "946",
            "@width": "381",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr11.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "88970",
            "@ref": "gr11",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "308",
            "@width": "381",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr6.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "27745",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "1022",
            "@width": "350",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr7.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "97031",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "1021",
            "@width": "354",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr4.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "73951",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "276",
            "@width": "379",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr12.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "28205",
            "@ref": "gr12",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "233",
            "@width": "542",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr2.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "21849",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "297",
            "@width": "380",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr5.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "33354",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "284",
            "@width": "387",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr8.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "26144",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "670",
            "@width": "382",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr9.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "55399",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "117",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr3.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "6843",
            "@ref": "gr3",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "173",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "11637",
            "@ref": "gr1",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "68",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr10.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "4190",
            "@ref": "gr10",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "66",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr11.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "4774",
            "@ref": "gr11",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "202",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr6.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "7361",
            "@ref": "gr6",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "56",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr7.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "4209",
            "@ref": "gr7",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "162",
            "@width": "56",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr4.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "3108",
            "@ref": "gr4",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "159",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr12.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "7970",
            "@ref": "gr12",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "94",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr2.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "4449",
            "@ref": "gr2",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "209",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr5.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "8425",
            "@ref": "gr5",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "161",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr8.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "6217",
            "@ref": "gr8",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "93",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr9.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "4087",
            "@ref": "gr9",
            "@mimetype": "image/gif"
        },
        {
            "@category": "high",
            "@height": "3305",
            "@width": "2355",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr3_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "527949",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2242",
            "@width": "2367",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr1_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "629840",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "4024",
            "@width": "1673",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr10_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "542328",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "4195",
            "@width": "1689",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr11_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "541881",
            "@ref": "gr11",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1365",
            "@width": "1686",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr6_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "222062",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "4528",
            "@width": "1551",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr7_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "823485",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "4528",
            "@width": "1570",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr4_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "539644",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1223",
            "@width": "1681",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr12_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "191027",
            "@ref": "gr12",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1031",
            "@width": "2402",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr2_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "149785",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1318",
            "@width": "1684",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr5_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "256896",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1259",
            "@width": "1714",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr8_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "182277",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2971",
            "@width": "1693",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-gr9_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "386201",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si51.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "49724",
            "@ref": "si51",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si9.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "12883",
            "@ref": "si9",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si27.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4817",
            "@ref": "si27",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si60.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7295",
            "@ref": "si60",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si46.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5715",
            "@ref": "si46",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si6.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7841",
            "@ref": "si6",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si42.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11377",
            "@ref": "si42",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si15.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "16800",
            "@ref": "si15",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si16.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1780",
            "@ref": "si16",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si5.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7051",
            "@ref": "si5",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si65.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2919",
            "@ref": "si65",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si2.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4078",
            "@ref": "si2",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si63.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "21076",
            "@ref": "si63",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si55.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "32565",
            "@ref": "si55",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si20.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "36856",
            "@ref": "si20",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si34.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5646",
            "@ref": "si34",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si48.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2975",
            "@ref": "si48",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si1.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "31299",
            "@ref": "si1",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si4.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4633",
            "@ref": "si4",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si3.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5738",
            "@ref": "si3",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si61.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "17598",
            "@ref": "si61",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si26.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5660",
            "@ref": "si26",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si37.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4741",
            "@ref": "si37",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si45.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "29595",
            "@ref": "si45",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si62.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11051",
            "@ref": "si62",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si49.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6627",
            "@ref": "si49",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si31.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1076",
            "@ref": "si31",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si33.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "22114",
            "@ref": "si33",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si38.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4918",
            "@ref": "si38",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si29.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11041",
            "@ref": "si29",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si57.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "26748",
            "@ref": "si57",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si59.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "36721",
            "@ref": "si59",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si13.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "21500",
            "@ref": "si13",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si43.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5214",
            "@ref": "si43",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si28.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "10376",
            "@ref": "si28",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si22.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "15360",
            "@ref": "si22",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si14.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "26209",
            "@ref": "si14",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si58.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "30096",
            "@ref": "si58",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si23.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "10308",
            "@ref": "si23",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si47.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3437",
            "@ref": "si47",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si10.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5311",
            "@ref": "si10",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si40.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "10113",
            "@ref": "si40",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si36.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2965",
            "@ref": "si36",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si17.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "28580",
            "@ref": "si17",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si21.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "9002",
            "@ref": "si21",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si12.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "8945",
            "@ref": "si12",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si32.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "21009",
            "@ref": "si32",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si64.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "26771",
            "@ref": "si64",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si7.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "42765",
            "@ref": "si7",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si44.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "24253",
            "@ref": "si44",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si19.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "29374",
            "@ref": "si19",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si41.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "23732",
            "@ref": "si41",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si8.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "17166",
            "@ref": "si8",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si30.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "23201",
            "@ref": "si30",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si39.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4075",
            "@ref": "si39",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si54.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "35705",
            "@ref": "si54",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si24.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "8420",
            "@ref": "si24",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si53.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "35843",
            "@ref": "si53",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si35.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3367",
            "@ref": "si35",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si18.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "32563",
            "@ref": "si18",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si56.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "27958",
            "@ref": "si56",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si50.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7226",
            "@ref": "si50",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si25.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11024",
            "@ref": "si25",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si11.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3759",
            "@ref": "si11",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-si52.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "32816",
            "@ref": "si52",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0360544220311269-am.pdf?httpAccept=%2A%2F%2A",
            "@multimediatype": "Acrobat PDF file",
            "@type": "AAM-PDF",
            "@size": "779054",
            "@ref": "am",
            "@mimetype": "application/pdf"
        }
    ]},
    "link": {
        "@rel": "abstract",
        "@href": "https://api.elsevier.com/content/abstract/scopus_id/85086479731"
    }
}}