{"full-text-retrieval-response": {
    "scopus-eid": "2-s2.0-85135701106",
    "originalText": "serial JL 271429 291210 291702 291731 291787 291877 291878 291881 31 Applied Energy APPLIEDENERGY 2022-08-08 2022-08-08 2022-08-08 2022-08-08 2023-05-16T15:02:37 1-s2.0-S0306261922010297 S0306-2619(22)01029-7 S0306261922010297 10.1016/j.apenergy.2022.119742 S300 S300.1 FULL-TEXT 1-s2.0-S0306261922X00160 2024-01-01T13:30:21.133674Z 0 0 20221015 2022 2022-08-08T17:00:13.328415Z absattachment articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor highlightsabst orcid primabst ref specialabst 0306-2619 03062619 true 324 324 C Volume 324 72 119742 119742 119742 20221015 15 October 2022 2022-10-15 2022 Research Papers article fla © 2022 Elsevier Ltd. All rights reserved. APRACTICALDEEPREINFORCEMENTLEARNINGFRAMEWORKFORMULTIVARIATEOCCUPANTCENTRICCONTROLINBUILDINGS LEI Y 1 Introduction 1.1 Multivariate building controls 1.2 Implementing DRL-based HVAC control 1.3 Demand for occupant-centric comfort management in RL-based control 1.4 Research gaps and objectives 2 Methodology 2.1 Description of the DRL control framework 2.2 Multivariate control with BDQ-based agent 2.2.1 Reinforcement learning 2.2.2 Branching dueling Q-network 2.2.3 BDQ-based agent training 2.3 Personalized thermal comfort matrix 2.4 Virtual environment for agent training 3 Case study 3.1 Building and system 3.2 DRL control for the hybrid cooling system 3.2.1 State design 3.2.2 Action design 3.2.3 Reward design 3.3 Personalized comfort matrix initialization and online update 3.4 BDQ-based agent training setup 3.5 BDQ-based agent online deployment 3.6 Performance evaluation 4 Results 4.1 Training with the virtual environment 4.2 Analysis of control actions for a typical day 4.3 Comfort performance evaluation based on real-time votes 4.4 Energy performance evaluation results 4.5 Analysis of online update for personalized comfort matrix 5 Discussion 5.1 Advantage of BDQ-based agent 5.2 Mismatch between thermal acceptability and thermal comfort 5.3 Justification of energy reduction 5.4 Importance of considering personalized comfort in HVAC control 5.5 Necessity of a virtual environment for agent pre-training 5.6 Potential implementation strategy in practice 5.7 Limitations 6 Conclusion and future work CRediT authorship contribution statement Acknowledgments Appendix Comfort surveys and personalized comfort matrix References CENTER 2020 1672 1679 B ENERGYINFORMATIONADMINISTRATIONWASHINGTONDCVOL12 ANNUALENERGYOUTLOOK2020 COMMISSION 2020 E COMMUNICATIONCOMMISSIONEUROPEANPARLIAMENTCOUNCILEUROPEANECONOMICSOCIALCOMMITTEECOMMITTEEREGIONS ARENOVATIONWAVEFOREUROPEGREENINGBUILDINGSCREATINGJOBSIMPROVINGLIVES FERNANDEZ 2017 N IMPACTSCOMMERCIALBUILDINGCONTROLSENERGYSAVINGSPEAKLOADREDUCTION FRONTCZAK 2012 119 131 M WANG 2008 3 32 S PARK 2019 106351 J XIE 2020 110392 J DAI 2020 110159 X AFROZ 2018 64 84 Z ZHAN 2022 119580 S WINKLER 2020 265 276 D 202019THACMIEEEINTERNATIONALCONFERENCEINFORMATIONPROCESSINGINSENSORNETWORKS OFFICEOPTIMIZATIONFRAMEWORKFORIMPROVEDCOMFORTEFFICIENCY DHAR 2017 178 188 N PENG 2018 1343 1358 Y PENG 2019 296 308 Y ARROYO 2022 118346 J WEI 2017 1 6 T PROCEEDINGS54THANNUALDESIGNAUTOMATIONCONFERENCE2017 DEEPREINFORCEMENTLEARNINGFORBUILDINGHVACCONTROL SATYAVADA 2016 262 273 H HOMOD 2020 115255 R SERALE 2018 631 G ZHAN 2021 110835 S CHONG 2021 111533 A YU 2020 407 419 L HANUMAIAH 2021 V DISTRIBUTEDMULTIAGENTDEEPREINFORCEMENTLEARNINGFRAMEWORKFORWHOLEBUILDINGHVACCONTROL MOCANU 2018 3698 3708 E VAZQUEZCANTELI 2020 J CITYLEARNSTANDARDIZINGRESEARCHINMULTIAGENTREINFORCEMENTLEARNINGFORDEMANDRESPONSEURBANENERGYMANAGEMENT HOMOD 2022 118863 R NAGARATHINAM 2020 57 67 S PROCEEDINGSELEVENTHACMINTERNATIONALCONFERENCEFUTUREENERGYSYSTEMS MARCOMULTIAGENTREINFORCEMENTLEARNINGBASEDCONTROLBUILDINGHVACSYSTEMS NGUYEN 2020 3826 3839 T LILLICRAP 2015 T CONTINUOUSCONTROLDEEPREINFORCEMENTLEARNING SUN 2015 1396 1406 B DING 2019 326 335 X PROCEEDINGS6THACMINTERNATIONALCONFERENCESYSTEMSFORENERGYEFFICIENTBUILDINGSCITIESTRANSPORTATION OCTOPUSDEEPREINFORCEMENTLEARNINGFORHOLISTICSMARTBUILDINGCONTROL YU 2021 L KAZMI 2018 159 168 H PARK 2019 397 414 J DULACARNOLD 2021 2419 2468 G CHEN 2018 195 205 Y BOTVINICK 2019 408 422 M WANG 2020 115036 Z ANDREWS 2002 493 494 N KATIPAMULA 2005 3 25 S BAE 2021 100068 Y ZHANG 2019 472 490 Z CHEN 2019 316 325 B PROCEEDINGS6THACMINTERNATIONALCONFERENCESYSTEMSFORENERGYEFFICIENTBUILDINGSCITIESTRANSPORTATION GNURLAPRECOCIALREINFORCEMENTLEARNINGSOLUTIONFORBUILDINGHVACCONTROLUSINGADIFFERENTIABLEMPCPOLICY QIU 2022 111694 S ZHANG 2019 C JUNG 2021 108633 S OBRIEN 2020 106738 W WANG 2018 181 193 Z ONO 2022 109255 E KIM 2018 114 124 J CHEUNG 2019 205 217 T DEDEAR 1998 R DEVELOPINGADAPTIVEMODELTHERMALCOMFORTPREFERENCE HUMPHREYS 2002 667 684 M PARK 2018 2664 2679 J HOMOD 2012 141 153 R WETTER 2014 253 270 M YANG 2015 577 586 L TAVAKOLI 2018 A PROCEEDINGSAAAICONFERENCEARTIFICIALINTELLIGENCEVOL32 ACTIONBRANCHINGARCHITECTURESFORDEEPREINFORCEMENTLEARNING SUTTON 2018 R REINFORCEMENTLEARNINGINTRODUCTION VANHASSELT 2016 H PROCEEDINGSAAAICONFERENCEARTIFICIALINTELLIGENCEVOL30 DEEPREINFORCEMENTLEARNINGDOUBLEQLEARNING WANG 2016 1995 2003 Z PROCEEDINGS33RDINTERNATIONALCONFERENCEMACHINELEARNING DUELINGNETWORKARCHITECTURESFORDEEPREINFORCEMENTLEARNING SEWAK 2019 M DEEPREINFORCEMENTLEARNING GUNNARSEN 1992 43 54 L LIN 1992 293 321 L BROCKMAN 2016 G OPENAIGYM ANDERSSON 2016 C PYFMIAPYTHONPACKAGEFORSIMULATIONCOUPLEDDYNAMICMODELSFUNCTIONALMOCKUPINTERFACE ZHANG 2017 S ADEEPERLOOKEXPERIENCEREPLAY CHONG 2019 177 190 A ZHAN 2022 112278 S CALIBRATINGBUILDINGSIMULATIONMODELSUSINGMULTISOURCEDATASETSMETALEARNEDBAYESIANOPTIMIZATION ANSIASHRAE 2020 S ANSIASHRAESTANDARD552020THERMALENVIRONMENTALCONDITIONSFORHUMANOCCUPANCY MIHARA 2019 109448 K VELAVAN 2020 278 T JUNG 2019 104 119 W ASHRAE 2014 A GUIDELINE142014MEASUREMENTENERGYDEMANDWATERSAVINGS ZHANG 2008 44 50 Y HENDERSON 2018 P PROCEEDINGSAAAICONFERENCEARTIFICIALINTELLIGENCEVOL32 DEEPREINFORCEMENTLEARNINGMATTERS PAINE 2020 T HYPERPARAMETERSELECTIONFOROFFLINEREINFORCEMENTLEARNING KEARNS 2002 193 208 M LEIX2022X119742 LEIX2022X119742XY 2024-08-08T00:00:00.000Z 2024-08-08T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ © 2022 Elsevier Ltd. All rights reserved. 2022-08-16T17:00:42.292Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/aggregated-refined https://doi.org/10.15223/policy-017 https://doi.org/10.15223/policy-037 https://doi.org/10.15223/policy-012 https://doi.org/10.15223/policy-029 https://doi.org/10.15223/policy-004 item S0306-2619(22)01029-7 S0306261922010297 1-s2.0-S0306261922010297 10.1016/j.apenergy.2022.119742 271429 2024-01-01T13:30:21.133674Z 2022-10-15 1-s2.0-S0306261922010297-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/MAIN/application/pdf/cfabfc44da4df7b1ec4c4de15f619fe5/main.pdf main.pdf pdf true 4972652 MAIN 18 1-s2.0-S0306261922010297-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/PREVIEW/image/png/9f5b3b5d4a1211ef54437e5c86bf87b6/main_1.png main_1.png png 44283 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0306261922010297-gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr9/DOWNSAMPLED/image/jpeg/48f1f9eeba38805e09f46592529a335e/gr9.jpg gr9 gr9.jpg jpg 44340 243 552 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-fx1001.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/fx1001/DOWNSAMPLED/image/jpeg/03844c372a600bf2291b8c512177ad8d/fx1001.jpg fx1001 fx1001.jpg jpg 140721 409 817 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr8/DOWNSAMPLED/image/jpeg/a2c5bb4f0c87eb59275f668bc7c430d3/gr8.jpg gr8 gr8.jpg jpg 84419 325 659 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr7/DOWNSAMPLED/image/jpeg/d86be95ab62cfa4fe8b4653174c46f4f/gr7.jpg gr7 gr7.jpg jpg 52861 206 653 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr6/DOWNSAMPLED/image/jpeg/36d1e33cb58f0aa95f532d44f5cf6a16/gr6.jpg gr6 gr6.jpg jpg 43746 234 429 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr5/DOWNSAMPLED/image/jpeg/e86ff24127e84f5c92e797dd488e26f0/gr5.jpg gr5 gr5.jpg jpg 154790 468 659 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr4/DOWNSAMPLED/image/jpeg/74717e5a097f65eb59259285a324f58e/gr4.jpg gr4 gr4.jpg jpg 89168 383 659 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr3/DOWNSAMPLED/image/jpeg/86325fe786ea95f9be03a3f70d7cf5fb/gr3.jpg gr3 gr3.jpg jpg 46215 176 659 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr2/DOWNSAMPLED/image/jpeg/45981d864788d02a56d33fd71fb2da54/gr2.jpg gr2 gr2.jpg jpg 23854 146 436 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr1/DOWNSAMPLED/image/jpeg/831c686795c426d3deb4b9f4abd6ba1a/gr1.jpg gr1 gr1.jpg jpg 80677 353 659 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr13.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr13/DOWNSAMPLED/image/jpeg/04fe2b136d84c3fcc25560deaf44eb51/gr13.jpg gr13 gr13.jpg jpg 158839 346 659 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr11.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr11/DOWNSAMPLED/image/jpeg/229662e7a3f16c7c7b8660e2609355b6/gr11.jpg gr11 gr11.jpg jpg 65438 249 659 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr12.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr12/DOWNSAMPLED/image/jpeg/ff6b5eccf9af0b8f07f84ae32a07879d/gr12.jpg gr12 gr12.jpg jpg 101420 599 659 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr10/DOWNSAMPLED/image/jpeg/3818126d0072594f35ec528fec292318/gr10.jpg gr10 gr10.jpg jpg 137927 499 659 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-ga1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/ga1/DOWNSAMPLED/image/jpeg/812885be0cf38a6130a391683f6795e4/ga1.jpg ga1 true ga1.jpg jpg 36003 161 301 IMAGE-DOWNSAMPLED 1-s2.0-S0306261922010297-gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr9/THUMBNAIL/image/gif/75a640a1da45f0c3cd8f33fa7a6355a8/gr9.sml gr9 gr9.sml sml 14124 96 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-fx1001.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/fx1001/THUMBNAIL/image/gif/d76cd16b36208f975617a5db0fdb440f/fx1001.sml fx1001 fx1001.sml sml 72354 110 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr8/THUMBNAIL/image/gif/2b0223da47fbfc779b9f78d4bdf35317/gr8.sml gr8 gr8.sml sml 16996 108 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr7/THUMBNAIL/image/gif/0ce5194edf0250503731fcd61fef03da/gr7.sml gr7 gr7.sml sml 12696 69 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr6/THUMBNAIL/image/gif/7f5ba7db056b28cf53f395f0ccda1f21/gr6.sml gr6 gr6.sml sml 16991 119 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr5/THUMBNAIL/image/gif/46f17db820ad4fb7093eca76feb667e5/gr5.sml gr5 gr5.sml sml 29094 155 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr4/THUMBNAIL/image/gif/208ca92107bb768dd7fa573fe9e2d283/gr4.sml gr4 gr4.sml sml 20617 127 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr3/THUMBNAIL/image/gif/547cb5538b1c4e05b5b5257822ea09fa/gr3.sml gr3 gr3.sml sml 13158 58 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr2/THUMBNAIL/image/gif/a5ecee12670be029effbfa108ae6b49b/gr2.sml gr2 gr2.sml sml 11355 73 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr1/THUMBNAIL/image/gif/b5c2e8b0ee6cd71622d382a97c187673/gr1.sml gr1 gr1.sml sml 18442 117 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr13.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr13/THUMBNAIL/image/gif/58abc9688de10866ee5efb7ed0abab0d/gr13.sml gr13 gr13.sml sml 29525 115 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr11.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr11/THUMBNAIL/image/gif/a37ddfbd6e5382bdecd2fc3ab38f4753/gr11.sml gr11 gr11.sml sml 15333 83 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr12.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr12/THUMBNAIL/image/gif/2cbe11225160ed44d525e18006dda607/gr12.sml gr12 gr12.sml sml 18238 164 180 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr10/THUMBNAIL/image/gif/7f3189b2473bd74973cfcb5c8532ed9c/gr10.sml gr10 gr10.sml sml 26851 164 217 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-ga1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/ga1/THUMBNAIL/image/gif/f9b58b7066237004538d2eb0b66fefbe/ga1.sml ga1 true ga1.sml sml 19122 117 219 IMAGE-THUMBNAIL 1-s2.0-S0306261922010297-gr9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr9/HIGHRES/image/jpeg/4d4d19f2983dd6499e5b4eb2cffdc64c/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 222066 1074 2443 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-fx1001_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/fx1001/HIGHRES/image/jpeg/f87c1a60d4b250856afc02b2866738e0/fx1001_lrg.jpg fx1001 fx1001_lrg.jpg jpg 655440 1813 3618 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr8/HIGHRES/image/jpeg/bdbec09fd4bb621a25a6a2d18ddc3a11/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 426315 1439 2917 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr7/HIGHRES/image/jpeg/f97e46633ddcbc6239e55ad28303a97d/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 307755 910 2890 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr6/HIGHRES/image/jpeg/e160549bc3104381f37d706676c5fb9c/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 227987 1037 1901 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr5/HIGHRES/image/jpeg/88f2290d97cc3895892d35a45b213ccb/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 1014095 2071 2918 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr4/HIGHRES/image/jpeg/006ae4e874f4c9ae076e2161da47f43d/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 540288 1693 2916 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr3/HIGHRES/image/jpeg/b879530738f0cdceac5eaf00e81edbc6/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 239217 778 2918 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr2/HIGHRES/image/jpeg/dce0c8bd646b9850bbbb2571d1b6e9c2/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 99056 646 1932 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr1/HIGHRES/image/jpeg/0aa3d217bad33401d2468bfa8bb25859/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 489044 1562 2917 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr13_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr13/HIGHRES/image/jpeg/37edaefa22c9edf30b060bc196ae311a/gr13_lrg.jpg gr13 gr13_lrg.jpg jpg 1014682 1533 2917 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr11_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr11/HIGHRES/image/jpeg/283de4c5b8bcfcc630b46a324177cd37/gr11_lrg.jpg gr11 gr11_lrg.jpg jpg 308950 1104 2917 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr12_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr12/HIGHRES/image/jpeg/6fe3eb2c306ed28ff3ff166e0345ff96/gr12_lrg.jpg gr12 gr12_lrg.jpg jpg 777750 2651 2917 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-gr10_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/gr10/HIGHRES/image/jpeg/04c3ff229a1aa170d8d6771d8f51bd67/gr10_lrg.jpg gr10 gr10_lrg.jpg jpg 723661 2207 2917 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-ga1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/ga1/HIGHRES/image/jpeg/0934dc6b65870fc2e0f6e98f8ffdd808/ga1_lrg.jpg ga1 true ga1_lrg.jpg jpg 187160 714 1333 IMAGE-HIGH-RES 1-s2.0-S0306261922010297-si1.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/27bcd1f6c042684db5466e72f441260f/si1.svg si1 si1.svg svg 3757 ALTIMG 1-s2.0-S0306261922010297-si10.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/4d7ed04eab0ea847faff11fcb01671b3/si10.svg si10 si10.svg svg 4460 ALTIMG 1-s2.0-S0306261922010297-si101.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/7b40b39225c984a0fbca946be3dffc2a/si101.svg si101 si101.svg svg 6528 ALTIMG 1-s2.0-S0306261922010297-si102.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/3fea37c81880dae06f09e7719953faa7/si102.svg si102 si102.svg svg 5221 ALTIMG 1-s2.0-S0306261922010297-si103.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/9af0e5e51633dbae2b23a1b2e4e4c96b/si103.svg si103 si103.svg svg 9695 ALTIMG 1-s2.0-S0306261922010297-si104.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/c7896d166ef6b553381b6ffc9ed031ab/si104.svg si104 si104.svg svg 5172 ALTIMG 1-s2.0-S0306261922010297-si105.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/dc02e2fc79c750ba4d2686fff847bd04/si105.svg si105 si105.svg svg 4610 ALTIMG 1-s2.0-S0306261922010297-si106.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/54c32815af7aef51c4467b9dc92c886b/si106.svg si106 si106.svg svg 7392 ALTIMG 1-s2.0-S0306261922010297-si107.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/5bcbb1e9817bbe38ceffdd25a4eab36b/si107.svg si107 si107.svg svg 3790 ALTIMG 1-s2.0-S0306261922010297-si108.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/2072b381f3c07a2a9aaf91e93595252d/si108.svg si108 si108.svg svg 6563 ALTIMG 1-s2.0-S0306261922010297-si109.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/77525d5c645a69ad1126e6d3926d59f6/si109.svg si109 si109.svg svg 24356 ALTIMG 1-s2.0-S0306261922010297-si11.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/453bcde2a19601f571e76f474b37dd21/si11.svg si11 si11.svg svg 5122 ALTIMG 1-s2.0-S0306261922010297-si110.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/6c8e54650d4cd665f0deaeb388724992/si110.svg si110 si110.svg svg 15323 ALTIMG 1-s2.0-S0306261922010297-si111.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/98414cae0bf269604dd17be4eb4e8768/si111.svg si111 si111.svg svg 1456 ALTIMG 1-s2.0-S0306261922010297-si112.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/b1611c28d0dce61a0c024fc3945d29d9/si112.svg si112 si112.svg svg 702 ALTIMG 1-s2.0-S0306261922010297-si113.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/48e9d86714c66d25d8933ee9b83c56ad/si113.svg si113 si113.svg svg 678 ALTIMG 1-s2.0-S0306261922010297-si119.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/4bfa0932975c7987c97eef7b2864665b/si119.svg si119 si119.svg svg 993 ALTIMG 1-s2.0-S0306261922010297-si12.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/032397dfafefb4421a30374e9f04a961/si12.svg si12 si12.svg svg 2962 ALTIMG 1-s2.0-S0306261922010297-si120.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/219ffcfb4cab08f10a8f0bffcd1bf0a1/si120.svg si120 si120.svg svg 1159 ALTIMG 1-s2.0-S0306261922010297-si13.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/cf73ec1d6d58f94f5ee2527921540204/si13.svg si13 si13.svg svg 4889 ALTIMG 1-s2.0-S0306261922010297-si14.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/796738edc2d9167d6dec58f076f96fe0/si14.svg si14 si14.svg svg 8370 ALTIMG 1-s2.0-S0306261922010297-si15.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/c00b3a68ce5f0eba4018af3850efaa1a/si15.svg si15 si15.svg svg 17322 ALTIMG 1-s2.0-S0306261922010297-si16.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/874df4cb74cd05fbc1ef785bea70fc8b/si16.svg si16 si16.svg svg 7214 ALTIMG 1-s2.0-S0306261922010297-si17.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/a56e7344f95a1cacf94a6e4ee915b420/si17.svg si17 si17.svg svg 1551 ALTIMG 1-s2.0-S0306261922010297-si18.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/03a771c449eb49c407ff7b8e16effdaa/si18.svg si18 si18.svg svg 1325 ALTIMG 1-s2.0-S0306261922010297-si19.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/ebecff4da684cb637e1dc7d87dfdfbeb/si19.svg si19 si19.svg svg 4774 ALTIMG 1-s2.0-S0306261922010297-si2.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/a6926079396483cbc02d6f7bd4f547bb/si2.svg si2 si2.svg svg 1424 ALTIMG 1-s2.0-S0306261922010297-si20.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/62286d739ba9c0a82e8c923f40e58a98/si20.svg si20 si20.svg svg 21891 ALTIMG 1-s2.0-S0306261922010297-si22.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/18949edfaaad9cb2d110c2b9bb12c939/si22.svg si22 si22.svg svg 6417 ALTIMG 1-s2.0-S0306261922010297-si23.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/4dab0296409326ba9f1dc8dae1b18d09/si23.svg si23 si23.svg svg 24693 ALTIMG 1-s2.0-S0306261922010297-si24.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/d98f16c66b7049a759e24096ec740519/si24.svg si24 si24.svg svg 1131 ALTIMG 1-s2.0-S0306261922010297-si25.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/bfc4a4fa277da08672e788aea504a194/si25.svg si25 si25.svg svg 2918 ALTIMG 1-s2.0-S0306261922010297-si27.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/d247302009ed8a120bd47df8022eebba/si27.svg si27 si27.svg svg 3195 ALTIMG 1-s2.0-S0306261922010297-si28.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/3da45e3f4c194d1e8f14fa3e0d54771d/si28.svg si28 si28.svg svg 1615 ALTIMG 1-s2.0-S0306261922010297-si29.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/41f5ff58bc6672ae1641e26ae4c2a50d/si29.svg si29 si29.svg svg 1798 ALTIMG 1-s2.0-S0306261922010297-si3.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/a2ccb73bbc3ab298384482ff8d797f10/si3.svg si3 si3.svg svg 3563 ALTIMG 1-s2.0-S0306261922010297-si30.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/49962c2548943bfdb061eaabf4ec3fff/si30.svg si30 si30.svg svg 1430 ALTIMG 1-s2.0-S0306261922010297-si31.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/0e8eba53492c43f213bae0b2d840e199/si31.svg si31 si31.svg svg 1305 ALTIMG 1-s2.0-S0306261922010297-si32.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/67eb2a568bbdd8c75ad08d7e80d1d29f/si32.svg si32 si32.svg svg 5972 ALTIMG 1-s2.0-S0306261922010297-si33.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/53bd039192f20db2a5b75732f8bdb1da/si33.svg si33 si33.svg svg 23575 ALTIMG 1-s2.0-S0306261922010297-si34.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/72202c12d7d72390e88e8820e943b249/si34.svg si34 si34.svg svg 1918 ALTIMG 1-s2.0-S0306261922010297-si36.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/76fd7db38dd14b8a17a367ccb87393e6/si36.svg si36 si36.svg svg 2334 ALTIMG 1-s2.0-S0306261922010297-si39.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/23f214e07b5c8d6ebf4d489bf70274c5/si39.svg si39 si39.svg svg 1352 ALTIMG 1-s2.0-S0306261922010297-si4.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/d5f4e756293123a978f5b50547df43dd/si4.svg si4 si4.svg svg 1093 ALTIMG 1-s2.0-S0306261922010297-si40.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/7e3a7eaafe40ab968f6788f5ddf51d0b/si40.svg si40 si40.svg svg 11341 ALTIMG 1-s2.0-S0306261922010297-si41.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/d64df67d76bf2cc6ca25b74e63be71aa/si41.svg si41 si41.svg svg 1303 ALTIMG 1-s2.0-S0306261922010297-si42.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/7badf05cdbe33801c3d354d3232ba936/si42.svg si42 si42.svg svg 1305 ALTIMG 1-s2.0-S0306261922010297-si43.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/846f420d66c76cb8b946bdb47ec24a7e/si43.svg si43 si43.svg svg 2849 ALTIMG 1-s2.0-S0306261922010297-si44.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/ac9955c3a75b66c149dc525979584857/si44.svg si44 si44.svg svg 2085 ALTIMG 1-s2.0-S0306261922010297-si49.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/7b5bb622eeb0d3aa728613c55468b5b1/si49.svg si49 si49.svg svg 11718 ALTIMG 1-s2.0-S0306261922010297-si5.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/32d5d11b749ef2128039fc376626a7ae/si5.svg si5 si5.svg svg 4763 ALTIMG 1-s2.0-S0306261922010297-si50.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/1e04a95643db2ad75e5c56e0f2249789/si50.svg si50 si50.svg svg 5591 ALTIMG 1-s2.0-S0306261922010297-si51.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/99c43a9b688a07a90279d6002d6ab0bb/si51.svg si51 si51.svg svg 5753 ALTIMG 1-s2.0-S0306261922010297-si52.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/519ed6846762ab8de8a1baa9bde3e487/si52.svg si52 si52.svg svg 2128 ALTIMG 1-s2.0-S0306261922010297-si54.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/a7ec2aef5fff2f4b2fdf7768fcfc42da/si54.svg si54 si54.svg svg 1054 ALTIMG 1-s2.0-S0306261922010297-si55.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/d5bf3dd039af83ada27598271f589eb1/si55.svg si55 si55.svg svg 1351 ALTIMG 1-s2.0-S0306261922010297-si56.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/67fc3039ed149f3b8aa05095d4dbc054/si56.svg si56 si56.svg svg 2950 ALTIMG 1-s2.0-S0306261922010297-si58.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/1344d81a9b3e362173032ebac5875fd5/si58.svg si58 si58.svg svg 6014 ALTIMG 1-s2.0-S0306261922010297-si59.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/f7494b6960b5450805f48ee07544e181/si59.svg si59 si59.svg svg 16645 ALTIMG 1-s2.0-S0306261922010297-si6.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/b3e13cb4a64e0c0d7e18ab91c0a0f1fb/si6.svg si6 si6.svg svg 2174 ALTIMG 1-s2.0-S0306261922010297-si60.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/34ba95cca66b37f293ea13c486c03107/si60.svg si60 si60.svg svg 30048 ALTIMG 1-s2.0-S0306261922010297-si63.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/aa801ee71365d8a79abc52925841ee38/si63.svg si63 si63.svg svg 2570 ALTIMG 1-s2.0-S0306261922010297-si64.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/541a16d7e4387ce210269f23a576af38/si64.svg si64 si64.svg svg 1663 ALTIMG 1-s2.0-S0306261922010297-si65.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/6801194b55656a0d0ff4e0bad6db8021/si65.svg si65 si65.svg svg 4241 ALTIMG 1-s2.0-S0306261922010297-si69.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/f79d2e6e767f302f23cd1bbf4ef0aa3c/si69.svg si69 si69.svg svg 5128 ALTIMG 1-s2.0-S0306261922010297-si7.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/2011b9bdf9580416f17838ecc54daa33/si7.svg si7 si7.svg svg 5248 ALTIMG 1-s2.0-S0306261922010297-si72.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/2e7192bb6ecf22ca1e26ef93f104fa95/si72.svg si72 si72.svg svg 5388 ALTIMG 1-s2.0-S0306261922010297-si8.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/d532ac1816a7d17c740e60ab55752537/si8.svg si8 si8.svg svg 4630 ALTIMG 1-s2.0-S0306261922010297-si80.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/4b7bc28c8e05e69eb2ade38821968209/si80.svg si80 si80.svg svg 7817 ALTIMG 1-s2.0-S0306261922010297-si85.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/b0db441c6e162b5fbe586b5e58441633/si85.svg si85 si85.svg svg 1521 ALTIMG 1-s2.0-S0306261922010297-si9.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/035f67d87493e9a34753ad8720b4b4b2/si9.svg si9 si9.svg svg 5253 ALTIMG 1-s2.0-S0306261922010297-si91.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/069f2344008d6124cedbee90b43d9394/si91.svg si91 si91.svg svg 3148 ALTIMG 1-s2.0-S0306261922010297-si92.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/1da0b4a6e919aa8559f6fda74f8ce4e3/si92.svg si92 si92.svg svg 3223 ALTIMG 1-s2.0-S0306261922010297-si93.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/9cad662e06cc60b72f7b5fc69ab4f738/si93.svg si93 si93.svg svg 1470 ALTIMG 1-s2.0-S0306261922010297-si94.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/e1ab1ebf68b9f631634b78cf39d3ab70/si94.svg si94 si94.svg svg 1478 ALTIMG 1-s2.0-S0306261922010297-si95.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/bda9fff4202de83e1f9c58066a935524/si95.svg si95 si95.svg svg 1147 ALTIMG 1-s2.0-S0306261922010297-si96.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/b713590383d31ac0e1048db876658384/si96.svg si96 si96.svg svg 1490 ALTIMG 1-s2.0-S0306261922010297-si97.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/9a796ee11e0fd2465b52f120d3e5a2cc/si97.svg si97 si97.svg svg 1381 ALTIMG 1-s2.0-S0306261922010297-si98.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/3af3e0d72b8e93c7445126315b0c7abf/si98.svg si98 si98.svg svg 1226 ALTIMG 1-s2.0-S0306261922010297-si99.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0306261922010297/STRIPIN/image/svg+xml/03bff8b6c2e9995c19cd959583d2fa7f/si99.svg si99 si99.svg svg 1686 ALTIMG 1-s2.0-S0306261922010297-am.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:1014GZTS4QX/MAIN/application/pdf/fccd52c3d855bffc669574fb1703b3d9/am.pdf am am.pdf pdf false 3882416 AAM-PDF APEN 119742 119742 S0306-2619(22)01029-7 10.1016/j.apenergy.2022.119742 Elsevier Ltd Fig. 1 Block diagram of the proposed multivariate DRL control framework. Fig. 2 Standard agent-environment interaction. Fig. 3 Visualization of the action branching network architecture for the proposed BDQ agent. The gray rectangles denote the weights of the fully connected neural network layers. The advantage dimension and Q-value dimension is also indicated. Fig. 4 Plan view of the open office used in this study to evaluate the control performance of the proposed DRL control framework. The office seating plan and the location of the ceiling fans are illustrated. Fig. 5 Initialization and online update process for the personalized comfort matrix. Fig. 6 Comparison of the convergence performance between BDQ and Double DQN. The reward for the baseline control strategy is shown in the gray shaded region. Each natural day is an episode. To match the baseline performance, it took 7 months in simulation for the BDQ and 21 months in simulation for the Double DQN. Fig. 7 Predicted room temperature on the first week of experiment using the virtual environment. Due to a missing data issue on the first day (10/11/2021), we included the following Saturday (10/16/2021) data into the calibration. Fig. 8 Visualization of control actions for a typical day. The solid gray line with triangular markers displays the temperature setpoints throughout the day. Ceiling fan 1 (green dotted line) served occupants #4 and #5, ceiling fan 2 (dash-dotted pink line) served occupants #1, #2 and #3, ceiling fan 3 (dashed orange line) served occupants #8, and ceiling fan 4 (dashed blue line) served occupants #6 and #7. Fig. 9 Comparison of comfort results prior to the online training. Baseline Days denotes the aggregate of all experiment days operated under the baseline strategy (27 °C and fan speed M3). RL+PMV denotes the BDQ agent pre-trained with the standard PMV model. RL Day 1 denotes the BDQ agent pre-trained with the personalized comfort matrix. Fig. 10 Comparison of comfort results during the online deployment. RL Day 1 to RL Day 10 denote the respective experiment days controlled by the proposed BDQ agent. RL Week 2 denotes the aggregate of the BDQ agent deployment days in the second week. The number of valid comfort votes is also indicated. Fig. 11 Bedford thermal comfort votes during the online deployment. Fig. 12 Comfort surveys used in this study to initialize and online update the personalized comfort matrix. Fig. 13 The initial and final personalized comfort matrix for each participant. The discomfort penalties are highlighted in different colors for better visualization: clearly acceptable ↦ green, just acceptable ↦ yellow, just unacceptable ↦ orange, clearly unacceptable ↦ red. Table 1 Summary of data sources and their usage at different agent training phases. Data Offline pre-training Online learning Early stage Late stage Thermal comfort feedback Initialized personalized comfort matrix Updated personalized comfort matrix HVAC energy feedback Calibrated virtual environment Periodically re-calibrated virtual environment by GP-BO Real-time BMS data Table 2 State items and the corresponding upper and lower limits for the BDQ agent. No. Item o b m i n o b m a x 1 Room Temperature ( ° C ) 24 29 2\u20135 Modes for Ceiling Fan 1 to 4 a 0 5 6 Hour of the Day 0 23 7 Outdoor Air Temperature ( ° C ) 21.5 34.5 8 Outdoor Solar Radiation (W/m 2 ) 0 1,150 9 Outdoor Relative Humidity (%) 40 100 10 Occupancy Flag b 0 1 a Each ceiling fan can be independently operated at 6 speed modes. M0 is off and M5 is the highest speed. b The occupancy flag is a binary variable indicating the occupied hours. The flag is 1 for the period 10:00 am\u20136:00 pm of weekdays. Table 3 BDQ agent training setups and hyperparameters. Parameters Value Parameters Value Network width of 1st hidden layer in share module 256 units Prioritized replay buffer size 10 3 Network width of 2nd hidden layer in share module 128 units Virtual environment simulation time step 1 second Network width of sub-action branches 64 units Control time step 15 minutes Network width of state value branch 64 units Reward discount factor γ 0.9 Nonlinear activation function Relu Batch size 64 Optimizer Adam Target network update frequency 288 steps Weights initialization method Xavier η in the reward 6000 Learning rate 5 × 10−4 δ in the reward 10 Gradient clip method L2-norm λ in the reward −0.4 Gradient clip size 10 β in the reward 2 Table 4 Comparison of energy consumption between baseline and BDQ agent. Day Number of survey responses Mean solar radiation (W/m 2 ) Mean outdoor temperature ( ° C ) Mean indoor temperature ( ° C) Energy Consumption (kWh) Plant PAHU Ceiling fans Total HVAC energy Baseline control 1 36 331.7 29.8 26.8 10.2 4.3 0.2 14.7 2 37 658.4 31.3 26.9 9.2 4.0 0.2 13.4 3 32 549.9 30.9 27.0 9.5 4.0 0.4 13.9 4 18 260.8 29.8 27.1 13.0 5.9 0.2 19.1 5 32 530.2 30.8 27.1 13.4 6.1 0.4 19.9 6 18 168.7 27.3 27.1 6.5 4.6 0.3 11.4 Norm. a 31 500.5 30.5 27.0 10.3 4.7 0.3 15.3 DRL-based control 1 25 713.5 31.2 27.8 10.3 4.1 0.2 14.6 2 24 599.2 31.7 28.0 9.1 3.5 0.4 13.0 3 16 519.5 31.0 28.1 9.5 3.5 0.2 13.2 4 24 588.6 31.5 27.8 10.3 4.0 0.2 14.5 5 28 683.3 31.3 28.0 10.6 4.2 0.4 15.2 6 19 84.4 25.3 28.0 7.6 2.4 0.2 10.2 7 22 485.6 30.1 27.8 8.3 2.6 0.4 11.3 8 33 433.5 29.9 27.7 8.8 2.7 0.4 11.9 9 22 553.5 30.5 27.9 10.2 3.6 0.2 14.0 10 24 495.0 32.1 27.9 9.6 3.6 0.2 13.4 Mean b 24 515.6 30.4 27.9 9.4 3.4 0.3 13.1 a The mean energy consumption of the baseline control deployment days after performing the weather normalization. b The mean energy consumption of the BDQ agent deployment days. A practical deep reinforcement learning framework for multivariate occupant-centric control in buildings Yue Lei Conceptualization Methodology Data curation Formal analysis Investigation Visualization Writing \u2013 original draft Writing \u2013 review & editing a Sicheng Zhan Software Visualization Writing \u2013 review & editing a Eikichi Ono Validation Writing \u2013 review & editing a b Yuzhen Peng Writing \u2013 review & editing a Zhiang Zhang Writing \u2013 review & editing c Takamasa Hasama Project administration b Adrian Chong Conceptualization Supervision Project administration Funding acquisition Writing \u2013 review & editing a \u204e a Department of the Built Environment, National University of Singapore, 117566, Singapore Department of the Built Environment, National University of Singapore 117566 Singapore organization=Department of the Built Environment, National University of Singapore, postcode=117566, country=Singapore b Kajima Technical Research Institute, Singapore, 449269, Singapore Kajima Technical Research Institute Singapore 449269 Singapore organization=Kajima Technical Research Institute Singapore, postcode=449269, country=Singapore c Department of Architecture and Built Environment, University of Nottingham Ningbo China, Ningbo, 315100, China Department of Architecture and Built Environment, University of Nottingham Ningbo China Ningbo 315100 China organization=Department of Architecture and Built Environment, University of Nottingham Ningbo China, city=Ningbo, postcode=315100, country=China \u204e Corresponding author. Reinforcement learning (RL) has been shown to have the potential for optimal control of heating, ventilation, and air conditioning (HVAC) systems. Although research on RL-based building control has received extensive attention in recent years, there is limited real-world implementation to evaluate its performance while keeping occupants in the loop. Additionally, many HVAC systems consist of multiple subsystems, but conventional RL algorithms face significant challenges when dealing with high-dimensional action spaces. This study proposes a practical deep reinforcement learning (DRL) based multivariate occupant-centric control framework that considers personalized thermal comfort and occupant presence. Specifically, Branching Dueling Q-network (BDQ) is leveraged as the learning agent to efficiently solve the multi-dimensional control task, and a tabular-based personal comfort modeling method is applied that is naturally integrated into human-in-the-loop operations. The BDQ agent is pre-trained in a virtual environment, followed by online deployment in a real office space for 5-dimensional action control. Based on the actual deployment and real-time comfort votes, our results showed a 14% reduction in cooling energy and an 11% improvement in total thermal acceptability. Graphical abstract Keywords Occupant-centric control Deep learning Reinforcement learning Thermal comfort Energy efficiency Data availability Data will be made available on request. 1 Introduction With a significant increase in building energy consumption, research on HVAC related energy conservation measures has become essential. In 2020, the residential and commercial sectors were responsible for approximately 40% of primary energy consumption and 35% carbon emissions in the U.S. [1]. Similar statistics were provided by the European Commission [2] for most EU countries. According to Fernandez et al. [3], commercial buildings have the potential to save an average of 29% in energy consumption by installing the advanced control technologies that are available today. The researchers quantified the saving potentials by investigating the improvements resulting from applying 34 different building control measures to 14 distinct building types in 16 climate zones across the U.S. In addition, while buildings are designed to provide a comfortable space for occupants, a post occupancy study revealed that over 50% of the 52,980 occupants were dissatisfied with their indoor environment [4]. Therefore, it is an ongoing challenge to utilize the advanced control and operation techniques in practical application to attain desirable building performance [5]. Leveraging increasingly affordable smart metering technologies, a growing number of studies investigated how buildings can take advantage of occupant-centric controls and the Internet of Things (IoT) to accommodate occupants\u2019 comfort and improve energy efficiency [6]. Based on existing literature on occupant-centric controls, the reported median energy savings and comfort improvement was 22% and 29.1%, respectively [7,8]. Although many advanced building control techniques have been developed over the past decade, it remains challenging due to the high-order nonlinearity of dynamics and the complexities resulting from numerous disturbances, constraints, and uncertainties in buildings [9]. Examples of advanced building controls include model predictive control (MPC) [10,11], linear quadratic regulator [12], and learning-based control [13,14]. More recently, there has been increasing interest in reinforcement learning (RL) because of its adaptability and flexibility [15]. More importantly, since RL algorithms generally do not need to analyze the building dynamics at each control step, they provide significantly more efficient run-time control than those optimization-based controllers, which opens up the possibility of applying RL-based controls to solve complex building automation problems [16]. 1.1 Multivariate building controls Existing studies focusing on the optimal control of HVAC systems typically consider a single control variable, such as the zone\u2019s temperature setpoint or supply airflow rate. However, modern HVAC systems may consist of more than one subsystem. Consequently, there is a need to control multiple variables simultaneously. Notable examples are radiant panels with dedicated outdoor air system (DOAS), mixed-mode ventilation systems, ceiling fans augmented air-conditioning, and personalized ventilation with ambient fan coil units. Independent univariate local controls are typically applied to operate each subsystem in these HVAC systems. However, it is necessary to ensure communication and cooperation between them to reach the full potential. Failing to consider possible subsystem interactions when developing a central control strategy could result in sub-optimal performance [17]. Multivariate control problems can be solved with multi-input-multi-output (MIMO) controllers. There are extensive studies on applying the self-tuning fuzzy PID (proportional\u2013integral\u2013derivative) or fuzzy PI-PD based control to the MIMO HVAC systems [18]. While these controllers are effective and robust, they are often not optimal because the predictive information is not considered and the adaptive adjustment ability is limited [19]. MPC is also a viable control strategy for MIMO systems owing to its capability of handling multivariate interactions and constraints. However, developing an efficient model for online optimization is not trivial [20]. Creating a model that accurately reflects system dynamics can also be challenging due to the ill-posedness of calibrating these models [21]. More recently, multi-agent RL algorithms were applied to the building domain for multi-dimensional action controls. Examples include multi-zone building control [22,23] and microgrid optimization [24,25]. In particular, some studies employed clustering-based methods to enhance the learning efficiency and stability of the agents with extremely large state\u2013action spaces [26]. However, in these multi-agent systems, each agent typically acted as a univariate controller and was responsible for one action dimension, and multiple agents worked together to complete control tasks. Although multi-agent RL is capable of multivariate building controls [27], its scalability remains challenging due to the need for many heterogeneous agents [28]. Hence, a more practical and intuitive approach to achieving scalability is implementing a single-agent multivariate control in individual rooms and extending it to multiple agent settings to control the whole building jointly. Leveraging advances in deep learning and RL, it is computationally tractable to learn policies in high-dimensional and continuous action spaces using deep function approximators [29]. Few studies investigated single-agent multivariate RL control in the field of building HVAC controls. Sun et al. [30] implemented a Lagrangian relaxation based method to co-optimized the fresh air unit and fan coil unit. Ding et al. [31] proposed a DRL-based framework that optimizes the control of four building subsystems (HVAC, window, blind and lighting). As high-dimensional action space in zone level control become increasingly important in buildings, more investigation is needed on how to efficiently implement multivariate HVAC control with single-agent algorithms, and how to scale them to multi-zone building using fully cooperative multi-agent methods. 1.2 Implementing DRL-based HVAC control Wei et al. [16] first applied DRL algorithms to HVAC controls in 2017. Using simulation, they showed that deep Q-network (DQN) outperformed the baseline rule-based approach and conventional Q-learning in building energy cost and temperature violation. Since then, DRL-related research has been increasingly applied in the field of building controls [32]. However, practical implementations of DRL-based building controls remain scarce, often being limited to domestic water heating [33] and lighting [34] control applications. Actual implementations are essential because many real-world challenges are often not reflected in virtual environments [35]. For instance, DRL is notorious for requiring large amounts of training data to achieve plausible results, making the learning process very inefficient in real-world operations [36,37]. Additionally, RL agents learn by exploring new actions, which will inevitably lead to undesirable outcomes when the algorithm performs sub-optimally [38]. Challenges encountered during the training process may also be overlooked in simulation-based studies because they usually focus on the final control performance (e.g., energy savings). Lastly, the high uncertainties in using actual thermal comfort votes [39] and the prevalence of faulty equipment and sensors in actual buildings [40,41] are often not considered in a virtual environment. Few studies demonstrated the improvements in control performance from using DRL in real buildings. Zhang et al. [42] pre-trained an A3C (Asynchronous Advantage Actor Critic) based agent on a calibrated building energy model before deployment in an actual office space to avoid inefficient learning. However, this algorithm required 3.5 million interaction steps (33 years in simulation) to achieve the satisfactory performance. Chen et al. [43] adopted a novel differentiable MPC policy in place of a generic neural network in the DRL. The pre-trained policy was directly deployed in a conference room for 3 weeks and the results showed that the proposed approach saved 16.7% of cooling demand compared to the existing PID controller. Although this approach was much more sample-efficient than conventional DRL algorithms, it assumed a linear model for the system dynamics, which may not extrapolate to more complex problems. Qiu et al. [44] optimized chiller performance by employing a chilled water reset strategy with a hybrid model-free RL. Specifically, the expertise knowledge was incorporated to dynamically narrow down the action space. The proposed method was compared with expert manual control in a real central chiller plant. In the context of using DRL for occupant-centric controls, wearable devices were often utilized to measure the physiological data. For example, Zhang et al. [45] used double deep Q-learning (Double DQN) to control the ceiling fan speed for 14 participants in an experiment room while considering their biological responses (wrist temperature, heart rate, and RR interval) and subjective thermal comfort votes in the control loop. Jung et al. [46] reduced thermal discomfort by 10.9% without increasing energy consumption using a one-dimensional convolutional neural network-based DRL algorithm that considers occupant activity from the smart wristband. While these studies showed that the thermal comfort can be maximized through the physiological information, they typically required the development of highly personalized comfort models prior to the control deployment. Consequently, occupants need to participate in dedicated comfort experiments for a few hours to collect the high granularity physiological data, which is difficult to achieve in practice. 1.3 Demand for occupant-centric comfort management in RL-based control Instead of controlling the indoor environment at a constant and fixed setpoint temperature, occupant-centric control intends to provide personalized comfort conditions based on occupants\u2019 feedback [47]. Studies have shown that conditioning the micro-environment of each occupant based on the matching personal comfort model often leads to co-benefit of energy savings and occupants\u2019 satisfaction [48,49]. A personal comfort model is used to predict the thermal comfort response of an individual rather than the average response of a large population [50]. Although the predicted mean vote and predicted percentage of dissatisfied (PMV-PPD) model is widely recognized, it is an aggregated model and has been shown to have poor predictive performance if applied to individuals or a small group of occupants [48,50]. Cheung et al. [51] analyzed the accuracy of PMV-PPD model using the ASHRAE global thermal comfort database II, and found the overall accuracy was only 34%. Additionally, the reliable range of the PMV is narrow, and it is also difficult and expensive to obtain full measurements of all input variables [52,53]. However, most HVAC control studies still use the PMV or pre-defined temperature ranges because the focus is often on achieving energy savings, and occupant satisfaction is usually not a primary consideration [54]. It has been shown that using the temperature as a reference for HVAC system operations is inadequate [55]. Thanks to the recent advancements in the occupant behavior sensing and modeling, high-accuracy occupancy presence detection technologies have become readily available [47]. Therefore, to have a tangible impact on both the energy efficiency and occupants\u2019 satisfaction in buildings, more research is needed to integrate the personalized thermal comfort modeling into actionable RL-based control frameworks. 1.4 Research gaps and objectives Two major gaps are identified in the existing literature. 1. Past research on the optimal HVAC control typically consider a single control variable, which cannot fully exploit the potential of HVAC systems comprising multiple subsystems. Dealing with high-dimensional action spaces is nontrivial because the computational cost for conventional DRL algorithms grows exponentially with the number of action dimensionality. 2. Efforts to incorporate personalized thermal comfort modeling into RL-based HVAC control loop have been limited, especially for real-world integration. Existing RL-based occupant-centric control studies typically rely on the personalized physiological data collected from dedicated comfort experiments prior to the control deployment, which limits their application and scalability. Therefore, this study proposed a new DRL control framework to fill the two knowledge gaps in an experimental-based study. The objective of this study is to develop a DRL-based multivariate control framework for building HVAC systems while considering personal thermal comfort and occupant presence. To that end, we applied a novel action branching architecture to efficiently solve control problems in multi-dimensional action spaces. A simple tabular-based personal comfort modeling method is also proposed, which fits naturally into human-in-the-loop building operations. To demonstrate the control performance, the proposed DRL agent is implemented in an actual office building with real-time occupant comfort votes. 2 Methodology This section presents the technical details used in the proposed multivariate DRL-based control framework. 2.1 Description of the DRL control framework As shown in Fig. 1, there are three key components in the proposed DRL control framework, which we elaborate in the subsequent sub-sections: \u2022 BDQ-based agent (Section 2.2). \u2022 Personalized thermal comfort matrix (Section 2.3). \u2022 Virtual environment for RL pre-training (Section 2.4). Broadly speaking, the implementation of RL-based control in actual buildings consists of 2 major tasks: (1) pre-training and (2) online learning. In the first task, the DRL agent is pre-trained offline in a virtual environment to ensure a plausible control performance and mitigate sub-optimal or unsafe actions [38]. We created the virtual environment with Modelica Buildings Library [56] and used the building\u2019s historical weather and operating data to calibrate the simulation model. A one-time preliminary comfort survey and the PMV model were used to initialize the personalized comfort matrix for the agent\u2019s pre-training. In the second task, the pre-trained agent would directly control the actual HVAC systems. During this process, the agent continuously refined its control policy by learning from the real-time feedback from the HVAC system and occupants. The daily agent online training was conducted at the end of the day (i.e., unoccupied hours). The personalized comfort matrix was updated daily based on the comfort votes, and the simulation model was also periodically re-calibrated with the latest building operating data. 2.2 Multivariate control with BDQ-based agent Due to the \u201ccurse of dimensionality\u201d, conventional DRL algorithms, such as DQN, are limited to problems with discrete and low-dimensional action spaces [28]. Yang et al. [57] showed that a univariate batch Q-learning agent required three years of training data to outperform a rule-based controller in a low exergy building. As the number of action variables increases, the training time duration will significantly increase because the number of sub-actions that need to be explicitly represented grows exponentially with the number of action dimensions [58]. Hence, this study implemented a novel action branching architecture to address the intractable training time in high-dimensional environments using conventional DRL algorithms. 2.2.1 Reinforcement learning Reinforcement learning is a branch of machine learning that enables an agent to interact with an environment and learn what actions to take based on the observed state of the environment. The agent learns by trial and error and is rewarded for desired behaviors and penalized for undesired behaviors [59]. In the context of HVAC controls, the RL agent refers to the controller, and the environment is the building or its virtual representation. The optimal control problem is modeled mathematically as a Markov decision process (MDP), as shown in Fig. 2. When executing a control task, a closed-loop process is performed as follows: At each time step, an agent observes a state S t = s representing the current situation of the environment. Following its control policy π , the agent takes action A t = α at time t , i.e., π ( s ) = α for a deterministic policy. In response to the action, after one time step, i.e., at time t + 1 , the agent finds itself at a new state S t + 1 = s \u2032 and receives a reward R t + 1 = r from the environment. Note that in DRL, the policy is commonly approximated by a deep neural network (DNN). The aim of the agent is to find an optimal policy that maximizes the discounted accumulated rewards ∑ t ∞ γ t R t by exploring different control policies. γ ∈ [ 0 , 1 ) is the discount factor. 2.2.2 Branching dueling Q-network This study leveraged the Branching Dueling Q-Network (BDQ), a branching variant of the Dueling Double Deep Q-Learning Network [58], to tackle multivariate control problems. \u2022 Double DQN In the standard DQN, the target network parameters are updated to reflect desired changes in Q-Values. However, it has been revealed that the target network is most likely to overestimate Q-Values since the same estimator is used to select and evaluate actions, leading to sub-optimal and unstable training [60]. The idea of the double DQN is to reduce overestimations by using two independent Q-Values estimators for action selection (on the online network) and action evaluation (on the target network). This algorithm not only yields more accurate value estimations but also finds better policies. \u2022 Dueling DQN The key idea behind the dueling architecture relies on the representation of the Q-Value of a state\u2013action pair Q ( s , a ) as two streams: the state-value V ( s ) and the advantages for each action A ( s , a ) . As shown in Eq. (1), the estimates of the value function are computed as the value of a given state and the value of the advantage of taking a particular action in this state, compared to all other possible actions in this state [61]. However, Eq. (1) cannot be directly used because it is unidentifiable. A common practice to address this issue is to force the advantage estimator to be zero at the best action for that state. Consequently, the maximum predicted advantage can be subtracted from the function as shown in Eq. (2). Many studies have suggested that the maximum operator in Eq. (2) can be replaced with an averaging operator for better performance [58,62]. Implementing the dueling architecture often leads to significant improvements in learning efficiency [61]. (1) Q ( s , a ) = V ( s ) + A ( s , a ) (2) Q ( s , a ) = V ( s ) + A ( s , a ) − m a x a \u2032 ∈ A A ( s , a \u2032 ) Fig. 3 illustrated the action branching network architecture for the proposed BDQ agent. The shared decision module consists of multilayer neural networks, which extract features from the input state. The latent representations are then decomposed into the state value and state-dependent action advantages for each subsequent independent branch. The latter is distributed on the several action branches, and each branch is responsible for controlling one dimension of the action. The Q-values for each action dimension is calculated by combining the state value and action advantages through a special aggregation layer. Finally, the argmax function is used to concatenate the joint-action tuples from sub-action branches. This network architecture achieves a linear increase in the number of network outputs by allowing independence for each action dimension, which is particularly efficient for multivariate tasks. Formally, for an action dimension d ∈ { 1 , \u2026 , N } , we discretize the it into n feasible sub-actions. A key concept of the dueling network architecture is to explicitly decouple the state value and the action advantages in deep Q-networks to enhance the learning efficiency and robustness [61]. Consequently, the individual branch\u2019s Q-value at state s when decision a d ∈ A d is taken can be expressed by: (3) Q d ( s , a d ) = V ( s ) + A d ( s , a d ) − 1 n ∑ a d \u2032 ∈ A d A d ( s , a d \u2032 ) Where V ( s ) denotes the common state value computed by the shared decision module and A d ( s , a d ) denotes the corresponding state-dependent action advantage. The temporal-difference (TD) target for BDQ agent can be calculated as: (4) y = r + γ 1 N ∑ d Q d − s \u2032 , a r g m a x a d \u2032 ∈ A d Q d ( s \u2032 , a d \u2032 ) Where r is the immediate reward after taking sub-action a d ; γ is the discount factor; and Q d − is the d th branch of the target network Q − , which will be periodically updated with the latest weights from the online network Q . Let D denote the replay buffer and a denotes the joint-action tuple ( a 1 , a 2 , \u2026 , a N ), the weights of the BDQ agent are iteratively adjusted by minimizing the loss function: (5) L = E ( s , a , r , s \u2032 ) ∼ D 1 N ∑ d y d − Q d ( s , a d ) 2 2.2.3 BDQ-based agent training The pseudocode for detailed training process of the proposed BDQ-based agent is outlined in algorithm 1. We considered each day as an episode. 2.3 Personalized thermal comfort matrix Although many studies have been conducted on personal comfort models, they often lack a vision for real-world integration in building controls [50]. This study proposes a personalized thermal comfort matrix that aligns with standard thermal comfort surveys and integrates individuals\u2019 comfort needs into the DRL control loop. Specifically, the comfort matrices (one for each occupant) are initialized based on the PMV model and a one-time preliminary comfort survey. The PMV model is used to develop the neutral-preference comfort matrices, then modified based on the survey responses. After initialization, the comfort matrices are used to pre-train the agent. Unlike many other data-driven personal comfort models requiring extensive training data, the proposed method relies only on a one-time survey before enabling online control. During the online learning phase, the initialized comfort matrices will be continuously updated through the real-time comfort votes. Gradually, each comfort matrix becomes customized for the corresponding occupant. Assuming that the personalized comfort level is mainly determined by two controllable indoor environment variables (e.g., room temperature and air velocity), we will discretize them into m and n intervals, respectively. Let C k denotes the m -by- n comfort matrix for k th occupant, where each entry ( c i j k ) ∈ R m × n represents the thermal discomfort penalty value at i th and j th environment condition. In particular, the thermal discomfort penalty must align with the standard thermal comfort surveys, such as the ASHRAE 7-point thermal sensation scale or the 4-point thermal acceptability scale [63]. An example of the thermal discomfort penalty values can be defined in the following format to map the personalized comfort level to the RL reward calculation: {Clearly acceptable (0), Just acceptable (−1), Just unacceptable (−2), Clearly unacceptable (−3)}. Note that instead of directly learning from occupants\u2019 feedback, the proposed agent always interact with the comfort matrices for two reasons. First, since real-time comfort votes at a high temporal granularity are difficult to acquire, the control time step is usually much smaller than the comfort survey interval. Consequently, a personal comfort model is needed to compute the reward for the agent at every control time step. Second, the real-time comfort votes may include inconsistent responses due to the recall bias [39], which will confuse the learning agent. Hence, the comfort matrices also act as a \u201cbuffer\u201d to consolidate inconsistent comfort votes, thereby stabilizing the online learning. The detailed process for the initialization and online update of the proposed personalized comfort matrix is illustrated in Section 3.3. This study employed a two-dimensional matrix because it was assumed that the thermal comfort is mainly related to the two environmental variables in the experiment setting, which can be easily extended to higher dimensions if more variables are considered. 2.4 Virtual environment for agent training RL agents learn to make better decisions by trial and error, inevitably leading to unsafe actions. Virtual environments play an essential role in RL research in mitigating undesirable outcomes during the exploration and accelerating the training process. In this study, the offline pre-training and the early stage of online training are done by having the agent interact with a Modelica-based virtual environment, as shown in Fig. 1. The BDQ agent training relies on the prioritized experience replay technique. It stores trajectories of experience in a replay buffer and lets off-policy agents reuse past experiences and prioritize important transitions. At each training step, a mini-batch of experiences will be sampled from the replay buffer to update the weights of the deep neural network. This technique has been shown to significantly improve the sample efficiency and stability of the network during training [64]. We selected Modelica over other traditional building simulation tools, such as EnergyPlus and TRNSYS, because it inherently models the building control dynamics without relying on additional software or scripts. To allow co-simulation between the DRL agent and the virtual environment, an OpenAI gym [65] interface wrapper for the pre-compiled Modelica model is developed based on PyFMI [66]. The data sources and their usage at different agent training phases are summarized in Table 1. During offline pre-training, the virtual environment provides synthetic building operating data based on historical weather files, and the initialized comfort matrix mimics the comfort feedback of the actual occupants. The deep neural network training and hyperparameters tuning are performed to maximize the reward in this interactive simulation environment. Finally, the pre-trained agent with fine-tuned hyperparameters is prepared to control the actual HVAC system. By contrast, the online agent training is divided into two stages. At the early stage, the agent still interacts with the virtual environment. This is because, in principle, the size of the replay buffer should be large enough to contain a wide variety of experiences; otherwise, the network tends to overfit the most recent trajectories and forget what it has learned from previous experiences. Consequently, the replay buffer needs to collect many experiences before starting training. Since only limited data is collected at the early stage of online deployment, the agent is trained daily in the virtual environment with the updated personalized comfort matrices. However, at the late stage, once the reply buffer is filled with the data from the actual HVAC system, the agent will directly learn from the BMS data onwards. Zhang and Sutton [67] compared the performance of different replay buffer sizes in two notable control tasks and concluded that 1 0 3 to 1 0 4 is the optimal size. Hence, the transition from online agent training with the virtual environment data to the actual environment data takes about 5 to 10 weeks. Throughout the early stage of online training, automated model calibration is conducted periodically to address the discrepancy between the virtual and actual environment. Gaussian Process-based Bayesian Optimization (GP-BO) is applied for calibration. Over BO iterations, the calibrated parameter sets and corresponding objective values are collected. A Gaussian Process is used to model the parameter ↦ objective relationship, and parameters that possess a higher probability of minimizing the objective function are accordingly selected for the next iteration until the threshold is met. Several studies have revealed that the Bayesian calibration provides better accuracy with reduced parameter uncertainty [68]. More details about GP-BO can be found in [69]. 3 Case study 3.1 Building and system The proposed DRL control framework was implemented in an actual office building. Located on the National University of Singapore (NUS) campus, the SDE4 building is a net-zero energy and WELL platinum certified building. It employs a novel hybrid cooling system that consists of DOAS units and ceiling fans. This system can deliver better indoor air quality since the DOAS provides 100% conditioned fresh air. With the help of ceiling fans, significant energy savings can be achieved because the building is operated at an elevated room temperature and air movement, using the extended thermal comfort boundaries suggested by ASHRAE Standard 55 [70]. According to a previous study [71], the optimal operating condition for this hybrid system is 27 °C room temperature with fan speed mode 3, which leads to energy savings while achieving both occupant thermal and IAQ (indoor air quality) satisfaction. Compared with 24 °C temperature setpoint in typical office buildings, they estimated that the annual HVAC energy consumption was reduced by 26% under this operating condition. However, the occupant presence was not considered in their study, which could lead to a sub-optimal thermal environment in the actual building. Considering the personalized thermal comfort and occupant presence, the proposed DRL-based controller can dynamically choose the optimal temperature setpoint and speed for each ceiling fan to improve the control performance. Approved by the Institutional Review Board (IRB), an open office located on the 3rd floor of the SDE4 building was selected to conduct the experiment. As illustrated in Fig. 4, it is 164m 2 and provides workspaces for 16 resident occupants. However, due to the safety measures for the COVID-19 pandemic [72], only eight occupants participated in the experiment since other people could not commit to coming to the office regularly. Participants were students and research staff from different countries between 20 to 40 years old. The experiment area has four ceiling fans, each serving four desks. We assumed that the air movement at each desk is mainly determined by the closest ceiling fan. 3.2 DRL control for the hybrid cooling system 3.2.1 State design Each state observation consists of 10 items shown in Table 2. Min-Max normalization is applied to constrain their values between 0 and 1 (Eq. (6)). o b m i n and o b m a x are the lower and upper bounds of the state items. The real-time state variables can be accessed via the BAS. Note that only the latest data stored in the BAS from the current control time step was used, so weather forecasting is not required for this study. (6) o b n o r m = o b − o b m i n o b m a x − o b m i n 3.2.2 Action design The action space is 5-dimensional, including the room temperature setpoint and four ceiling fans\u2019 speed mode. The temperature setpoint can take seven discrete values at 0.5 °C interval: {26 °C, 26.5 °C, 27 °C, 27.5 °C, 28 °C, 28.5 °C, 35 °C}, and each ceiling fan can take 6 actions: {M0 (off), M1, M2, M3, M4, M5}. Consequently, the action space totals up to 9,072. Formally, for an environment with an N -dimensional action space and n d discrete sub-actions for each action dimension d , there are a total of ∏ d = 1 N n d possible actions to be considered if using conventional DRL algorithms. This will rapidly encounter the issue of exponential explosion for the domains with large action spaces. In particular, 35 °C is the setback setpoint during the occupied hours, during which the supply airflow of the DOAS is kept at the lowest limit (10%). This value complies with the minimum outdoor air requirements in the local building code. Additionally, the BDQ agent can be extended to solve problems with continuous action spaces; however, finer room temperature setpoint resolutions are often unnecessary in real buildings and may even lead to conflicting comfort feedback from untrained occupants. Jung and Jazizadeh [73] compared three control setpoint resolutions, i.e., 0.1 °C, 0.5 °C, and 1 °C, and found that finer resolutions did not show any statistically significant impact on the average occupant satisfaction because ordinary occupants often cannot tell slight temperature differences. Accordingly, a relatively coarse resolution of 0.5 °C was used in this study. 3.2.3 Reward design The reward design is empirically determined to achieve better training convergence rate and balance between thermal comfort and HVAC energy consumption, which is calculated by: (7) D P ¯ = ∑ k = 1 K c i j k ∗ P r e s k / ∑ k = 1 K P r e s k (8) R = − η ∗ D P ¯ + λ β + E H V A C | O c c . F l a g = 1 η ∗ D P ¯ + λ β + δ ∗ E H V A C | O c c . F l a g = 0 Where D P ¯ denotes the mean discomfort penalty for the occupants who are currently present in the office. K is the number of total occupants. c i j k is the thermal discomfort penalty for the k th occupant at the i th room temperature and the j th fan speed mode, which can be looked up from the personalized comfort matrix. P r e s k is the binary presence indicator for the k th occupant, and it is 1 when the corresponding occupant is present. D P ¯ is computed as the arithmetic mean of the discomfort penalties considering the current occupant presence. E H V A C is the total HVAC energy consumption (kWh) during the last control time step. The detailed calculation of the energy consumption associated with this experiment space can be found in Section 3.6. η and δ are tunable hyperparameters. Specifically, η balances the relative weights between the energy use and the thermal comfort, and δ penalizes any excessive energy consumption during unoccupied hours when the thermal comfort is not the main concern. Lastly, λ and β are used to re-scale the mean discomfort penalty. We first tuned η to ensure that the thermal discomfort penalty and energy consumption are of similar magnitude during the occupied hours ( O c c . F l a g = 1 ). Since D P ¯ took a much smaller absolute value than E H V A C in this study, η had to be large, and a slight change in D P ¯ would significantly affect the total reward R . As mentioned in Section 2.3, the discomfort penalties from the personalized comfort matrix take integer values, which intends to align with the standard comfort votes. Consequently, D P ¯ could fluctuate drastically when the number of present occupants is small. For example, when a participant reports that the indoor environment is \u2018unacceptable\u2019 (−2), the change in the mean penalty value would be −0.67 if three occupants were present and −0.25 if eight occupants were present. This discrepancy could lead to a very unsmooth reward function, making the agent easily get stuck in a local optimum. To deal with it, we found that applying a transformation (with scaling factors λ and β ) to D P ¯ was effective in smoothing out the changes in the rewards. Additionally, β also helped further penalize large discomfort penalties. The hyperparameters of the reward were empirically fine-tuned on the virtual environment. 3.3 Personalized comfort matrix initialization and online update In this section, an example is provided to demonstrate the development of the personalized comfort matrix. The two controllable environment variables are the room temperature and air velocity in this experiment. The proposed personalized comfort matrix takes them as inputs and maps the thermal discomfort level (discomfort penalties) to the RL reward calculation. Following [71], two short comfort questionnaires were used in this study via the Google Form platform. The preliminary comfort survey was carried out to initialize the personalized comfort matrices for the eight participants. The online comfort survey was disseminated every 60 min only to the occupants present in the office during the online deployment. The feedback collected was used to update the comfort matrix at the end of the day. The participants were allowed to answer the questionnaires voluntarily, and reimbursements were made upon completion of 75% of them. We recorded the room temperature and fan speed mode at the time when survey responses were received. Since there are no occupancy sensors in this building, we manually detected the occupants\u2019 presence every 30 min from 10:00 am and 6:00 pm daily. The initialization and online update process are detailed below (see Fig. 5). A one-time preliminary comfort survey and the PMV model were used to initialize the personalized comfort matrix for the agent pre-training. As shown in Fig. 12(a) in Appendix, this 4-question survey collected information about occupants\u2019 typical clothing type (Q1), overall thermal preference (Q2), overall air movement preference (Q3), and the general opinion about their current indoor environment (Q4). The 3-step initialization procedures are as follows: Step 1. The on-site air velocity measurement was taken at different ceiling fan modes. Along with the occupant\u2019s clothing type (Q1), PMV values were calculated at different combinations of room temperature and fan mode, which were then translated into 4-point discomfort penalties. The ASHRAE Standard 55 recommends that the PMV index is within ± 0 . 5 limits. However, it will lead to a wide thermal acceptable range in the comfort matrix. To ensure a higher level of satisfaction, we considered a more stringent limit and started penalizing PMV values over ± 0 . 3 . At this point, a neutral-preference personalized comfort matrix was developed. Step 2. Based on the occupants\u2019 perceptions of the current indoor environment (Q4), neutral-preference matrices were shifted towards the top-right corner if they prefer warmer or towards the bottom-left corner if they prefer cooler. This experiment assumed that one scale difference in Q4 can be compensated for by one level of change in both the temperature setpoint and fan mode. In other words, the comfort matrices would be shifted only in the diagonal direction. Step 3. Fan mode constraints were incorporated to account for the difference in occupants\u2019 tolerance for elevated air movement. Specifically, an additional penalty of 1 or 2 will be added for all environmental conditions in the comfort matrices where the fan mode is higher than the occupants\u2019 preferred fan mode in Q3. After that, the initialized personalized comfort matrices were prepared. Another 5-question online comfort survey was employed to collect real-time thermal comfort feedback and to continuously update the personalized comfort matrices (Fig. 12(b) in Appendix). Q1 asked the time length of stay in the office. Since we only consider the thermal comfort in steady-state conditions, transient comfort votes (occupants sitting for less than 15 min) were excluded. Q2 was a standardized question for 7-point Bedford scale comfort descriptors. The online update of the personalized comfort matrices was based on the Q3 and Q4 votes, which sought to understand the occupants\u2019 acceptance of their current thermal environment and air movement. Note that occupants may give distinct comfort votes under the same indoor conditions. To alleviate this uncertainty and avoid unstable changes in the control strategy, the actual votes collected were not directly used for the agent training. Instead, each discomfort penalty value in the comfort matrix was periodically updated to the comfort vote that occurred the most frequent (i.e., mode) under the particular combination of room temperature and fan mode. In this way, the agent interacted with those personalized comfort matrices rather than the actual real-time votes, resulting in a more stable learning process. 3.4 BDQ-based agent training setup Prior to any interaction with the actual building, the proposed BDQ agent was pre-trained in the virtual environment with three years (2018, 2019 & 2020) of Singapore\u2019s actual meteorological year (AMY) weather data, of which the first two years of data was for training and the remaining year of data was for testing. Table 3 summarized the agent training setups and hyperparameters used. Since the action space was 5-dimensional in this experiment, the BDQ agent had five network branches. The size of each network layer is indicated in Fig. 3. To encourage the agent to explore the environment, we sampled actions from a Gaussian distribution with its mean at the greedy actions. Following a linear schedule, the standard deviations started at 0.4 and decreased to 0.05 after the second year. This experiment involved eight occupants with a total of 2 8 different occupant presence states. However, in practical applications, since some occupancy states (e.g., 100% occupied) would occur much more frequently than others (e.g., 0% occupied), the control performance would not compromise too much if we only focus on the most frequent occupancy states. Furthermore, long-term historical occupancy data is often unavailable in real-world buildings, making it difficult to train offline agents that take high-granularity occupancy data as their state input. Hence, we simplified the control problem by developing multiple DRL policies, each of which was only responsible for a specific occupancy state. This experiment selected the most frequent 16 out of the 128 possible occupancy states based on a short-term occupancy presence observation. At each control time step, one of the 16 trained policies will be put in charge based on the latest occupancy presence detection. Consequently, by eliminating the dependency of the occupancy presence information as the agent\u2019s state inputs, the training process involves updating 16 policies in parallel, which significantly reduces the occupancy data required for offline training. 3.5 BDQ-based agent online deployment The BDQ agent was deployed for two weeks to control the hybrid cooling system. The deployment setups and the hyperparameters were the same as those used in pre-training, except that the control time step was changed to 30 min, as the daily temperature in the tropics is relatively stable and our experiment involves a few manual tasks. At each control step, we manually detected the occupant presence states and selected the appropriate BDQ policy to be put in charge. The agent received the latest readings of state variables from the BAS and chose the optimal actions accordingly. The sub-action for temperature setpoint was sent directly back to the BAS, while the sub-action for ceiling fan mode was executed through a local router. The personalized comfort matrices were updated daily at the end of the day based on the online comfort survey votes, and the virtual environment was re-calibrated automatedly once a week using the operating data from the past week. As aforementioned, the model calibration is performed only at the early stage until the reply buffer is filled with measurement data. Since we only maintained the top 16 BDQ policies, there may be occasional occurrences of occupancy presence states that are not covered. In these cases, we would always use the available policy corresponding to a similar occupancy state. Indeed, according to the historical data, the selected 16 most frequently occurring occupancy states had already covered the actual occupancy states for 86% of the time. 3.6 Performance evaluation The control performance of the proposed DRL framework was evaluated against the baseline control strategy (27 °C with fixed fan speed at M3). The performance metrics are the total HVAC energy consumption, total thermal acceptability rate, and total air movement acceptability rate. The total HVAC energy ( E H V A C ) of the hybrid cooling system consists of the district cooling plant energy, DOAS fan energy, and ceiling fan energy. The DOAS unit that serves the experiment space also supplies outdoor air to other spaces. While the plant and DOAS energy were not metered at the room level, we used Eqs. (9) and (10) to estimate the energy consumed by this room. Specifically, the cooling plant energy ( E P l a n t ) was computed using the enthalpy difference between the room air and supply air ( H R o o m and H S u p p l y A i r ). The DOAS fan energy ( E D O A S ) was assumed to be proportional to the ratio of the room\u2019s supply airflow ( V R o o m ) to the system\u2019s total supply airflow ( V S y s t e m ). ρ A i r denotes the air density at room temperature and η P l a n t denotes the coefficient of performance (COP) of the chilled water plant. (9) E P l a n t = ρ A i r ( H R o o m − H S u p p l y A i r ) V R o o m / η P l a n t (10) E D O A S = E S y s t e m ( V R o o m / V S y s t e m ) The proposed and baseline control deployments were conducted over a consecutive 4-week time period. The baseline control strategy was run three days before, two days in between, and one day after the DRL-based agent deployment to account for any changes in occupants\u2019 schedules or the seasonal divergence of thermal satisfaction. In practice, it is infeasible to operate the proposed control and the baseline control simultaneously, making it difficult to compare them under different outdoor weather conditions and occupancy states. Following [11], to ensure a fair comparison, for each day of the DRL control, we took the energy consumption data and compared it to the baseline day that had the most similar average outdoor temperature and solar radiation during the occupied hours. 4 Results 4.1 Training with the virtual environment Fig. 6 compares the convergence of the BDQ and the Double DQN algorithm in the pre-training. The BDQ agent achieved training convergence in less than a year, which was significantly faster than the time duration of the conventional DRL algorithm, indicating that the BDQ agent handled high-dimensional action spaces more efficiently in this multivariate control task. Note that rewards fluctuated between episodes, especially in the early phase. This fluctuation is because not only is the reward highly related to the outdoor weather, but random actions (determined by a Gaussian distribution) were taken over some timesteps to encourage the agent to explore the environment. In particular, the exploration probability was linearly annealed during the training. Based on preliminary sensitivity analysis, four parameters were selected to calibrate the virtual environment: floor thermal conductivity, leakage area, internal thermal mass, and effective window area. Root mean squared error (RMSE) of room temperature at 15-minute resolution was adopted as the objective function. The automated model re-calibration took place after the first week of deployment, during which the RMSE was reduced from 0.91 °C to 0.41 °C, indicating a more representative thermal dynamics. Fig. 7 compares the predicted thermal responses obtained before and after the GP-BO based calibration. As per ASHRAE Guideline 14 [74], the re-calibrated model had a Mean Bias Error (MBE) and Coefficient of Variation of the Root Mean Squared Error (CVRMSE) of 0.7% and 1.5%, respectively. 4.2 Analysis of control actions for a typical day Fig. 8 presents an overview of the 5-dimensional control actions and the corresponding occupant presence for a typical day. Four different colors were used to map the occupants to their closest ceiling fans, as shown in the bottom part of the figure. It is apparent that the BDQ agent tried to maximize the rewards by pushing the room temperature up to around 28 °C. To further reduce the energy consumption, the agent used the setback setpoint for the minimum outdoor airflow rate, allowing the room temperature to float towards the end of the occupancy. This controlling behavior happened almost every day. The length of time to use the setback setpoint was usually 30 or 60 min and was highly dependent on outdoor conditions. Through the interactions with the high-fidelity virtual environment, the agent appeared to learn that using the setback setpoint can maximize the reward. This is because the energy consumption is minimal at this setpoint, and the room temperature does not rise too quickly to cause discomfort due to the thermal lag. Additionally, the room temperature fluctuated by about 0.3 °C throughout the day. Given that this is an open-plan office, this discrepancy could be attributed to the constant movement of occupants, the opening and closing of doors, or the sensor measurement errors. Depending on the occupants\u2019 presence, the ceiling fans\u2019 mode was dynamically adjusted throughout the day to compensate for the elevated room temperature. Fig. 13 presents the initial and final personalized comfort matrix for each participant is presented. Occupant #2 had a warm preference; thus, fan 2 was operated under either M0 or M1 in the morning and early afternoon when this occupant was alone under the fan. Since occupant #1 and #2 shared the same fan and occupant #1 had a neutral preference, fan 2 was increased to M2 after occupant #1 arrived at the office around 16:00. Additionally, the agent temporarily turned the temperature setpoint down to 27.5 °C at 13:00 upon the arrival of occupant #4, who preferred a neutral to cool environment. The setpoint was raised again to 28 °C as soon as occupant #2 returned around 13:30. Fan 3 and fan 4 were operated at M3 most of the time because both occupant #7 and #8 had similar neutral to cool thermal preferences. Note that occupant #3 and #6 were not present at the office on this day. These control actions suggest that the BDQ agent is capable of dynamically choosing appropriate actions based on occupant-specific thermal comfort. 4.3 Comfort performance evaluation based on real-time votes Before online learning begins, we compared the pre-training performance of the proposed BDQ agent with two benchmarks in terms of the thermal and air movement acceptability as shown in Fig. 9. In addition to the baseline control, RL+PMV is also considered because the PMV is widely used as the indicator of thermal comfort in RL studies on building control. RL Day 1 is the first day of deployment of the proposed BDQ agent in the actual building prior to any online update. Hence, the difference in control performance between RL Day 1 and RL+PMV can only be caused by the different thermal comfort information used for offline training. Although the baseline strategy achieved a rather good total thermal acceptability rate of 88%, the proposed BDQ agent slightly outperformed it on day 1. More importantly, training the agent using the PMV index as the thermal comfort metric led to the worst control performance. Initializing the comfort matrix with just a one-time comfort survey improves the total thermal acceptability by 25% over the PMV method. This result is expected because the standard PMV calculation does not consider any air movement limits. Consequently, the agent pushed the energy reduction too aggressively by using the maximum temperature and fan speed available at all times. Consistent with previous literature, this finding supports that the PMV index is often insufficient for individuals because thermal neutrality is not the same as occupant satisfaction. Thanks to the one-time preliminary comfort survey, the differences in personal thermal comfort preferences can be captured prior to the deployment, which greatly facilitates the learning process. 411 valid real-time comfort votes were collected during the experiment period. Fig. 10 illustrates the thermal and air movement acceptability rate during the online deployment. Due to the small daily sample size, we combined the votes for the second week (RL Day 6 to RL Day 10) of the DRL control for a fair comparison with the baseline. The total thermal acceptability rate was improved by 11% to 99%. Additionally, there was a gradual rise in the ratio of \u2018Clearly Acceptable\u2019 votes for both thermal and air movement performance. The pink line in Fig. 10 indicates the p -value of the Chi-square test for the daily \u2018Clearly Acceptable\u2019 rate compared to the one in the baseline. The results show that the proposed BDQ agent achieved a 31% increase in clear thermal acceptability rate and the improvement was statistically significant with 95% confidence since day 5 of the deployment. Furthermore, a strong positive correlation (r(8) = .88, p < .01) was observed between the thermal and air movement acceptance votes, which implies that the air movement is a critical factor in the overall thermal comfort of this hybrid cooling system. 4.4 Energy performance evaluation results Table 4 summarizes the daily energy consumption and the corresponding outdoor weather information. During the experimental period from 10:00 am to 6:00 pm, the mean normalized baseline energy consumption was 15.3 kWh. By contrast, the BDQ agent consumed 13.1 kWh of HVAC energy per day on average, which yielded 13.9% of HVAC energy reduction. Given that the baseline control strategy in the SDE4 building has already achieved net-zero energy, the energy performance of the proposed control framework is very significant. Additionally, the ceiling fans consumed less than 3% of the total HVAC energy in both cases, indicating that raising room temperature and compensating for it by increasing air movement is a very promising energy-efficient measure without compromising the thermal comfort. Closer inspection of Table 4 shows that there is a significant positive correlation (r(10) = .87, p < .01) between the HVAC energy consumption and the mean solar radiation. Since there is not much daily variation in mean outdoor temperature in Singapore\u2019s climate, its outdoor solar radiation greatly affects the daily mean HVAC energy consumption. By further analyzing the hourly cooling demand profile, we observed that the hotter the outdoor weather, the more energy reduction could be achieved through the DRL control. However, when the outdoor temperature was below 28 °C and solar radiation was below 300 W/m 2 , the DOAS unit mostly operated at its lowest airflow rate, regardless of the temperature setpoint used. Lastly, Monday (baseline day 1 and RL day 4 & 9) tended to consume more energy than other weekdays. The difference was due to the thermal mass of the building that built up heat over the weekend, increasing the cooling demand on Monday. 4.5 Analysis of online update for personalized comfort matrix As shown in Fig. 13, the differences between the initial and final personalized comfort matrices are generally small, except for occupant #1 and #2. The comfort matrix for occupants #3 and #8 has not even changed. These results suggest that the proposed simple comfort matrix initialized with the one-time survey effectively captured most of the personal comfort information in this experiment. 5 Discussion 5.1 Advantage of BDQ-based agent According to the learning curve shown in Fig. 6, both the BDQ agent and the conventional DRL agent eventually reached a similar level of reward, indicating that they converged to similar final performance levels for this task. However, the BDQ agent significantly outperformed its counterpart in terms of sample-efficiency. Specifically, the BDQ agent not only found the path to accelerate the learning progress earlier but also learned at a faster rate with a steeper learning curve. This difference may become more pronounced when the action dimensionality is further increased. Since there are always discrepancies between simulated and actual environments, and the thermal dynamics of actual environments may change over time, sample-efficient agents will provide better adaptive performance during online training. Moreover, we observed that the BDQ agent converged to the optimal policy in a stable manner. A possible explanation for this might be that the use of the shared decision module enabled a form of centralized coordination. 5.2 Mismatch between thermal acceptability and thermal comfort The online comfort survey included both the thermal acceptability scale and the Bedford thermal comfort scale. Interestingly, there was a discrepancy between the occupants\u2019 responses to the two questions. According to dedicated thermal comfort studies [75], the thermal comfort votes falling in the categories of \u2018Comfortable\u2019, \u2018Comfortably Cool/Warm\u2019, or slightly \u2018Cool/Warm\u2019 should be perceived as thermal acceptable. As can be seen from Fig. 11, the thermal comfort votes received throughout the BDQ deployment period except for RL Day 1 and RL Day 2 were within the acceptable categories. However, this observation was not in good agreement with the votes obtained from the thermal acceptability scale (as shown in Fig. 10), and the discrepancy is more significant if we compare the rate of \u2018Comfortable\u2019 and \u2018clearly acceptable\u2019. The reason for this is unclear but may be related to the elevated airflow. Additionally, some participants may be unfamiliar with the definitions of terms used in the questionnaire. It is important to note that this study considers total thermal acceptability as the comfort performance metric. However, if we evaluate the comfort performance by the Bedford scale, the improvement due to the proposed DRL control was 16% (77% to 93%). 5.3 Justification of energy reduction The 13.9% HVAC energy reduction was determined by the measured data. To consider a wider range of weather conditions, we also compared the annual energy consumption between the proposed BDQ agent and the baseline in the virtual environment. We applied the same schedules as in the 4-week experiment period for the occupancy, lighting and plug load to the simulation model. Additionally, the discomfort penalty values from the final personalized comfort matrices on day 10 were used to mimic the real-time comfort votes for the control. Hence, the comfort matrices were not updated throughout the simulation. Based on the aforementioned assumptions, the estimated HVAC energy savings were 9.5% for Singapore\u2019s 2020 AMY weather dataset, which was less than the experiment results. This inconsistency could be due to potential errors that occurred during weather normalization calculations. Another possible explanation for this may be the mismatch between the actual and the simulated environment despite the use of advanced model calibration techniques. The model assumes well-mixed air, which is often not the case in reality, mainly because occupants and electrical equipment are unevenly distributed across the space. We speculate that since the exhaust from the experimental room depends entirely on pressure difference (no mechanical exhaust in the system), the higher supply airflow rate in the baseline control may lead to a short air circuit and higher leakage rate, resulting in wasted cooling energy. 5.4 Importance of considering personalized comfort in HVAC control The findings presented in Section 4.3 are in agreement with those obtained by previous thermal comfort research that controlling buildings based on average occupants is insufficient for comfort [47,50]. However, personalized comfort is often not considered in studies on advanced HVAC controls. In this experimental setup that allowed for increased airflow, a simple one-time comfort survey significantly helped improve the thermal control performance compared to using the PMV index alone. Therefore, it is worth exploring how to integrate personalized comfort information in the control loop to facilitate the practical application of advanced HVAC controls in buildings. The proposed tabular-based personal comfort modeling method with periodical updates showed a promising thermal acceptability result, which has the potential to be used in a broader range of applications. Further research should be undertaken to investigate the robustness and generalization of this method. 5.5 Necessity of a virtual environment for agent pre-training Virtual environments are useful for training the RL agent due to the realism and flexibility that they offer. There is no doubt that high-fidelity building models are expensive to create. On the one hand, they usually require extensive domain knowledge about the dynamics of complex building systems. On the other hand, high granularity data needed to calibrate or identify those models is often difficult to acquire. A previous study showed that RL agents can be pre-trained using imitation learning, thus eliminating the need for a high-fidelity model [43]. However, a number of studies have shown that the performance of RL algorithms is very sensitive to numerous hyperparameters [76,77], such as the learning rate, reward decay factor, and network architecture. Without a proper virtual environment to pre-train the agent offline, fine-tuning these hyperparameters only during online deployment can be significantly inefficient and even lead to catastrophic consequences due to unsafe exploration. Furthermore, Wang and Hong [38] pointed out that simulation models do not have to be very accurate because the pre-trained policy will be further improved when interacting with the actual environment. However, more research should be undertaken to investigate what are the minimum performance requirements for a satisfactory virtual environment. 5.6 Potential implementation strategy in practice The proposed DRL based occupant-centric control framework has demonstrated promising control performance in the experiment setting. However, its online learning phase heavily relied on the high temporal granularity comfort survey (i.e., every 60 min), which is challenging to carry out in practice. By analyzing the daily changes in the personalized comfort matrices, we found that 5 of the 8 comfort matrices had few new updates after the 4th day of the online deployment, as the corresponding occupants voted for \u2018Clearly Acceptable\u2019 for most of the time. Additionally, there were no updates for all the matrices on the 10th day. This implies that frequent comfort surveys may not be necessary for most occupants. Therefore, instead of using a fixed survey schedule, we can consider asking occupants to voluntarily submit comfort surveys only when they feel uncomfortable. This can be done by placing a QR (quick response) code linked to the comfort questionnaire on their desks. Alternatively, we could adopt the sparse sampling technique to develop a parsimonious survey schedule [78]. As wearables are becoming ubiquitous, it will be easier to collect personal comfort data in natural environments [79]. In both ways, the frequency of the need for comfort surveys would be significantly reduced, making practical implementations of the proposed control framework feasible and scalable in occupants\u2019 natural office environments. 5.7 Limitations The main weakness of this study was the lack of long-term demonstration of the agent\u2019s online training performance directly using the BAS data. Since this study relied on repeated comfort surveys and survey fatigue started to appear at the end of our experiment, the agent was deployed online for only two weeks. Consequently, the online agent training was based on the periodically re-calibrated simulation model. Another potential problem is that occupant presence data was required at a high granularity in this control framework, which is expensive and difficult to obtain. We assumed that the occupancy presence was perfectly known by using manual observations in this experiment, while fault-free occupancy sensing is rare in real buildings. Last but not least, maintaining multiple BDQ policies is inefficient and may lead to sub-optimal performance because these policies are trained independently and a few policies are updated more frequently than others. Consequently, switching between policies may lead to unstable or inconsistent control strategies if the occupancy state changes frequently. 6 Conclusion and future work This study proposes a practical DRL-based framework for multivariate occupant-centric HVAC control. Our approach enables a linear growth of the total number of network outputs with the increasing HVAC action dimensionality, which improves the learning efficiency for controlling HVAC systems consisting of multiple subsystems. Additionally, the personalized thermal comfort matrix that maps the discomfort level onto the RL reward is presented, which can be easily integrated into human-in-the-loop building operations. The proposed agent was deployed in an actual office to validate the control performance, dynamically controlling its room temperature setpoint and ceiling fans\u2019 speed mode. Compared to the baseline optimal static control strategy, the proposed agent achieved a 13.9% cooling energy reduction and an 11% total thermal acceptability improvement based on the deployment results. The offline training in simulation showed that the BDQ-based agent was significantly more sample-efficient than the standard Double DQN algorithm. More importantly, it has been revealed that initializing the comfort matrix based on a one-time comfort survey is effective for capturing individual differences in thermal comfort, as this brought 25% thermal acceptability improvement over the PMV method to the proposed control framework. This is the first DRL-based multivariate HVAC control study that has been implemented in a real building. It highlights the importance of considering individual differences in the thermal comfort for building operations. As future work, to improve the scalability and robustness of the control framework, we will explore effective approaches to encode occupant presence information in state inputs instead of maintaining multiple policies. Besides, since developing a high-fidelity virtual environment is expensive and an overly accurate model may not provide obvious benefits for the agent pre-training, further investigation is needed to determine the minimum performance requirements for a satisfactory virtual environment. Moreover, this study employed the automated model calibration to address the discrepancies between the simulated and real environments. It is worth investigating more sim-to-real transfer techniques for efficient and generalized policy transfer. Last but not least, it is necessary to extend the BDQ agent to multi-zone building controls using cooperative multi-agent techniques. CRediT authorship contribution statement Yue Lei: Conceptualization, Methodology, Data curation, Formal analysis, Investigation, Visualization, Writing \u2013 original draft, Writing \u2013 review & editing. Sicheng Zhan: Software, Visualization, Writing \u2013 review & editing. Eikichi Ono: Validation, Writing \u2013 review & editing. Yuzhen Peng: Writing \u2013 review & editing. Zhiang Zhang: Writing \u2013 review & editing. Takamasa Hasama: Project administration. Adrian Chong: Conceptualization, Supervision, Project administration, Funding acquisition, Writing \u2013 review & editing. Declaration of Competing Interest Adrian Chong reports financial support was provided by Kajima Technical Research Institute Singapore (KaTRIS). Acknowledgments This research is supported by Kajima Corporation, Japan through its Kajima Technical Research Institute Singapore (KaTRIS) (Project No. A-0008298-00-00). Appendix Comfort surveys and personalized comfort matrix See Figs. 12 and 13. References [1] Center B.P. Annual energy outlook 2020 Energy information administration, Washington, DC. Vol. 12 2020 1672 1679 B. P. Center, Annual energy outlook 2020, Energy Information Administration, Washington, DC 12 2020 1672\u20131679,. [2] Commission E. A renovation wave for Europe\u2014Greening our buildings, creating jobs, improving lives Communication from the commission to the European parliament, the council, the European economic and social committee and the committee of the regions 2020 European Commission Brussels Belgium E. Commission, A renovation wave for europe\u2014greening our buildings, creating jobs, improving lives,2020. [3] Fernandez N.E. Katipamula S. Wang W. Xie Y. Zhao M. Corbin C.D. Impacts of commercial building controls on energy savings and peak load reduction Technical Report 2017 Pacific Northwest National Lab.(PNNL) Richland, WA (United States) 10.2172/1400347 N. E. Fernandez, S. Katipamula, W. Wang, Y. Xie, M. Zhao, C. D. Corbin, Impacts of commercial building controls on energy savings and peak load reduction, Technical Report, Pacific Northwest National Lab.(PNNL), Richland, WA (United States),2017.10.2172/1400347. [4] Frontczak M. Schiavon S. Goins J. Arens E. Zhang H. Wargocki P. Quantitative relationships between occupant satisfaction and satisfaction aspects of indoor environmental quality and building design Indoor Air 22 2 2012 119 131 10.1111/j.1600-0668.2011.00745.x M. Frontczak, S. Schiavon, J. Goins, E. Arens, H. Zhang, P. Wargocki, Quantitative relationships between occupant satisfaction and satisfaction aspects of indoor environmental quality and building design, Indoor air 22 2012 119\u2013131,.10.1111/j.1600-0668.2011.00745.x. [5] Wang S. Ma Z. Supervisory and optimal control of building HVAC systems: A review Hvac R Res 14 1 2008 3 32 10.1080/10789669.2008.10390991 S. Wang, Z. Ma, Supervisory and optimal control of building hvac systems: A review, Hvac&R Research 14 2008 3\u201332,.10.1080/10789669.2008.10390991. [6] Park J.Y. Ouf M.M. Gunay B. Peng Y. O\u2019Brien W. Kjærgaard M.B. A critical review of field implementations of occupant-centric building controls Build Environ 165 2019 106351 10.1016/j.buildenv.2019.106351 J. Y. Park, M. M. Ouf, B. Gunay, Y. Peng, W. O\u2019Brien, M. B. Kjærgaard, Z. Nagy, A critical review of field implementations of occupant-centric building controls, Building and Environment 165 2019 106351,.10.1016/j.buildenv.2019.106351. [7] Xie J. Li H. Li C. Zhang J. Luo M. Review on occupant-centric thermal comfort sensing, predicting, and controlling Energy Build 226 2020 110392 10.1016/j.enbuild.2020.110392 J. Xie, H. Li, C. Li, J. Zhang, M. Luo, Review on occupant-centric thermal comfort sensing, predicting, and controlling, Energy and Buildings 226 2020 110392,.10.1016/j.enbuild.2020.110392. [8] Dai X. Liu J. Zhang X. A review of studies applying machine learning models to predict occupancy and window-opening behaviours in smart buildings Energy Build 223 2020 110159 10.1016/j.enbuild.2020.110159 X. Dai, J. Liu, X. Zhang, A review of studies applying machine learning models to predict occupancy and window-opening behaviours in smart buildings, Energy and Buildings 223 2020 110159,.10.1016/j.enbuild.2020.110159. [9] Afroz Z. Shafiullah G. Urmee T. Higgins G. Modeling techniques used in building HVAC control systems: A review Renew Sustain Energy Rev 83 2018 64 84 10.1016/j.rser.2017.10.044 Z. Afroz, G. Shafiullah, T. Urmee, G. Higgins, Modeling techniques used in building hvac control systems: A review, Renewable and sustainable energy reviews 83 2018 64\u201384,.10.1016/j.rser.2017.10.044. [10] Zhan S. Lei Y. Jin Y. Yan D. Chong A. Impact of occupant related data on identification and model predictive control for buildings Applied Energy 323 2022 119580 10.1016/j.apenergy.2022.119580 B. Dong, K. P. Lam, A real-time model predictive control for building heating and cooling systems based on the occupancy behavior pattern detection and local weather forecasting, in: Building Simulation, volume 7, Springer,2014, pp. 89\u2013106,.10.1007/s12273-013-0142-7. [11] Winkler D.A. Yadav A. Chitu C. Cerpa A.E. Office: Optimization framework for improved comfort & efficiency 2020 19th ACM/IEEE international conference on information processing in sensor networks 2020 IEEE 265 276 10.1109/IPSN48710.2020.00030 D. A. Winkler, A. Yadav, C. Chitu, A. E. Cerpa, Office: Optimization framework for improved comfort & efficiency, in: 2020 19th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN), IEEE,2020, pp. 265\u2013276,.10.1109/IPSN48710.2020.00030. [12] Dhar N.K. Verma N.K. Behera L. Adaptive critic-based event-triggered control for HVAC system IEEE Trans Ind Inf 14 1 2017 178 188 10.1109/TII.2017.2725899 N. K. Dhar, N. K. Verma, L. Behera, Adaptive critic-based event-triggered control for hvac system, IEEE Transactions on Industrial Informatics 14 2017 178\u2013188,.10.1109/TII.2017.2725899. [13] Peng Y. Rysanek A. Nagy Z. Schlüter A. Using machine learning techniques for occupancy-prediction-based cooling control in office buildings Appl Energy 211 2018 1343 1358 10.1016/j.apenergy.2017.12.002 Y. Peng, A. Rysanek, Z. Nagy, A. Schlüter, Using machine learning techniques for occupancy-prediction-based cooling control in office buildings, Applied energy 211 2018 1343\u20131358,.10.1016/j.apenergy.2017.12.002. [14] Peng Y. Nagy Z. Schlüter A. Temperature-preference learning with neural networks for occupant-centric building indoor climate controls Build Environ 154 2019 296 308 10.1016/j.buildenv.2019.01.036 Y. Peng, Z. Nagy, A. Schlüter, Temperature-preference learning with neural networks for occupant-centric building indoor climate controls, Building and Environment 154 2019 296\u2013308,.10.1016/j.buildenv.2019.01.036. [15] Arroyo J. Manna C. Spiessens F. Helsen L. Reinforced model predictive control (RL-MPC) for building energy management Appl Energy 309 2022 118346 10.1016/j.apenergy.2021.118346 J. Arroyo, C. Manna, F. Spiessens, L. Helsen, Reinforced model predictive control (rl-mpc) for building energy management, Applied Energy 309 2022 118346,.10.1016/j.apenergy.2021.118346. [16] Wei T. Wang Y. Zhu Q. Deep reinforcement learning for building HVAC control Proceedings of the 54th annual design automation conference 2017 2017 1 6 10.1145/3061639.3062224 T. Wei, Y. Wang, Q. Zhu, Deep reinforcement learning for building hvac control, in: Proceedings of the 54th annual design automation conference 2017,2017, pp. 1\u20136,.10.1145/3061639.3062224. [17] Satyavada H. Baldi S. An integrated control-oriented modelling for HVAC performance benchmarking J Build Eng 6 2016 262 273 10.1016/j.jobe.2016.04.005 H. Satyavada, S. Baldi, An integrated control-oriented modelling for hvac performance benchmarking, Journal of Building Engineering 6 2016 262\u2013273,.10.1016/j.jobe.2016.04.005. [18] Homod R.Z. Gaeid K.S. Dawood S.M. Hatami A. Sahari K.S. Evaluation of energy-saving potential for optimal time response of hvac control system in smart buildings Appl Energy 271 2020 115255 10.1016/j.apenergy.2020.115255 R. Z. Homod, K. S. Gaeid, S. M. Dawood, A. Hatami, K. S. Sahari, Evaluation of energy-saving potential for optimal time response of hvac control system in smart buildings, Applied Energy 271 2020 115255,.10.1016/j.apenergy.2020.115255. [19] Serale G. Fiorentini M. Capozzoli A. Bernardini D. Bemporad A. Model predictive control (MPC) for enhancing building and HVAC system energy efficiency: Problem formulation, applications and opportunities Energies 11 3 2018 631 10.3390/en11030631 G. Serale, M. Fiorentini, A. Capozzoli, D. Bernardini, A. Bemporad, Model predictive control (mpc) for enhancing building and hvac system energy efficiency: Problem formulation, applications and opportunities, Energies 11 2018 631,.10.3390/en11030631. [20] Zhan S. Chong A. Data requirements and performance evaluation of model predictive control in buildings: A modeling perspective Renew Sustain Energy Rev 142 2021 110835 10.1016/j.rser.2021.110835 S. Zhan, A. Chong, Data requirements and performance evaluation of model predictive control in buildings: A modeling perspective, Renewable and Sustainable Energy Reviews 142 2021 110835,.10.1016/j.rser.2021.110835. [21] Chong A. Gu Y. Jia H. Calibrating building energy simulation models: A review of the basics to guide future work Energy Build 253 2021 111533 10.1016/j.enbuild.2021.111533 A. Chong, Y. Gu, H. Jia, Calibrating building energy simulation models: A review of the basics to guide future work, Energy and Buildings 253 2021 111533,.10.1016/j.enbuild.2021.111533. [22] Yu L. Sun Y. Xu Z. Shen C. Yue D. Jiang T. Multi-agent deep reinforcement learning for HVAC control in commercial buildings IEEE Trans Smart Grid 12 1 2020 407 419 10.1109/TSG.2020.3011739 L. Yu, Y. Sun, Z. Xu, C. Shen, D. Yue, T. Jiang, X. Guan, Multi-agent deep reinforcement learning for hvac control in commercial buildings, IEEE Transactions on Smart Grid 12 2020 407\u2013419,.10.1109/TSG.2020.3011739. [23] Hanumaiah V. Genc S. Distributed multi-agent deep reinforcement learning framework for whole-building HVAC control 2021 arXiv preprint arXiv:2110.13450. http://dx.doi.org/10.48550/arXiv.2110.13450 V. Hanumaiah, S. Genc, Distributed multi-agent deep reinforcement learning framework for whole-building hvac control, arXiv preprint arXiv:2110.13450 2021.10.48550/arXiv.2110.13450. [24] Mocanu E. Mocanu D.C. Nguyen P.H. Liotta A. Webber M.E. Gibescu M. On-line building energy optimization using deep reinforcement learning IEEE Trans Smart Grid 10 4 2018 3698 3708 10.1109/TSG.2018.2834219 E. Mocanu, D. C. Mocanu, P. H. Nguyen, A. Liotta, M. E. Webber, M. Gibescu, J. G. Slootweg, On-line building energy optimization using deep reinforcement learning, IEEE transactions on smart grid 10 2018 3698\u20133708,.10.1109/TSG.2018.2834219. [25] Vázquez-Canteli J.R. Dey S. Henze G. Nagy Z. CityLearn: Standardizing research in multi-agent reinforcement learning for demand response and urban energy management 2020 arXiv preprint arXiv:2012.10504. http://dx.doi.org/10.48550/arXiv.2012.10504 J. R. Vázquez-Canteli, S. Dey, G. Henze, Z. Nagy, Citylearn: Standardizing research in multi-agent reinforcement learning for demand response and urban energy management, arXiv preprint arXiv:2012.10504 2020.10.48550/arXiv.2012.10504. [26] Homod R.Z. Togun H. Hussein A.K. Al-Mousawi F.N. Yaseen Z.M. Al-Kouz W. Dynamics analysis of a novel hybrid deep clustering for unsupervised learning by reinforcement of multi-agent to energy saving in intelligent buildings Appl Energy 313 2022 118863 10.1016/j.apenergy.2022.118863 R. Z. Homod, H. Togun, A. K. Hussein, F. N. Al-Mousawi, Z. M. Yaseen, W. Al-Kouz, H. J. Abd, O. A. Alawi, M. Goodarzi, O. A. Hussein, Dynamics analysis of a novel hybrid deep clustering for unsupervised learning by reinforcement of multi-agent to energy saving in intelligent buildings, Applied Energy 313 2022 118863,.10.1016/j.apenergy.2022.118863. [27] Nagarathinam S. Menon V. Vasan A. Sivasubramaniam A. Marco-multi-agent reinforcement learning based control of building hvac systems Proceedings of the eleventh acm international conference on future energy systems 2020 57 67 10.1145/3396851.3397694 S. Nagarathinam, V. Menon, A. Vasan, A. Sivasubramaniam, Marco-multi-agent reinforcement learning based control of building hvac systems, in: Proceedings of the Eleventh ACM International Conference on Future Energy Systems,2020, pp. 57\u201367,.10.1145/3396851.3397694. [28] Nguyen T.T. Nguyen N.D. Nahavandi S. Deep reinforcement learning for multiagent systems: A review of challenges, solutions, and applications IEEE Trans Cybern 50 9 2020 3826 3839 10.1109/TCYB.2020.2977374 T. T. Nguyen, N. D. Nguyen, S. Nahavandi, Deep reinforcement learning for multiagent systems: A review of challenges, solutions, and applications, IEEE transactions on cybernetics 50 2020 3826\u20133839,.10.1109/TCYB.2020.2977374. [29] Lillicrap T.P. Hunt J.J. Pritzel A. Heess N. Erez T. Tassa Y. Continuous control with deep reinforcement learning 2015 arXiv preprint arXiv:1509.02971. http://dx.doi.org/10.48550/arXiv.1509.02971 T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, D. Wierstra, Continuous control with deep reinforcement learning, arXiv preprint arXiv:1509.02971 2015.10.48550/arXiv.1509.02971. [30] Sun B. Luh P.B. Jia Q.-S. Yan B. Event-based optimization within the Lagrangian relaxation framework for energy savings in HVAC systems IEEE Trans Autom Sci Eng 12 4 2015 1396 1406 10.1109/TASE.2015.2455419 B. Sun, P. B. Luh, Q.-S. Jia, B. Yan, Event-based optimization within the lagrangian relaxation framework for energy savings in hvac systems, IEEE Transactions on Automation Science and Engineering 12 2015 1396\u20131406,.10.1109/TASE.2015.2455419. [31] Ding X. Du W. Cerpa A. Octopus: Deep reinforcement learning for holistic smart building control Proceedings of the 6th acm international conference on systems for energy-efficient buildings, cities, and transportation 2019 326 335 10.1145/3360322.3360857 X. Ding, W. Du, A. Cerpa, Octopus: Deep reinforcement learning for holistic smart building control, in: Proceedings of the 6th ACM international conference on systems for energy-efficient buildings, cities, and transportation,2019, pp. 326\u2013335,.10.1145/3360322.3360857. [32] Yu L. Qin S. Zhang M. Shen C. Jiang T. Guan X. A review of deep reinforcement learning for smart building energy management IEEE Internet Things J 2021 10.1109/JIOT.2021.3078462 L. Yu, S. Qin, M. Zhang, C. Shen, T. Jiang, X. Guan, A review of deep reinforcement learning for smart building energy management, IEEE Internet of Things Journal 2021.10.1109/JIOT.2021.3078462. [33] Kazmi H. Mehmood F. Lodeweyckx S. Driesen J. Gigawatt-hour scale savings on a budget of zero: Deep reinforcement learning based optimal control of hot water systems Energy 144 2018 159 168 10.1016/j.energy.2017.12.019 H. Kazmi, F. Mehmood, S. Lodeweyckx, J. Driesen, Gigawatt-hour scale savings on a budget of zero: Deep reinforcement learning based optimal control of hot water systems, Energy 144 2018 159\u2013168,.10.1016/j.energy.2017.12.019. [34] Park J.Y. Dougherty T. Fritz H. Nagy Z. LightLearn: An adaptive and occupant centered controller for lighting based on reinforcement learning Build Environ 147 2019 397 414 10.1016/j.buildenv.2018.10.028 J. Y. Park, T. Dougherty, H. Fritz, Z. Nagy, Lightlearn: An adaptive and occupant centered controller for lighting based on reinforcement learning, Building and Environment 147 2019 397\u2013414,.10.1016/j.buildenv.2018.10.028. [35] Dulac-Arnold G. Levine N. Mankowitz D.J. Li J. Paduraru C. Gowal S. Challenges of real-world reinforcement learning: definitions, benchmarks and analysis Mach Learn 110 9 2021 2419 2468 10.1007/s10994-021-05961-4 G. Dulac-Arnold, N. Levine, D. J. Mankowitz, J. Li, C. Paduraru, S. Gowal, T. Hester, Challenges of real-world reinforcement learning: definitions, benchmarks and analysis, Machine Learning 110 2021 2419\u20132468,.10.1007/s10994-021-05961-4. [36] Chen Y. Norford L.K. Samuelson H.W. Malkawi A. Optimal control of HVAC and window systems for natural ventilation through reinforcement learning Energy Build 169 2018 195 205 10.1016/j.enbuild.2018.03.051 Y. Chen, L. K. Norford, H. W. Samuelson, A. Malkawi, Optimal control of hvac and window systems for natural ventilation through reinforcement learning, Energy and Buildings 169 2018 195\u2013205,.10.1016/j.enbuild.2018.03.051. [37] Botvinick M. Ritter S. Wang J.X. Kurth-Nelson Z. Blundell C. Hassabis D. Reinforcement learning, fast and slow Trends Cogn Sci 23 5 2019 408 422 10.1016/j.tics.2019.02.006 M. Botvinick, S. Ritter, J. X. Wang, Z. Kurth-Nelson, C. Blundell, D. Hassabis, Reinforcement learning, fast and slow, Trends in cognitive sciences 23 2019 408\u2013422,.10.1016/j.tics.2019.02.006. [38] Wang Z. Hong T. Reinforcement learning for building controls: The opportunities and challenges Appl Energy 269 2020 115036 10.1016/j.apenergy.2020.115036 Z. Wang, T. Hong, Reinforcement learning for building controls: The opportunities and challenges, Applied Energy 269 2020 115036,.10.1016/j.apenergy.2020.115036. [39] Andrews N. Miller E. Taylor B. Lingam R. Simmons A. Stowe J. Recall bias, MMR, and autism Arch Dis Child 87 6 2002 493 494 10.1136/adc.87.6.493 N. Andrews, E. Miller, B. Taylor, R. Lingam, A. Simmons, J. Stowe, P. Waight, Recall bias, mmr, and autism, Archives of disease in childhood 87 2002 493\u2013494,.10.1136/adc.87.6.493. [40] Katipamula S. Brambley M.R. Methods for fault detection, diagnostics, and prognostics for building systems\u2014a review, part I Hvac R Res 11 1 2005 3 25 10.1080/10789669.2005.10391123 S. Katipamula, M. R. Brambley, Methods for fault detection, diagnostics, and prognostics for building systems\u2014a review, part i, Hvac&R Research 11 2005 3\u201325,.10.1080/10789669.2005.10391123. [41] Bae Y. Bhattacharya S. Cui B. Lee S. Li Y. Zhang L. Sensor impacts on building and HVAC controls: A critical review for building energy performance Adv Appl Energy 4 2021 100068 10.1016/j.adapen.2021.100068 Y. Bae, S. Bhattacharya, B. Cui, S. Lee, Y. Li, L. Zhang, P. Im, V. Adetola, D. Vrabie, M. Leach,, others, Sensor impacts on building and hvac controls: A critical review for building energy performance, Advances in Applied Energy 4 2021 100068,.10.1016/j.adapen.2021.100068. [42] Zhang Z. Chong A. Pan Y. Zhang C. Lam K.P. Whole building energy model for HVAC optimal control: A practical framework based on deep reinforcement learning Energy Build 199 2019 472 490 10.1016/j.enbuild.2019.07.029 Z. Zhang, A. Chong, Y. Pan, C. Zhang, K. P. Lam, Whole building energy model for hvac optimal control: A practical framework based on deep reinforcement learning, Energy and Buildings 199 2019 472\u2013490,.10.1016/j.enbuild.2019.07.029. [43] Chen B. Cai Z. Bergés M. Gnu-rl: A precocial reinforcement learning solution for building hvac control using a differentiable mpc policy Proceedings of the 6th acm international conference on systems for energy-efficient buildings, cities, and transportation 2019 316 325 10.1145/3360322.3360849 B. Chen, Z. Cai, M. Bergés, Gnu-rl: A precocial reinforcement learning solution for building hvac control using a differentiable mpc policy, in: Proceedings of the 6th ACM international conference on systems for energy-efficient buildings, cities, and transportation,2019, pp. 316\u2013325,.10.1145/3360322.3360849. [44] Qiu S. Li Z. Fan D. He R. Dai X. Li Z. Chilled water temperature resetting using model-free reinforcement learning: Engineering application Energy Build 255 2022 111694 10.1016/j.enbuild.2021.111694 S. Qiu, Z. Li, D. Fan, R. He, X. Dai, Z. Li, Chilled water temperature resetting using model-free reinforcement learning: Engineering application, Energy and Buildings 255 2022 111694,.10.1016/j.enbuild.2021.111694. [45] Zhang C. Zhang Z. Loftness V. Bio-sensing and reinforcement learning approaches for occupant-centric control ASHRAE Trans 125 2 2019 C. Zhang, Z. Zhang, V. Loftness, Bio-sensing and reinforcement learning approaches for occupant-centric control, ASHRAE Transactions 125 2019. [46] Jung S. Jeoung J. Hong T. Occupant-centered real-time control of indoor temperature using deep learning algorithms Build Environ 2021 108633 10.1016/j.buildenv.2021.108633 S. Jung, J. Jeoung, T. Hong, Occupant-centered real-time control of indoor temperature using deep learning algorithms, Building and Environment 2021 108633,.10.1016/j.buildenv.2021.108633. [47] O\u2019Brien W. Wagner A. Schweiker M. Mahdavi A. Day J. Kjærgaard M.B. Introducing IEA EBC Annex 79: Key challenges and opportunities in the field of occupant-centric building design and operation Build Environ 178 2020 106738 10.1016/j.buildenv.2020.106738 W. O\u2019Brien, A. Wagner, M. Schweiker, A. Mahdavi, J. Day, M. B. Kjærgaard, S. Carlucci, B. Dong, F. Tahmasebi, D. Yan,, others, Introducing iea ebc annex 79: Key challenges and opportunities in the field of occupant-centric building design and operation, Building and Environment 178 2020 106738,.10.1016/j.buildenv.2020.106738. [48] Wang Z. de Dear R. Luo M. Lin B. He Y. Ghahramani A. Individual difference in thermal comfort: A literature review Build Environ 138 2018 181 193 10.1016/j.buildenv.2018.04.040 Z. Wang, R. de Dear, M. Luo, B. Lin, Y. He, A. Ghahramani, Y. Zhu, Individual difference in thermal comfort: A literature review, Building and Environment 138 2018 181\u2013193,.10.1016/j.buildenv.2018.04.040. [49] Ono E. Mihara K. Lam K.P. Chong A. The effects of a mismatch between thermal comfort modeling and HVAC controls from an occupancy perspective Build Environ 2022 109255 10.1016/j.buildenv.2022.109255 E. Ono, K. Mihara, K. P. Lam, A. Chong, The effects of a mismatch between thermal comfort modeling and hvac controls from an occupancy perspective, Building and Environment 2022 109255,.10.1016/j.buildenv.2022.109255. [50] Kim J. Schiavon S. Brager G. Personal comfort models\u2013a new paradigm in thermal comfort for occupant-centric environmental control Build Environ 132 2018 114 124 10.1016/j.buildenv.2019.106351 J. Kim, S. Schiavon, G. Brager, Personal comfort models\u2013a new paradigm in thermal comfort for occupant-centric environmental control, Building and Environment 132 2018 114\u2013124,.10.1016/j.buildenv.2019.106351. [51] Cheung T. Schiavon S. Parkinson T. Li P. Brager G. Analysis of the accuracy on PMV\u2013PPD model using the ASHRAE global thermal comfort database II Build Environ 153 2019 205 217 10.1016/j.buildenv.2019.01.055 T. Cheung, S. Schiavon, T. Parkinson, P. Li, G. Brager, Analysis of the accuracy on pmv\u2013ppd model using the ashrae global thermal comfort database ii, Building and Environment 153 2019 205\u2013217,.10.1016/j.buildenv.2019.01.055. [52] De Dear R. Brager G.S. Developing an adaptive model of thermal comfort and preference 1998 R. De Dear, G. S. Brager, Developing an adaptive model of thermal comfort and preference 1998. [53] Humphreys M.A. Nicol J.F. The validity of ISO-PMV for predicting comfort votes in every-day thermal environments Energy Build 34 6 2002 667 684 10.1016/S0378-7788(02)00018-X M. A. Humphreys, J. F. Nicol, The validity of iso-pmv for predicting comfort votes in every-day thermal environments, Energy and buildings 34 2002 667\u2013684,.10.1016/S0378-7788(02)00018-X. [54] Park J.Y. Nagy Z. Comprehensive analysis of the relationship between thermal comfort and building control research-a data-driven literature review Renew Sustain Energy Rev 82 2018 2664 2679 10.1016/j.rser.2017.09.102 J. Y. Park, Z. Nagy, Comprehensive analysis of the relationship between thermal comfort and building control research-a data-driven literature review, Renewable and Sustainable Energy Reviews 82 2018 2664\u20132679,.10.1016/j.rser.2017.09.102. [55] Homod R.Z. Sahari K.S.M. Almurib H.A. Nagi F.H. RLF and TS fuzzy model identification of indoor thermal comfort based on PMV/PPD Build Environ 49 2012 141 153 10.1016/j.buildenv.2011.09.012 R. Z. Homod, K. S. M. Sahari, H. A. Almurib, F. H. Nagi, Rlf and ts fuzzy model identification of indoor thermal comfort based on pmv/ppd, Building and Environment 49 2012 141\u2013153,.10.1016/j.buildenv.2011.09.012. [56] Wetter M. Zuo W. Nouidui T.S. Pang X. Modelica buildings library J Build Perform Simul 7 4 2014 253 270 10.1080/19401493.2013.765506 M. Wetter, W. Zuo, T. S. Nouidui, X. Pang, Modelica buildings library, Journal of Building Performance Simulation 7 2014 253\u2013270,.10.1080/19401493.2013.765506. [57] Yang L. Nagy Z. Goffin P. Schlueter A. Reinforcement learning for optimal control of low exergy buildings Appl Energy 156 2015 577 586 10.1016/j.apenergy.2015.07.050 L. Yang, Z. Nagy, P. Goffin, A. Schlueter, Reinforcement learning for optimal control of low exergy buildings, Applied Energy 156 2015 577\u2013586,.10.1016/j.apenergy.2015.07.050. [58] Tavakoli A. Pardo F. Kormushev P. Action branching architectures for deep reinforcement learning Proceedings of the AAAI conference on artificial intelligence. Vol. 32 2018 URL: https://ojs.aaai.org/index.php/AAAI/article/view/11798 A. Tavakoli, F. Pardo, P. Kormushev, Action branching architectures for deep reinforcement learning, Proceedings of the AAAI Conference on Artificial Intelligence 32 2018. https://ojs.aaai.org/index.php/AAAI/article/view/11798. [59] Sutton R.S. Barto A.G. Reinforcement learning: an introduction 2018 MIT Press R. S. Sutton, A. G. Barto, Reinforcement learning: An introduction, MIT press,2018. [60] Van Hasselt H. Guez A. Silver D. Deep reinforcement learning with double q-learning Proceedings of the AAAI conference on artificial intelligence. Vol. 30 2016 10.1609/aaai.v30i1.10295 H. Van Hasselt, A. Guez, D. Silver, Deep reinforcement learning with double q-learning, in: Proceedings of the AAAI conference on artificial intelligence, volume 30,2016.10.1609/aaai.v30i1.10295. [61] Wang Z. Schaul T. Hessel M. Hasselt H. Lanctot M. Freitas N. Dueling network architectures for deep reinforcement learning Proceedings of the 33rd international conference on machine learning 2016 PMLR 1995 2003 Z. Wang, T. Schaul, M. Hessel, H. Hasselt, M. Lanctot, N. Freitas, Dueling network architectures for deep reinforcement learning, in: Proceedings of The 33rd International Conference on Machine Learning, PMLR,2016, pp. 1995\u20132003,. [62] Sewak M. Deep reinforcement learning 2019 Springer M. Sewak, Deep reinforcement learning, Springer,2019. [63] Gunnarsen L. Fanger P.O. Adaptation to indoor air pollution Environ Int 18 1 1992 43 54 10.1016/0160-4120(92)90209-M L. Gunnarsen, P. O. Fanger, Adaptation to indoor air pollution, Environment International 18 1992 43\u201354,.10.1016/0160-4120(92)90209-M. [64] Lin L.-J. Self-improving reactive agents based on reinforcement learning, planning and teaching Mach Learn 8 3 1992 293 321 10.1007/BF00992699 L.-J. Lin, Self-improving reactive agents based on reinforcement learning, planning and teaching, Machine learning 8 1992 293\u2013321,.10.1007/BF00992699. [65] Brockman G. Cheung V. Pettersson L. Schneider J. Schulman J. Tang J. Openai gym 2016 arXiv preprint arXiv:1606.01540. http://dx.doi.org/10.48550/arXiv.1606.01540 G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, W. Zaremba, Openai gym, arXiv preprint arXiv:1606.01540 2016.10.48550/arXiv.1606.01540. [66] Andersson C. Åkesson J. Führer C. Pyfmi: a python package for simulation of coupled dynamic models with the functional mock-up interface 2016 Centre for Mathematical Sciences, Lund University Lund Sweden C. Andersson, J. Åkesson, C. Führer, Pyfmi: A python package for simulation of coupled dynamic models with the functional mock-up interface, Centre for Mathematical Sciences, Lund University Lund, Sweden,2016. [67] Zhang S. Sutton R.S. A deeper look at experience replay 2017 arXiv preprint arXiv:1712.01275. http://dx.doi.org/10.48550/arXiv.1712.01275 S. Zhang, R. S. Sutton, A deeper look at experience replay, arXiv preprint arXiv:1712.01275 2017.10.48550/arXiv.1712.01275. [68] Chong A. Xu W. Chao S. Ngo N.-T. Continuous-time Bayesian calibration of energy models using BIM and energy data Energy Build 194 2019 177 190 10.1016/j.enbuild.2019.04.017 A. Chong, W. Xu, S. Chao, N.-T. Ngo, Continuous-time bayesian calibration of energy models using bim and energy data, Energy and Buildings 194 2019 177\u2013190,.10.1016/j.enbuild.2019.04.017. [69] Zhan S. Wichern G. Laughman C. Chong A. Chakrabarty A. Calibrating building simulation models using multi-source datasets and meta-learned bayesian optimization 2022 Elsevier 112278 10.1016/j.enbuild.2022.112278 S. Zhan, G. Wichern, C. Laughman, A. Chakrabarty, Meta-learned bayesian optimization for calibrating building simulation models with multi-source data, in: NeurIPS 2021 Workshop on Tackling Climate Change with Machine Learning,2021. https://www.climatechange.ai/papers/neurips2021/18. [70] ANSI/ASHRAE S. ANSI/ASHRAE standard 55-2020: thermal environmental conditions for human occupancy 2020 American Society of Heating, Refrigerating and Air Conditioning Engineers ANSI/ASHRAE, ANSI/ASHRAE Standard 55-2020: thermal environmental conditions for human occupancy,2020. [71] Mihara K. Sekhar C. Takemasa Y. Lasternas B. Tham K.W. Thermal comfort and energy performance of a dedicated outdoor air system with ceiling fans in hot and humid climate Energy Build 203 2019 109448 10.1016/j.enbuild.2019.109448 K. Mihara, C. Sekhar, Y. Takemasa, B. Lasternas, K. W. Tham, Thermal comfort and energy performance of a dedicated outdoor air system with ceiling fans in hot and humid climate, Energy and Buildings 203 2019 109448,.10.1016/j.enbuild.2019.109448. [72] Velavan T.P. Meyer C.G. The COVID-19 epidemic Trop Med Int Health 25 3 2020 278 10.1111/tmi.13383 T. P. Velavan, C. G. Meyer, The covid-19 epidemic, Tropical medicine & international health 25 2020 278,.10.1111/tmi.13383. [73] Jung W. Jazizadeh F. Comparative assessment of HVAC control strategies using personal thermal comfort and sensitivity models Build Environ 158 2019 104 119 10.1016/j.buildenv.2019.04.043 W. Jung, F. Jazizadeh, Comparative assessment of hvac control strategies using personal thermal comfort and sensitivity models, Building and Environment 158 2019 104\u2013119,.10.1016/j.buildenv.2019.04.043. [74] ASHRAE A.G. Guideline 14-2014: measurement of energy, demand, and water savings 2014 American Society of Heating, Refrigerating, and Air Conditioning Engineers, Atlanta, Georgia A. G. ASHRAE, Guideline 14-2014: Measurement of energy, demand, and water savings, American Society of Heating, Refrigerating, and Air Conditioning Engineers, Atlanta, Georgia 2014. [75] Zhang Y. Zhao R. Overall thermal sensation, acceptability and comfort Build Environ 43 1 2008 44 50 10.1016/j.buildenv.2006.11.036 Y. Zhang, R. Zhao, Overall thermal sensation, acceptability and comfort, Building and environment 43 2008 44\u201350,.10.1016/j.buildenv.2006.11.036. [76] Henderson P. Islam R. Bachman P. Pineau J. Precup D. Meger D. Deep reinforcement learning that matters Proceedings of the AAAI conference on artificial intelligence. Vol. 32 2018 URL: https://ojs.aaai.org/index.php/AAAI/article/view/11694 P. Henderson, R. Islam, P. Bachman, J. Pineau, D. Precup, D. Meger, Deep reinforcement learning that matters, in: Proceedings of the AAAI conference on artificial intelligence, volume 32,2018. https://ojs.aaai.org/index.php/AAAI/article/view/11694. [77] Paine T.L. Paduraru C. Michi A. Gulcehre C. Zolna K. Novikov A. Hyperparameter selection for offline reinforcement learning 2020 arXiv preprint arXiv:2007.09055. http://dx.doi.org/10.48550/arXiv.2007.09055 T. L. Paine, C. Paduraru, A. Michi, C. Gulcehre, K. Zolna, A. Novikov, Z. Wang, N. de Freitas, Hyperparameter selection for offline reinforcement learning, arXiv preprint arXiv:2007.09055 2020.10.48550/arXiv.2007.09055. [78] Kearns M. Mansour Y. Ng A.Y. A sparse sampling algorithm for near-optimal planning in large Markov decision processes Mach Learn 49 2 2002 193 208 10.1023/A:1017932429737 M. Kearns, Y. Mansour, A. Y. Ng, A sparse sampling algorithm for near-optimal planning in large markov decision processes, Machine learning 49 2002 193\u2013208,. [79] Solis R, Pakbin A, Akbari A, Mortazavi BJ, Jafari R. A human-centered wearable sensing platform with intelligent automated data annotation capabilities. In: Proceedings of the international conference on internet of things design and implementation. 2019, p. 255\u201360. http://dx.doi.org/10.1145/3302505.3310087. R. Solis, A. Pakbin, A. Akbari, B. J. Mortazavi, R. Jafari, A human-centered wearable sensing platform with intelligent automated data annotation capabilities, in: Proceedings of the International Conference on Internet of Things Design and Implementation,2019, pp. 255\u2013260,.",
    "scopus-id": "85135701106",
    "coredata": {
        "eid": "1-s2.0-S0306261922010297",
        "dc:description": "Reinforcement learning (RL) has been shown to have the potential for optimal control of heating, ventilation, and air conditioning (HVAC) systems. Although research on RL-based building control has received extensive attention in recent years, there is limited real-world implementation to evaluate its performance while keeping occupants in the loop. Additionally, many HVAC systems consist of multiple subsystems, but conventional RL algorithms face significant challenges when dealing with high-dimensional action spaces. This study proposes a practical deep reinforcement learning (DRL) based multivariate occupant-centric control framework that considers personalized thermal comfort and occupant presence. Specifically, Branching Dueling Q-network (BDQ) is leveraged as the learning agent to efficiently solve the multi-dimensional control task, and a tabular-based personal comfort modeling method is applied that is naturally integrated into human-in-the-loop operations. The BDQ agent is pre-trained in a virtual environment, followed by online deployment in a real office space for 5-dimensional action control. Based on the actual deployment and real-time comfort votes, our results showed a 14% reduction in cooling energy and an 11% improvement in total thermal acceptability.",
        "openArchiveArticle": "false",
        "prism:coverDate": "2022-10-15",
        "openaccessUserLicense": null,
        "prism:aggregationType": "Journal",
        "prism:url": "https://api.elsevier.com/content/article/pii/S0306261922010297",
        "dc:creator": [
            {
                "@_fa": "true",
                "$": "Lei, Yue"
            },
            {
                "@_fa": "true",
                "$": "Zhan, Sicheng"
            },
            {
                "@_fa": "true",
                "$": "Ono, Eikichi"
            },
            {
                "@_fa": "true",
                "$": "Peng, Yuzhen"
            },
            {
                "@_fa": "true",
                "$": "Zhang, Zhiang"
            },
            {
                "@_fa": "true",
                "$": "Hasama, Takamasa"
            },
            {
                "@_fa": "true",
                "$": "Chong, Adrian"
            }
        ],
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/article/pii/S0306261922010297"
            },
            {
                "@_fa": "true",
                "@rel": "scidir",
                "@href": "https://www.sciencedirect.com/science/article/pii/S0306261922010297"
            }
        ],
        "dc:format": "application/json",
        "openaccessType": null,
        "pii": "S0306-2619(22)01029-7",
        "prism:volume": "324",
        "articleNumber": "119742",
        "prism:publisher": "Elsevier Ltd.",
        "dc:title": "A practical deep reinforcement learning framework for multivariate occupant-centric control in buildings",
        "prism:copyright": "© 2022 Elsevier Ltd. All rights reserved.",
        "openaccess": "0",
        "prism:issn": "03062619",
        "dcterms:subject": [
            {
                "@_fa": "true",
                "$": "Occupant-centric control"
            },
            {
                "@_fa": "true",
                "$": "Deep learning"
            },
            {
                "@_fa": "true",
                "$": "Reinforcement learning"
            },
            {
                "@_fa": "true",
                "$": "Thermal comfort"
            },
            {
                "@_fa": "true",
                "$": "Energy efficiency"
            }
        ],
        "openaccessArticle": "false",
        "prism:publicationName": "Applied Energy",
        "openaccessSponsorType": null,
        "prism:pageRange": "119742",
        "pubType": "fla",
        "prism:coverDisplayDate": "15 October 2022",
        "prism:doi": "10.1016/j.apenergy.2022.119742",
        "prism:startingPage": "119742",
        "dc:identifier": "doi:10.1016/j.apenergy.2022.119742",
        "openaccessSponsorName": null
    },
    "objects": {"object": [
        {
            "@category": "standard",
            "@height": "243",
            "@width": "552",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr9.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "44340",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "409",
            "@width": "817",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-fx1001.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "140721",
            "@ref": "fx1001",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "325",
            "@width": "659",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr8.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "84419",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "206",
            "@width": "653",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr7.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "52861",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "234",
            "@width": "429",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr6.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "43746",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "468",
            "@width": "659",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr5.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "154790",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "383",
            "@width": "659",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr4.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "89168",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "176",
            "@width": "659",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr3.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "46215",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "146",
            "@width": "436",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr2.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "23854",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "353",
            "@width": "659",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "80677",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "346",
            "@width": "659",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr13.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "158839",
            "@ref": "gr13",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "249",
            "@width": "659",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr11.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "65438",
            "@ref": "gr11",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "599",
            "@width": "659",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr12.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "101420",
            "@ref": "gr12",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "499",
            "@width": "659",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr10.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "137927",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "161",
            "@width": "301",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-ga1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "36003",
            "@ref": "ga1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@height": "96",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr9.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "14124",
            "@ref": "gr9",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "110",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-fx1001.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "72354",
            "@ref": "fx1001",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "108",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr8.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "16996",
            "@ref": "gr8",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "69",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr7.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "12696",
            "@ref": "gr7",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "119",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr6.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "16991",
            "@ref": "gr6",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "155",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr5.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "29094",
            "@ref": "gr5",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "127",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr4.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "20617",
            "@ref": "gr4",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "58",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr3.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "13158",
            "@ref": "gr3",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "73",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr2.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "11355",
            "@ref": "gr2",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "117",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "18442",
            "@ref": "gr1",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "115",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr13.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "29525",
            "@ref": "gr13",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "83",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr11.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "15333",
            "@ref": "gr11",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "180",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr12.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "18238",
            "@ref": "gr12",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "217",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr10.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "26851",
            "@ref": "gr10",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "117",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-ga1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "19122",
            "@ref": "ga1",
            "@mimetype": "image/gif"
        },
        {
            "@category": "high",
            "@height": "1074",
            "@width": "2443",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr9_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "222066",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1813",
            "@width": "3618",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-fx1001_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "655440",
            "@ref": "fx1001",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1439",
            "@width": "2917",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr8_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "426315",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "910",
            "@width": "2890",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr7_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "307755",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1037",
            "@width": "1901",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr6_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "227987",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2071",
            "@width": "2918",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr5_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "1014095",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1693",
            "@width": "2916",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr4_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "540288",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "778",
            "@width": "2918",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr3_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "239217",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "646",
            "@width": "1932",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr2_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "99056",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1562",
            "@width": "2917",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr1_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "489044",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1533",
            "@width": "2917",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr13_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "1014682",
            "@ref": "gr13",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1104",
            "@width": "2917",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr11_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "308950",
            "@ref": "gr11",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2651",
            "@width": "2917",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr12_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "777750",
            "@ref": "gr12",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2207",
            "@width": "2917",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-gr10_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "723661",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "714",
            "@width": "1333",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-ga1_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "187160",
            "@ref": "ga1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si1.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3757",
            "@ref": "si1",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si10.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4460",
            "@ref": "si10",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si101.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6528",
            "@ref": "si101",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si102.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5221",
            "@ref": "si102",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si103.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "9695",
            "@ref": "si103",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si104.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5172",
            "@ref": "si104",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si105.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4610",
            "@ref": "si105",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si106.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7392",
            "@ref": "si106",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si107.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3790",
            "@ref": "si107",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si108.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6563",
            "@ref": "si108",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si109.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "24356",
            "@ref": "si109",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si11.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5122",
            "@ref": "si11",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si110.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "15323",
            "@ref": "si110",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si111.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1456",
            "@ref": "si111",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si112.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "702",
            "@ref": "si112",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si113.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "678",
            "@ref": "si113",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si119.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "993",
            "@ref": "si119",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si12.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2962",
            "@ref": "si12",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si120.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1159",
            "@ref": "si120",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si13.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4889",
            "@ref": "si13",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si14.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "8370",
            "@ref": "si14",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si15.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "17322",
            "@ref": "si15",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si16.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7214",
            "@ref": "si16",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si17.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1551",
            "@ref": "si17",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si18.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1325",
            "@ref": "si18",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si19.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4774",
            "@ref": "si19",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si2.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1424",
            "@ref": "si2",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si20.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "21891",
            "@ref": "si20",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si22.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6417",
            "@ref": "si22",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si23.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "24693",
            "@ref": "si23",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si24.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1131",
            "@ref": "si24",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si25.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2918",
            "@ref": "si25",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si27.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3195",
            "@ref": "si27",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si28.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1615",
            "@ref": "si28",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si29.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1798",
            "@ref": "si29",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si3.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3563",
            "@ref": "si3",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si30.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1430",
            "@ref": "si30",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si31.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1305",
            "@ref": "si31",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si32.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5972",
            "@ref": "si32",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si33.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "23575",
            "@ref": "si33",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si34.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1918",
            "@ref": "si34",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si36.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2334",
            "@ref": "si36",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si39.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1352",
            "@ref": "si39",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si4.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1093",
            "@ref": "si4",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si40.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11341",
            "@ref": "si40",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si41.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1303",
            "@ref": "si41",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si42.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1305",
            "@ref": "si42",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si43.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2849",
            "@ref": "si43",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si44.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2085",
            "@ref": "si44",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si49.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11718",
            "@ref": "si49",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si5.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4763",
            "@ref": "si5",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si50.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5591",
            "@ref": "si50",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si51.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5753",
            "@ref": "si51",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si52.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2128",
            "@ref": "si52",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si54.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1054",
            "@ref": "si54",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si55.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1351",
            "@ref": "si55",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si56.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2950",
            "@ref": "si56",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si58.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6014",
            "@ref": "si58",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si59.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "16645",
            "@ref": "si59",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si6.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2174",
            "@ref": "si6",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si60.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "30048",
            "@ref": "si60",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si63.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2570",
            "@ref": "si63",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si64.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1663",
            "@ref": "si64",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si65.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4241",
            "@ref": "si65",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si69.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5128",
            "@ref": "si69",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si7.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5248",
            "@ref": "si7",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si72.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5388",
            "@ref": "si72",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si8.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4630",
            "@ref": "si8",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si80.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7817",
            "@ref": "si80",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si85.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1521",
            "@ref": "si85",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si9.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5253",
            "@ref": "si9",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si91.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3148",
            "@ref": "si91",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si92.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3223",
            "@ref": "si92",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si93.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1470",
            "@ref": "si93",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si94.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1478",
            "@ref": "si94",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si95.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1147",
            "@ref": "si95",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si96.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1490",
            "@ref": "si96",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si97.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1381",
            "@ref": "si97",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si98.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1226",
            "@ref": "si98",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-si99.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1686",
            "@ref": "si99",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0306261922010297-am.pdf?httpAccept=%2A%2F%2A",
            "@multimediatype": "Acrobat PDF file",
            "@type": "AAM-PDF",
            "@size": "3882416",
            "@ref": "am",
            "@mimetype": "application/pdf"
        }
    ]},
    "link": {
        "@rel": "abstract",
        "@href": "https://api.elsevier.com/content/abstract/scopus_id/85135701106"
    }
}}