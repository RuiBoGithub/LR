{"full-text-retrieval-response": {
    "scopus-eid": "2-s2.0-85116036530",
    "originalText": "serial JL 271089 291210 291731 291800 291881 31 Energy and Buildings ENERGYBUILDINGS 2021-09-23 2021-09-23 2021-09-30 2021-09-30 2022-01-17T14:55:42 1-s2.0-S0378778821007891 S0378-7788(21)00789-1 S0378778821007891 10.1016/j.enbuild.2021.111505 S300 S300.1 FULL-TEXT 1-s2.0-S0378778821X00205 2022-12-12T16:32:34.737732Z 0 0 20211215 2021 2021-09-23T14:45:08.314193Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid highlightsabst nomenclature orcid primabst ref 0378-7788 03787788 true 253 253 C Volume 253 5 111505 111505 111505 20211215 15 December 2021 2021-12-15 2021 Research Articles article fla © 2021 Elsevier B.V. All rights reserved. COMPARISONMACHINELEARNINGMODELSFORPREDICTINGSHORTTERMBUILDINGHEATINGLOADUSINGOPERATIONALPARAMETERS ZHOU Y Nomenclature 1 Introduction 2 Method 2.1 Machine learning models 2.1.1 ANN-based models 2.1.1.1 Multi-layer perception 2.1.1.2 Radial basis function neural network 2.1.1.3 Generalized regression neural network 2.1.1.4 Extreme learning machine 2.1.2 Kernel-based models 2.1.2.1 Support vector machine 2.1.2.2 Least square support vector machine 2.1.2.3 Gaussian process regression 2.1.3 Tree-based models 2.1.3.1 Regression trees 2.1.3.2 Model five tree 2.1.3.3 Random forest 2.1.3.4 Gradient boosting decision tree 2.1.3.5 Extreme gradient boosting 2.1.3.6 Light gradient boosting machine 2.1.3.7 Categorical boosting tree 2.1.4 Multi-adaptive regression spline 2.2 ReliefF feature selection algorithm 2.3 Model set-up and parameter optimization 2.4 Data collection and data preprocessing 2.5 Evaluation metrics 3 Results and discussion 3.1 Feature selection 3.2 Comparison of model performances 3.3 Comparison of model stability 3.4 Comparison of computation time 3.5 Comparison of model comprehensive performances 4 Conclusion and future work Acknowledgements References DONG 2020 105411 N FANG 2021 119208 X LIU 2020 122984 Y BOURDEAU 2019 101533 M YAKAI 2021 119322 L ZHANG 2019 622 633 Q AMASYALI 2018 1192 1205 K CHENGFAN 2017 222 233 F LIU 2017 168 179 Y DING 2017 254 267 Y FAN 2019 35 45 C AHMAD 2014 102 109 A AHMAD 2017 77 89 M CHEN 2020 100028 S DONG 2021 110929 Z LEI 2021 110886 L DING 2021 116660 Z ZHANG 2020 110301 C ZENG 2020 101054 A SHAO 2020 102128 M KAMEL 2020 118045 E YAN 2020 102194 L DENG 2018 34 43 H SONG 2021 110998 J ZHOU 2021 113960 Y TAKI 2018 3028 3041 M MASSAOUDI 2021 118874 M BUI 2020 116370 D ILBEIGI 2020 102325 M ZHANG 2004 2333 2339 A HAN 2020 118414 Y LI 2009 90 96 Q SANIKHANI 2018 242 260 H BENNAKHI 2004 2127 2141 A YE 2018 168 174 H LIU 2020 115383 C SEKHARROY 2018 4256 4268 S TAN 2020 119252 Z ZHOU 2021 124710 Y GONG 2020 101455 M QUINLAN 1992 343 348 J PROCEEDINGS5THAUSTRALIANJOINTCONFERENCEARTIFICIALINTELLIGENCE LEARNINGCONTINUOUSCLASSES WANG 2018 11 25 Z ZHANG 2021 1588 1597 W MO 2019 109564 H LIU 2021 106399 S LEE 2021 112109 S PRADA 2018 814 826 A ALMARAASHI 2018 250 263 M AKARSLAN 2021 100488 E ZHOU 2019 518 536 Y LIU 2020 1101 1112 Y ZHOUX2021X111505 ZHOUX2021X111505XY 2023-09-30T00:00:00.000Z 2023-09-30T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ © 2021 Elsevier B.V. All rights reserved. 2021-10-04T23:08:46.371Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/aggregated-refined National Natural Science Foundation of China 52108091 NSFC National Natural Science Foundation of China http://data.elsevier.com/vocabulary/SciValFunders/501100001809 http://sws.geonames.org/1814991/ China Postdoctoral Science Foundation Project 2020M683431 China Postdoctoral Science Foundation http://data.elsevier.com/vocabulary/SciValFunders/501100002858 http://sws.geonames.org/1814991/ Natural Science in Shaanxi Province 2021JQ-511 Natural Science Foundation of Shaanxi Province http://data.elsevier.com/vocabulary/SciValFunders/501100007128 http://sws.geonames.org/1814991/ Independent Research and Development project of State Key Laboratory of Green Building in Western China LSZZ202106 This paper was supported by the National Natural Science Foundation of China (Project No. 52108091 ), China Postdoctoral Science Foundation Project (Project No. 2020M683431), Basic research program of Natural Science in Shaanxi Province (Project No. 2021JQ-511), Independent Research and Development project of State Key Laboratory of Green Building in Western China (Project No. LSZZ202106). 0 https://doi.org/10.15223/policy-017 https://doi.org/10.15223/policy-037 https://doi.org/10.15223/policy-012 https://doi.org/10.15223/policy-029 https://doi.org/10.15223/policy-004 item S0378-7788(21)00789-1 S0378778821007891 1-s2.0-S0378778821007891 10.1016/j.enbuild.2021.111505 271089 2022-01-17T15:17:22.23602Z 2021-12-15 1-s2.0-S0378778821007891-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/MAIN/application/pdf/649a9b62c6e5c10e0305fbf60f7f0aa5/main.pdf main.pdf pdf true 2810443 MAIN 15 1-s2.0-S0378778821007891-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/PREVIEW/image/png/5dcc5be3e9a96bb29bab8e593376aeb3/main_1.png main_1.png png 59831 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0378778821007891-gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr10/DOWNSAMPLED/image/jpeg/e23ffce82f41c5743d66fd5863cea4f6/gr10.jpg gr10 gr10.jpg jpg 40243 315 627 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr2/DOWNSAMPLED/image/jpeg/a0ba7ad4048e07953f95212249f763db/gr2.jpg gr2 gr2.jpg jpg 17370 179 373 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr3/DOWNSAMPLED/image/jpeg/9ecbf251df759773381e94fee7546b02/gr3.jpg gr3 gr3.jpg jpg 72203 475 667 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr4/DOWNSAMPLED/image/jpeg/dbd944dd4e773eb698239b28b314e936/gr4.jpg gr4 gr4.jpg jpg 28923 370 373 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr5/DOWNSAMPLED/image/jpeg/9e7d25d9faae76d366d71f4794581c29/gr5.jpg gr5 gr5.jpg jpg 76616 354 667 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr6/DOWNSAMPLED/image/jpeg/cb0ecf10bc83f963e8b8e656d209b2ce/gr6.jpg gr6 gr6.jpg jpg 133206 639 667 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr7/DOWNSAMPLED/image/jpeg/b6eff7b2a487c27c158ee37f94f6b3b2/gr7.jpg gr7 gr7.jpg jpg 191047 899 711 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr8/DOWNSAMPLED/image/jpeg/b06d4525fecb9c8dc78833ac121b8440/gr8.jpg gr8 gr8.jpg jpg 148382 724 711 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr9/DOWNSAMPLED/image/jpeg/5751b802657d12c6bf4d68a77dcd5486/gr9.jpg gr9 gr9.jpg jpg 54053 239 756 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr1/DOWNSAMPLED/image/jpeg/35873a0953697d5d747dd25dc38c3aa9/gr1.jpg gr1 gr1.jpg jpg 76720 544 667 IMAGE-DOWNSAMPLED 1-s2.0-S0378778821007891-gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr10/THUMBNAIL/image/gif/23a348bf118a4e2a6a23dff879d0b273/gr10.sml gr10 gr10.sml sml 6135 110 219 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr2/THUMBNAIL/image/gif/4789bd0f3b15ad43ebc49eea4ab01f2d/gr2.sml gr2 gr2.sml sml 5373 105 219 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr3/THUMBNAIL/image/gif/0f6dcfa12e39be121053fa7f5b80aa3a/gr3.sml gr3 gr3.sml sml 9779 156 219 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr4/THUMBNAIL/image/gif/10b62176ab08cb01f3841e7bc6716693/gr4.sml gr4 gr4.sml sml 6470 164 165 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr5/THUMBNAIL/image/gif/862fa33ad8bac004838dc9c4bed1c4b8/gr5.sml gr5 gr5.sml sml 11988 116 219 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr6/THUMBNAIL/image/gif/a0f640a251d801316720c8d4e692e9ff/gr6.sml gr6 gr6.sml sml 11160 164 171 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr7/THUMBNAIL/image/gif/2477604ff025c2cf177a755c73e0a062/gr7.sml gr7 gr7.sml sml 9053 163 129 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr8/THUMBNAIL/image/gif/05a4d5bccb7bbdb9d04677edfce8d966/gr8.sml gr8 gr8.sml sml 11978 164 161 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr9/THUMBNAIL/image/gif/b4803ac94b0879c43313e6c69ff711ff/gr9.sml gr9 gr9.sml sml 6755 69 219 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr1/THUMBNAIL/image/gif/ba6e8514010cf7d4f2cc6f8c2fbf8c85/gr1.sml gr1 gr1.sml sml 10040 164 201 IMAGE-THUMBNAIL 1-s2.0-S0378778821007891-gr10_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr10/HIGHRES/image/jpeg/d99af77be8094983cc1546e82dabe936/gr10_lrg.jpg gr10 gr10_lrg.jpg jpg 381876 1395 2776 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr2/HIGHRES/image/jpeg/359b0fbd5f4571b44880193da342a786/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 127535 794 1654 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr3/HIGHRES/image/jpeg/8a1a035a75f537068d6b6520da408105/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 515055 2105 2953 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr4/HIGHRES/image/jpeg/e426e7375e6bc80036d0a4e9eb9c04ab/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 187245 1642 1654 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr5/HIGHRES/image/jpeg/72cbce615d9d25cc35cdfd66d9dd23a5/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 621234 1569 2953 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr6/HIGHRES/image/jpeg/462c76c93f35507bfc96b55118feae6a/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 1160353 2829 2953 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr7/HIGHRES/image/jpeg/35ccdea752af3de6ceb097039b6e1c1e/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 1943451 3984 3150 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr8/HIGHRES/image/jpeg/68388afca76fd3cdd275042967bffb63/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 1290208 3209 3150 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-gr9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr9/HIGHRES/image/jpeg/a97af39a76861a499075479a1e243b5c/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 493154 1060 3346 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/gr1/HIGHRES/image/jpeg/22aa7cedfd78ea2a7fee868d7036917b/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 474761 2409 2953 IMAGE-HIGH-RES 1-s2.0-S0378778821007891-si1.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/3f429519d50262a290059007b50b9fdd/si1.svg si1 si1.svg svg 13082 ALTIMG 1-s2.0-S0378778821007891-si10.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/8b3f3ef7bd277340ae4058daf2db992d/si10.svg si10 si10.svg svg 18460 ALTIMG 1-s2.0-S0378778821007891-si11.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/72a74ee3ea6e64a8596a74849e89bdc7/si11.svg si11 si11.svg svg 7053 ALTIMG 1-s2.0-S0378778821007891-si12.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/35f07f7f3d233f055c6212ae4f4ff31b/si12.svg si12 si12.svg svg 1330 ALTIMG 1-s2.0-S0378778821007891-si13.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/9bb263e01772d2fbca4f15153a69ef15/si13.svg si13 si13.svg svg 13704 ALTIMG 1-s2.0-S0378778821007891-si14.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/cf1cdc78e16e7e5eae67594f547fcac1/si14.svg si14 si14.svg svg 1377 ALTIMG 1-s2.0-S0378778821007891-si15.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/5aee512576c2f7ab0bdb2efe31791981/si15.svg si15 si15.svg svg 10616 ALTIMG 1-s2.0-S0378778821007891-si16.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/6e12d9a08b70a723faff96935b8946f4/si16.svg si16 si16.svg svg 14659 ALTIMG 1-s2.0-S0378778821007891-si17.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/d2807985ffa43762c8860fee92d00f3f/si17.svg si17 si17.svg svg 23765 ALTIMG 1-s2.0-S0378778821007891-si18.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/6e736b4c7c5d9b1cf31223e310f33d38/si18.svg si18 si18.svg svg 7924 ALTIMG 1-s2.0-S0378778821007891-si19.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/1d5dc1be956e77bc7d55fc6a6485385a/si19.svg si19 si19.svg svg 2547 ALTIMG 1-s2.0-S0378778821007891-si2.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/38b7cd4e1f9146cc43d63e818683193d/si2.svg si2 si2.svg svg 18600 ALTIMG 1-s2.0-S0378778821007891-si20.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/979ff8b1f61f0b065dac8d564410ef62/si20.svg si20 si20.svg svg 8278 ALTIMG 1-s2.0-S0378778821007891-si21.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/39943e9d5fc16e84c12a728e4b242be8/si21.svg si21 si21.svg svg 13647 ALTIMG 1-s2.0-S0378778821007891-si22.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/524d3cddc0a832693b53e6ccdcffa6ad/si22.svg si22 si22.svg svg 12369 ALTIMG 1-s2.0-S0378778821007891-si23.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/39371838e4f146428d6d099ad6c430f2/si23.svg si23 si23.svg svg 23037 ALTIMG 1-s2.0-S0378778821007891-si24.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/660a26c21613b6ab5d479ec1cb4cd10d/si24.svg si24 si24.svg svg 8666 ALTIMG 1-s2.0-S0378778821007891-si25.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/2e3422a6df46f470cc32f6dea4bb583e/si25.svg si25 si25.svg svg 6408 ALTIMG 1-s2.0-S0378778821007891-si26.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/2a73a4e54aee910c389bdd5fe8ceb676/si26.svg si26 si26.svg svg 3419 ALTIMG 1-s2.0-S0378778821007891-si27.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/03f9acfd50a3380607015d3ce19e04f5/si27.svg si27 si27.svg svg 18222 ALTIMG 1-s2.0-S0378778821007891-si28.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/c9a3c3d0a80f044faca4fbd3eb1f6fa5/si28.svg si28 si28.svg svg 19015 ALTIMG 1-s2.0-S0378778821007891-si29.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/6e805a6bddc850426df41fb78e28cd15/si29.svg si29 si29.svg svg 7358 ALTIMG 1-s2.0-S0378778821007891-si3.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/7a488b9ab1a1858d2499c69fb067ea59/si3.svg si3 si3.svg svg 1960 ALTIMG 1-s2.0-S0378778821007891-si30.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/195979725f0f13b269e682faea84cdc6/si30.svg si30 si30.svg svg 20101 ALTIMG 1-s2.0-S0378778821007891-si31.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/57b0430ff2da2832f8319f46a3d6c964/si31.svg si31 si31.svg svg 7086 ALTIMG 1-s2.0-S0378778821007891-si32.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/6bec74d5ad235dc992ecf5a456df4c2d/si32.svg si32 si32.svg svg 22610 ALTIMG 1-s2.0-S0378778821007891-si33.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/7934635f09195c02188bf6c298e5c99c/si33.svg si33 si33.svg svg 14707 ALTIMG 1-s2.0-S0378778821007891-si34.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/bfdcd4ad1e64bfbcc0575dbc497b57af/si34.svg si34 si34.svg svg 12498 ALTIMG 1-s2.0-S0378778821007891-si35.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/722674eee5499fa8ad07cbe7788fec44/si35.svg si35 si35.svg svg 20121 ALTIMG 1-s2.0-S0378778821007891-si36.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/c9d63213520555df8cdab62bd3cc405f/si36.svg si36 si36.svg svg 19622 ALTIMG 1-s2.0-S0378778821007891-si37.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/9c6ad9402025c5e7516e8a6044fc9981/si37.svg si37 si37.svg svg 21712 ALTIMG 1-s2.0-S0378778821007891-si38.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/2b837ee98e7bdea4e008285868a1be2b/si38.svg si38 si38.svg svg 15269 ALTIMG 1-s2.0-S0378778821007891-si39.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/4b556391f941bec7e432f748b052fe81/si39.svg si39 si39.svg svg 6371 ALTIMG 1-s2.0-S0378778821007891-si4.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/cb267e31985f2e5dd5db3b2687fd08dd/si4.svg si4 si4.svg svg 17606 ALTIMG 1-s2.0-S0378778821007891-si40.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/1fe1296585dc204e8a50e249398c531e/si40.svg si40 si40.svg svg 4494 ALTIMG 1-s2.0-S0378778821007891-si41.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/9e95bc3bed2746e3a00ee95bf44650f2/si41.svg si41 si41.svg svg 4189 ALTIMG 1-s2.0-S0378778821007891-si42.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/978974e682641b153ad3726f4e44e57e/si42.svg si42 si42.svg svg 15803 ALTIMG 1-s2.0-S0378778821007891-si43.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/eba0b7c1d933a9dceaf8698347efade1/si43.svg si43 si43.svg svg 2802 ALTIMG 1-s2.0-S0378778821007891-si44.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/c4a006a4a7725472d40ebdb138643f96/si44.svg si44 si44.svg svg 3212 ALTIMG 1-s2.0-S0378778821007891-si45.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/3efb413dca419683eb228dd50607190f/si45.svg si45 si45.svg svg 6314 ALTIMG 1-s2.0-S0378778821007891-si46.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/cd922b6688079ce8fc0b0beb48a1c440/si46.svg si46 si46.svg svg 40034 ALTIMG 1-s2.0-S0378778821007891-si47.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/7e41bc887259880e3fe2205531d5ad2f/si47.svg si47 si47.svg svg 18792 ALTIMG 1-s2.0-S0378778821007891-si48.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/d3da6ec973956c0e72c39c178f78faf4/si48.svg si48 si48.svg svg 22920 ALTIMG 1-s2.0-S0378778821007891-si49.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/9c3e6c17ab6094a6a479e898060a74d3/si49.svg si49 si49.svg svg 24073 ALTIMG 1-s2.0-S0378778821007891-si5.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/6b91e0f8156f3729eb9b54651fe91502/si5.svg si5 si5.svg svg 18603 ALTIMG 1-s2.0-S0378778821007891-si50.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/3e483104f6c183672e562128c10866ed/si50.svg si50 si50.svg svg 18444 ALTIMG 1-s2.0-S0378778821007891-si51.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/0fd19e749cd476a2ec493a513b30b4d1/si51.svg si51 si51.svg svg 19692 ALTIMG 1-s2.0-S0378778821007891-si6.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/6f123a674f19ba6d75ec965bf94270a0/si6.svg si6 si6.svg svg 11763 ALTIMG 1-s2.0-S0378778821007891-si7.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/50342dbf1cba77058b9f25c4aaccd6bf/si7.svg si7 si7.svg svg 11810 ALTIMG 1-s2.0-S0378778821007891-si8.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/786ff21b1c923e71a21f623cb848e9b2/si8.svg si8 si8.svg svg 11038 ALTIMG 1-s2.0-S0378778821007891-si9.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0378778821007891/STRIPIN/image/svg+xml/558b71c4ee5159146955632b2ea4ef33/si9.svg si9 si9.svg svg 5284 ALTIMG 1-s2.0-S0378778821007891-am.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:102CWDJ71LR/MAIN/application/pdf/b59abb443117a9f57f879ea14b305e85/am.pdf am am.pdf pdf false 1046850 AAM-PDF ENB 111505 111505 S0378-7788(21)00789-1 10.1016/j.enbuild.2021.111505 Elsevier B.V. Fig. 1 The machine-learning models investigated in this paper and corresponding correlations. Fig. 2 General structure of artificial neural network-based models; x: input matrices; ω: weights matrices; f(x): trained model; b: excursion matrices. Fig. 3 General structure for support vector machine and Gaussian process regression models; x: input vector; φ: mapping function; K: kernel function; f(x): trained model. Fig. 4 The general structure of tree-based models. Fig. 5 The hourly heating load, flow, dry-bulb temperature and solar radiation studied in this paper. Fig. 6 Prediction accuracies of the 15 models investigated in this study. Fig. 7 Scatter plot of predicted and measured short-term district heating load values. Fig. 8 Comparison predicted and measured values for short-term district heating load. Fig. 9 Comparison of R2 between training and testing phases and increase in testing R2 over training R2. Fig. 10 Comparison of computation time of the 15 models for the training and testing phases. Table 1 Hyper-parameter search ranges and steps for the 15 ML models. Models Hyper-parameters Minimum values Maximum values Steps MLP N 1 20 1 RBF-NN Spread 1 500 1 GRNN Spread 0 1 0.01 ELM C 0 500 1 θ 0 10 0.01 SVM C 0 100 1 g 0 20 0.01 p 0 1 0.01 LSSVM C 0 100 1 g 0 20 0.01 GPR Mean \u2013 \u2013 \u2013 Cov RTree Parent 5 100 5 Leaf 5 500 5 M5tree Parent 5 100 5 Leaf 5 500 5 RF Tree 300 500 10 Depth 1 10 1 GBDT Estimators 100 500 10 Depth 1 10 1 XGBoost Estimators 10 500 10 Depth 1 10 1 LightGBM Leaf 10 500 10 Depth 1 10 1 CatBoost Iterations 10 500 10 Depth 1 10 1 MARS Functions 1 100 1 Interactions 1 5 1 Table 2 Descriptive statistics for hourly input variables utilized in this study. Parameters Training dataset Validation dataset Average Maximum Minimum Standard deviation Average Maximum Minimum Standard deviation T (°C) −0.7 17.0 −17.0 5.9 4.2 21.0 −9.0 6.2 Rh (%) 59.3 100.0 10.0 22.6 39.5 93.0 10.0 18.2 Ws (m/s) 2.3 8.0 1.0 1.4 2.6 8.0 0.0 1.0 SR (W/m2) 301.4 800.0 0.0 221.7 369.6 886.1 0.0 271.8 G (kg/s) 128.7 149.4 106.0 8.9 130.9 158.5 114.0 9.4 T supply,1 (°C) 83.5 95.2 63.0 5.6 76.1 84.1 62.7 5.6 P supply,1 (MPa) 0.96 1.10 0.65 0.04 0.95 0.99 0.76 0.03 T return,1 (°C) 45.6 51.6 31.9 3.7 44.7 48.2 40.7 1.4 P return,1 (MPa) 0.97 1.15 0.77 0.04 0.97 1.05 0.85 0.03 T supply,2 (°C) 54.7 66.1 39.0 4.4 51.9 57.6 40.9 3.2 P supply,2 (MPa) 0.48 0.54 0.43 0.02 0.48 0.59 0.44 0.02 T return,2 (°C) 43.8 50.0 27.0 3.3 42.7 46.0 38.9 1.4 P return,2 (MPa) 0.32 0.36 0.27 0.01 0.32 0.34 0.30 0.01 Q (kW) 5685.7 7518.6 3743.9 734.2 4744.8 5612.9 3313.8 564.5 Table 3 Weights and ranks of the fourteen parameters related to heating load obtained from the ReliefF algorithm. Parameters Description Weights Ranks T Ambient dry-bulb temperature 0.0074 7 Rh Relative humidity 0.0009 11 Ws Wind speed −0.0069 14 SR Solar radiation −0.0014 12 G Mass flow rate 0.0123 4 T supply,1 Supply water temperature of primary network 0.0236 2 P supply,1 Supply water pressure of primary network 0.0045 9 T return,1 Return water temperature of primary network 0.0124 3 P return,1 Return water pressure of primary network 0.006 8 T supply,2 Supply water temperature of secondary network 0.0084 5 P supply,2 Supply water pressure of secondary network −0.0023 13 T return,2 Return water temperature of secondary network 0.008 6 P return,2 Return water pressure of secondary network 0.0014 10 Q One-hour ahead heating load 0.0389 1 Table 4 Optimized hyper-parameter values for the 15 models investigated in this study. Model Parameters MLP N = 4 RBFNN Spread = 388 GRNN Spread = 0.12 ELM C = 466, θ = 8.27 SVM C = 35, g = 0.02, p = 0.12 LSSVM C = 98, g = 16.49 GPR Mean = 1032.0, Cov = [7.38, 7.00, 0.10] RTree Parent = 35, Leaf = 30 M5tree Parent = 30, Leaf = 40 RF Tree = 350, Depth = 3 GBDT Estimators = 210, Depth = 1 XGBoost Estimators = 130, Depth = 1 LightGBM Leaf = 40, Depth = 5 CatBoost Iterations = 180, Depth = 2 MARS Functions = 51, Interactions = 2 Table 5 The summary of 15 machine-learning models investigated in this study. Classifications Models Accuracy Over-fitting Training Speed Training Testing ANN-based MLP ★★★ ★★★★ ★ ★★★ RBFNN ★★★★ ★★★★★ ★ ★★ GRNN ★★★★★ ★ ★★★★★★ ★★★★★★ ELM ★★★★ ★ ★★★★ ★★★★★ Kernel-based SVM ★★★ ★★★★★★ ★ ★★★★★★ LSSVM ★★★★ ★★★★★ ★ ★★★★★ GPR ★★★ ★★★★★★ ★ ★★ Tree-based RTree ★★ ★★ ★★★★★ ★★★★ MTree ★★★ ★★★ ★ ★★★★ RF ★★★★★★ ★★★ ★★★★ ★★★★★ GBDT ★★★★ ★★★★ ★★★ ★★★★ XGBoost ★★★★ ★★★ ★★★ ★★★★★ LightGBM ★★★★ ★★★ ★★★ ★★★★★★ CatBoost ★★★★ ★★★ ★★ ★★★ Other MARS ★★★★ ★★★★★★ ★ ★ Comparison of machine-learning models for predicting short-term building heating load using operational parameters Yong Zhou a b \u204e Yanfeng Liu b c Dengjia Wang b c Xiaojun Liu a a School of Management, Xi\u2019an University of Architecture and Technology, No. 13 Yanta Road, Xi\u2019an 710055, China School of Management Xi\u2019an University of Architecture and Technology No. 13 Yanta Road Xi\u2019an 710055 China School of Management, Xi\u2019an University of Architecture and Technology, No. 13 Yanta Road, Xi\u2019an 710055, China b State Key Laboratory of Green Building in Western China, Xi\u2019an University of Architecture and Technology, No. 13 Yanta Road, Xi\u2019an 710055, China State Key Laboratory of Green Building in Western China Xi\u2019an University of Architecture and Technology No. 13 Yanta Road Xi\u2019an 710055 China State Key Laboratory of Green Building in Western China, Xi\u2019an University of Architecture and Technology, No. 13 Yanta Road, Xi\u2019an 710055, China c School of Building Services Science and Engineering, Xi\u2019an University of Architecture and Technology, No. 13 Yanta Road, Xi\u2019an 710055, China School of Building Services Science and Engineering Xi\u2019an University of Architecture and Technology No. 13 Yanta Road Xi\u2019an 710055 China School of Building Services Science and Engineering, Xi\u2019an University of Architecture and Technology, No. 13 Yanta Road, Xi\u2019an 710055, China \u204e Corresponding author at: School of Management, Xi\u2019an University of Architecture and Technology, No. 13 Yanta Road, Xi\u2019an 710055, China. School of Management Xi\u2019an University of Architecture and Technology No. 13 Yanta Road Xi\u2019an 710055 China Short-term building energy consumption prediction is of great significance to the optimal operation of building energy systems and conservation. Machine-learning models are widely used due to their high prediction accuracy and efficiency in dealing with high-dimensional nonlinear problems. To compare the performance of different machine-learning models in building energy consumption prediction, this paper analyzes 15 machine-learning models, including a multi-layer perception, a radials basis function neural network, a generalized regression neural network, an extreme learning machine, a support vector machine, a least-square support vector machine, a Gaussian process regression, a regression tree, a model five tree, a random forest, a gradient boosting decision tree, an extreme gradient boosting tree, a light gradient boosting machine, a categorical gradient boosting tree and a multi-adaptive regression spline, from the aspects of model prediction accuracy, model stability (over-fitting) and calculation speed. The operation parameters determined by ReliefF algorithm were used as input parameters. The results showed that the prediction accuracy of all models is higher in the training phases, with R2 values greater than 0.90, while the prediction accuracy in testing phases was much lower. In terms of prediction accuracy and model stability, the Gaussian process regression model had the best overall performance among the 15 models, while the support vector machine had the faster calculation speed with acceptable prediction accuracy. For small datasets, the Gaussian process regression model is recommended, and the support vector machine should be preferred for large datasets. The results of this paper can provide a basis for model selection and the establishment of combined models for predicting building energy consumption. Keywords Machine-learning model Feature selection Building heating load Building energy prediction Nomenclature Symbols C Penalty parameters G Flow rate (kg/s) Q Heating load (kWh) Rh Relative humidity (%) R 2 Coefficient of determination T Dry-bulb temperature (°C) T supply, 1 Supply water temperature of primary pipe networks (°C) T supply, 2 Supply water temperature of secondary pipe networks (°C) T return, 1 Return water temperature of primary pipe networks (°C) T return, 2 Return water temperature of secondary pipe networks (°C) P supply, 1 Supply water pressure of primary pipe networks (MPa) P supply, 2 Supply water pressure of secondary pipe networks (MPa) P return, 1 Return water pressure of primary pipe networks (MPa) P return, 2 Return water pressure of secondary pipe networks (MPa) Ws Wind speed (m/s) Abbreviations ANN Artificial neural network CatBoost Categorical gradient boosting tree CV-RMSE Coefficient of variation of the RMSE (%) ELM Extreme learning machine GBDT Gradient boosting decision tress GPR Gaussian process regression LightGBM Light gradient boost machine LSSVM Least square support vector machine LSTM Long short-term memory MAE Mean square error (kWh) MARS Multi-adaptive regression spline ML Machine learning M5Tree Model five tree RBF Radials basis function RF Random forest RMSE Root mean square error (kWh) RTree Regression tree SR Solar radiation (W/m2) SVM Support vector machine XGBoost Extreme gradient boosting tree 1 Introduction Accurate and reliable prediction of building energy consumption is of great significance for building predictive control and optimal scheduling [1]. Based on the duration period, predicting building energy consumption can be divided into short-, medium- and long-term. Short-term building energy prediction is closely related to the daily operation model of energy systems; it can provide useful guidance and be used to develop cost-effective and energy-saving measures for users [2]. Short-term prediction can be used to adjust the energy system in real time according to the predicted values to match the energy-supply end and demand, so as to help the system operate effectively and harmoniously. Short-term prediction can also be used to formulate the operation and regulation strategy of building energy supply systems, so as to achieve better energy distribution [3]. Building energy prediction methods can be divided into two categories [4]: physical models and data-driven models. Physical models require detailed building information as input parameters, including detailed envelope information such as doors, windows, external walls and the layout of buildings. However, this information is often difficult to obtain accurately, which limits the applicability of physical models [5]. In contrast, with the rapid development of Internet-of-things technology, a large number of building operation data have become accessible, which provides an opportunity for data-driven methods [6]. Data driven models usually include statistical models and machine-learning models (ML) [7]. ML-based building energy prediction models are supervised learning models [8], which learn from existing data and do not rely on predetermined equations to predict new results [9]. Because of their high prediction accuracy in high-dimensional nonlinear problems, they have become the most commonly used models in data-driven methods [10], and include artificial neural network (ANNs) [11], support vector machine (SVMs) [12], decision trees [13], and others. Turhan et al. [14] compared an ANN and building energy simulation tools for heating load prediction and the results showed that, compared with building energy simulation software, the ANN model had the advantages of being simpler to implement and achieved faster calculation speed. Similar conclusions were obtained by Chen et al. [15]. Dong et al. [16] developed an ensemble model based on the running conditions of buildings during different periods which showed a higher prediction accuracy compared with ANN and SVM models. Lei et al. [17] developed a deep neural network combined with a rough dataset for building energy consumption prediction and illustrated that, compared with back propagation, Elman and fuzzy neural networks, the deep network achieved greater accuracy. Ding et al. [18] developed a long short-term memory (LSTM) model integrated with evolutionary double-attention model for building energy consumption prediction. Through the analysis of RMSE and MAE, the combined model proved to be better than other LSTM models. Zhang et al. [19] developed a combined LSTM and ANN model. Zeng et al. [20] developed the Gaussian process regression model (GPR) and illustrated that it can predict the energy consumption of office buildings under the condition of balanced data with high prediction accuracy, average deviation less than 15% and low calculation time. Shao et al. [21] developed SVM models to predict hotel energy consumption. Kamel et al. [22] developed XGBoost model to determine the optimal features for cooling the heating energy predictions. The comparison with filter and wrapped feature selection methods proved that XGBoost yielded the highest performances. Researchers have established a series of ML models to predict building energy consumption and proved that different models are very effective in predicting building cooling, heating, electric and other loads. However, the performance of different ML models varies greatly. For example, Yan et al. [23] compared the random forest (RF), AdaBoost, SVM, ANN, gradient boosting decision tree (GBDT), and extreme gradient boosting tree (XGBoost) models and proved that the latter two have higher prediction accuracy and faster calculation speeds than the other four models. Deng et al. [24] compared six models, namely linear regression, Lasso region, SVM, RF, gradient boosting and ANN. The results showed that the ANN and gradient boosting method showed high regularity and programmability, and higher performance in different subsets. Understanding the performance of different ML models is very important for researchers to build more advanced combination models. Therefore, in this study we compare and analyze a total of 15 models, namely the multi-layer perception (MLP), radials basis function neural network (RBFNN), generalized regression neural network (GRNN), extreme learning machine (ELM), SVM, least square SVM (LSSVM), GPR, regression tree (RTree), model five tree (M5tree), RF, GBDT, XGBoost, light gradient boosting machine (LightGBM), categorical gradient boosting tree (CatBoost) and multi-adaptive regression spline (MARS), from the aspects of prediction accuracy, model stability and calculation time, to provide basic guidance for the establishment of hybrid models. 2 Method In this section, we introduce the ML models, feature selection algorithms, hyper-parameter optimization methods and evaluation metrics. 2.1 Machine learning models Due to its advantages of high prediction accuracy and excellent performance when dealing with high-dimensional nonlinear problems, ML models are widely used by researchers [25]. Overall, ML models could be categorized into general and deep ML models. Generally, deep MLs yield higher accuracy than general MLs. However, deep MLs have the problems of higher computational cost, longer computational time, higher hardware requirements, resulting in its poor portability. For building energy control systems, the lower computational cost, faster computational speed and better portability are significant. Thus, there is a long way to go for deep MLs being applied to building energy control system. Therefore, general ML models are studied and compared in this study. ML models could also be categorized into ANN-, kernel-, tree-based models and other models. Fig. 1 shows the ML models studied in this paper and corresponding correlations. 2.1.1 ANN-based models The ANN is an extensive parallel interconnected network composed of simple adaptive units. Its organization simulates the interaction of biological neural systems with real world objects. The ANN model is composed of input layers connected to a hidden layer, which processes the data through weighted connection. Each neuron in the hidden layer is interconnected with all neurons in the output layer [26]. The general structure of the model is shown in Fig. 2 . For ANN models, MLP is the simplest structure while RBFNN and GRNN are the simplest variants of MLP. Due to faster computational cost, ELM is also widely used, Therefore, MLP, RBFNN, GRNN and ELM are studied in this paper. 2.1.1.1 Multi-layer perception MLP is the simplest ANN-based model [27]. It consists of an input layer, an output layer and one or more hidden layers [28]. The different layers are fully connected, while different neurons in the same layer are not connected. The input layer is used to receive data; it does not carry out any calculations, but only transfers the data to the adjacent hidden layer by applying different weights. The hidden layer processes the data through a nonlinear activation function, then transfers them to the output layer, which then outputs the final result [29]. A simple three-layer perceptron can be expressed as: (1) f x = b 2 + W 2 s b 1 + W 1 x where W 1 and b 1 are the weight and excursion matrices between the input layer and the hidden layer, respectively; W 2 and b 2 are the corresponding matrices between the hidden layer and the output layer; and s is the activation function. The MLP model is trained using the Levenberg Marquardt back-propagation algorithm. More detailed information can be found in [30]. 2.1.1.2 Radial basis function neural network The RBFNN is a three-layer feedforward neural network, which can be considered as an MLP network with only one hidden layer. The weight between the input layer and the hidden layer of the RBFNN is fixed at 1. The transfer function of the hidden layer unit is a radial basis function (RBF) [31]. The hidden layer neurons multiply the vector distance and deviation bi between the weight vector wi and the input vector Xi and the result is used the input of the neuron activation function. If the RBF is Gaussian, the output of the neuron is as follows: (2) k \u2016 x - x i \u2016 = exp - \u2016 x - x i \u2016 2 2 σ 2 where xi is the kernel function\u2019s center and σ is its width, which is used to determine the input vector of each RBF neuron. The RBFNN has strong nonlinear fitting ability, as it can map any complex nonlinear relationship, and has simple learning rules, which are easy to be implement by computer. More detailed information is available in [32]. 2.1.1.3 Generalized regression neural network The GRNN is an improvement on RBFNN, and is a feedforward neural network model based on nonlinear regression theory [33]. The GRNN consists of the input, mode, summation and output layers [34]. The GRNN does not need a predetermined equation, but uses a probability density function to inherently replace the equation form [35]. The number of neurons of the input layer is the dimension d of the input vector in the learning sample, and each neuron is a simple distribution unit. The number of neurons in the pattern layer is equal to the number of learning samples n, so each neuron corresponds to a learning sample [36]. If the input vector is denoted as X and the output vector is denoted as y, then the network output Y ^ is expected mathematically: (3) Y ^ = E y | X = ∫ - ∞ + ∞ y f X , y d y ∫ - ∞ + ∞ f X , y d y where E(x|y) is the mathematical expectation of output the y, and f(x, y) is the joint probability density function of x and y, which is subject to the normal distribution. 2.1.1.4 Extreme learning machine The ELM is a single-hidden-layer feedforward neural network [37]. The algorithm generates the connection weights between the input and hidden layers and the threshold value of the hidden layer neurons randomly. During the training process, no adjustment is needed; only the number of neurons in the hidden layer is required to obtain the optimal solution [38]. Compared to other types of single-hidden-layer neural networks, the ELM\u2019s learning speed is greatly accelerated [39]. For any N samples (xi , yi ), 1 < i < N, assuming there are m neurons in the input layer, L neurons in the hidden layer, N neurons in the output layer, and g(x) is the activation function, then the output of the network can be expressed as: (4) y i = ∑ j = 1 L β j g ω j x i + b j where β j = β j 1 , β j 2 , ⋯ , β jn T is the weight vector linking the j-th hidden layer node and the network output node; ω j = ω j 1 , ω j 2 , ⋯ , ω jn T denotes the input weight vector of the input layer node and the j-th hidden layer node, and bi is the threshold of the i-th hidden layer node. 2.1.2 Kernel-based models Kernel-based models mainly use kernel functions to map linearly inseparable data from low-dimensional space to high-dimensional space, so as to achieve linear separability. They mainly include the SVM, LSSVM and the GPR models. The general structure of kernel-based models is shown in Fig. 3 . 2.1.2.1 Support vector machine SVM is a supervised learning algorithm proposed by Vapnik et al. [40] in 1995, and is suitable for ML of small samples and high-dimensional data. The SVM uses a kernel function to transform samples which are linearly inseparable in low-dimensional space to a high-dimensional feature space to maximize the distance between the hyperplane and the nearest data points of each class [9]. The objective function of SVM can be expressed as follows: (5) f x = ω φ x + b where φ x is a high-dimensional feature space, while ω and b are the weight vector and deviation, respectively. Compared with other kernel functions, the RBF is adopted in this study due to its better performance [9], and it can be expressed as: (6) K x i , x j = e x p - γ \u2016 x i - x j \u2016 2 where γ = - 1 2 σ 2 ; σ is the Gaussian noise; and xi and xj are the feature vectors of the input space, which can be obtained from the training set. 2.1.2.2 Least square support vector machine LS-SVM is an improved version of SVM, which transforms the inequality constraints of traditional SVMs into equality constraints, and transforms the sum-of-squares error loss function into an empirical loss function of training data. The training process is transformed into a solution of linear equations, which greatly improves the solution efficiency of traditional SVMs and reduces the learning difficulty [41]. (7) 0 y T y Ω + I / y b α = 0 1 v where Ω is the kernel matrix. Similarly to SVMs, in this study the RBF kernel function is adopted for the LSSVM. 2.1.2.3 Gaussian process regression The GPR is a nonparametric model that uses a Gaussian process prior for data analysis. It uses a kernel function to replace the linear kernel of Bayesian linear regression, so it has good adaptability and strong generalization ability when dealing with complex problems such as a high number of dimension, small samples and nonlinearity [42]. If we define function space as f x = Φ x T ω , and f x 1 , f x 2 , ⋯ , f x n constitutes a set of random variables which obey the joint Gaussian distribution, then the GPR model can expressed as: (8) y G P m x , c o v x , x ' + σ n 2 δ ij where m(x) is the mean function, δij is Kronecker delta function c o v x , x ' is the covariance matrix, and σ 2 is the variance matrix, which obeys the Gaussian distribution. It can be seen from Eq. (8) that the GPR produces not only an estimated value, but also the variance of the estimated value. This method takes the uncertainty of prediction into account and is therefore more realistic. 2.1.3 Tree-based models Tree-based models mainly include regression and ensemble trees. Ensemble trees take a regression tree as the basis function to build a regression model. The RF is one of the most commonly used ensemble tree models. The general structure of tree-based models is shown in Fig. 4 . RTree is the base models for almost all tree-based models. M5Tree is the simplest variants of RTree. RF is developed based on bagging ensemble method while GBDT, XGBoost, LightGBM and CatBoost are developed based on boosting ensemble method. They are the most commonly used in the tree-based models. Therefore, RTree, M5Tree, RF, GBDT, XGBoost, LightGBM and CatBoost are studied and compared in this study. 2.1.3.1 Regression trees The RTree uses a tree model to solve a regression problem. Each leaf outputs a predictive value, which is generally the mean value of the output of the training set elements contained in the leaf [43]. An obvious advantage of RTree is that it does not require an assumption of the probability distribution, but identifies relevant explanatory variables (or features) and detects the interaction between them. Finally, a piecewise constant regression model is established by taking the average value of the response variables as the prediction value. Tree pruning is often performed by using a statistic that takes into account the sum of squares of deviations as a function of node impurities [44]. A regression tree corresponds to a partition of input space (i.e., feature space) and the output value on the divided unit. Suppose that the input space has been divided into M units R 1 , R 2 , ⋯ , R M , and each unit Rm produces a fixed output value cm . Then the RTree model can be expressed as: (9) f x = ∑ m = 1 M c m I 2.1.3.2 Model five tree M5tree is a high precision first-order linear model tree established by Wang and Witten [45] based on the idea of the piecewise multiple linear regression tree of Quinlan [46]. Using the principle of sample attribute difference, the model splits the sample space until the number of sample books split to a node is less than a certain number or the standard deviation of the node sample attributes is less than a threshold. The principle of sample attribute differentiation can be expressed as follows: (10) SDR = S D T - ∑ T i T S D T i where T is the total set of samples reaching a certain node; Ti is the i-th sample set after splitting T into i spaces; and SD(Ti ) is the attribute standard deviation of the sample set. 2.1.3.3 Random forest RFs are a kind of ensemble model based on decision trees, which randomly take k samples back using random sampling method. [47] The output discriminant is as follows: (11) H x = argmax Y ∑ i = 1 k I h i x = Y where a r g m a x Y is the value when the function reaches the maximum value; h i x is the result of decision tree model; I ∙ is the indicator function; Y is the output variable. 2.1.3.4 Gradient boosting decision tree GBDT is the boosting-based ensemble models. For GBDT, the output was yielded by the weighted-sum of the predictions of weaking learning machine. Assuming that the training samples is D = x 1 , y 1 , x 2 , y 2 , ⋯ , x n , y n , the maximum iteration number is T; the loss function is L y , f x = log 1 + exp - y f x , where y ∈ - 1 , 1 ; the strong learning machine is f(x). The prediction procedure of GBDT are as follows [48]: (1) Initial the weaking learning machine: (12) f 0 x = arg min c L y i , c (2) For the initial number i = 1 , 2 , ⋯ , T , the negative gradient error is: (13) r ti = - ∂ L y , f x i ∂ f x i = y i 1 + exp y , f x i Then, x i , r ti ( i = 1 , 2 , ⋯ , m ) , a regression tree can be obtained, where the space of leaf nodes is R ij ( j = 1 , 2 , ⋯ , J ) , where J is the number of leaf nodes of t-th regression tree. The optimal fitting value of negative gradient is: (14) c tj = ∑ x i ∈ R tj r ti ∑ x i ∈ R tj r ti 1 - r ti (3) Update the strong learning machine: (15) f t x = f t - 1 x + ∑ j = 1 J c tj I x ∈ R tj (4) Finally, the strong learning machine f(x) can be expressed as: (16) f x = f T x = f 0 x + ∑ t = 1 T ∑ j = 1 J c tj I x ∈ R tj 2.1.3.5 Extreme gradient boosting XGBoost is gradient boosting machine proposed by Chen and Guestrin [49] in 2016. The aims of the proposal of XGBoost are to improve the overfitting problems and simplify the model to reduce the computational cost [50]. XGBoost can be expressed as follows: (17) f t t = ∑ k = 1 t f k x t = f t t - 1 + f t x t where f t x t is the prediction of t-th step; f t t and f t t - 1 are the predictions of t-th and (t-1) step. xt is the input. 2.1.3.6 Light gradient boosting machine LightGBM uses the histogram optimization algorithm based on GBDT. First, it discretizes the continuous features into k integers and constructs a histogram with a width of k. When the data are traversed, the statistics are accumulated in the histogram according to the discretized value as the index. After traversing the data, the histogram accumulates the required statistics, and then traverses to find the optimal segmentation point according to the discrete value of the histogram. At the same time, the leaf growth strategy of Leaf-wise with depth is used, and the leaves of the same layer can be split at the same time after one data processing. LightGBM is easy to realize multithread optimization and improve the overfitting problems [51]. 2.1.3.7 Categorical boosting tree CatBoost is a novel gradient boosting decision tree algorithm. It can handle the categorical features, and uses the categorical features in the training process instead of preprocessing. The advantage of CatBoost is that it uses a new pattern to calculate the leaf values when selecting the tree structure, which helps to reduce overfitting and allows the use of the whole training data set, that is, it randomly arranges the data of each instance and calculates the average value of the instances [52]. For the regression task, the average value of the obtained data needs to be used for a priori calculation. 2.1.4 Multi-adaptive regression spline MARS is a piecewise nonlinear and nonparametric regression strategy [39]. Instead of assuming the specific relationship between the input and output variables, the training set is divided into independent segments with different gradients, where each segment is called a basis function and the end points of each segment are called nodes. Each node marks the end of a region and the beginning of the next region. The obtained basis function will give the model more flexibility, allowing bending, thresholding and other deviations from linearity [39]. MARS generates the basis function using a step-by-step search, and uses an adaptive regression algorithm to select the node position. The MARS algorithm is divided into two steps: forward selection and backward pruning. The forward selection process involves dividing and processing the input sample data, while a spline function is used to replace the inter-cell fitting to obtain a new basis function and a fitting model. The backward pruning process involves screening the generated basis functions and eliminating those that have only small contributions to the model so as to avoid overfitting and finally obtain the optimal model [53]. The MARS model is established through the linear combination of basis functions and their relationships and can be expressed as: (18) f x = β 0 + ∑ n = 1 N β n λ n x where β 0 is a constant; N is the number of basis functions; β n the coefficient of the n-th basis function, and λ n x is a basis function. 2.2 ReliefF feature selection algorithm Correlation coefficient method and sensitive analysis are the ones of the most commonly used feature selection method for building energy prediction. However, they could only describe the simple correlation. While the heating load is affected by series factors and the parameters are correlated with complex correlation [3]. Thus, the applicability of these methods is limited. Almaraashi [54] compared four feature selection methods and concluded that considering the calculation speed and prediction accuracy, ReliefF method had the best performances. Therefore, in this paper, ReliefF method was adopted. The RelifF algorithms was proposed by Spolaor et al. [55] to deal with multi-classification problems based on Relief proposed by Kononenko [56], which can only solve a binary classification problems. This algorithm calculates weights according to the correlation between each feature and the target, where larger feature weights correspond to higher correlations of the features with the target [57]. Feature selection is carried out by setting a threshold for feature weights and removing those features whose weight is smaller than the threshold. The basic flow of the ReliefF algorithm is: randomly select a sample R from the training set, take k nearest-neighbor samples from the same sample set of R, then find k-nearest-neighbor samples from other different sample sets, and finally update the feature weight according to the following equation: (19) W A = W A - ∑ j = 1 k d i f f A , R , H j mk + ∑ C ∉ c l a s s R p C 1 - p c l a s s R ∑ j = 1 k d i f f A , R , H j mk where p(C) is the proportion of category C; p(class(R)) is the proportion of the category of a randomly selected sample; diff(A, R 1, R 2) represents the distance between sample R 1 and R 2 in feature A; Hj (C) represents the j-th nearest sample in category C. 2.3 Model set-up and parameter optimization In this study, the hyper-parameters of the GPR model include the mean and covariance matrix, which were calculated via maximum likelihood estimation while the hyper-parameters of other models were calculated using grid search combined with 10-cross validation. Table 1 shows the search range and steps of the hyper-parameters of the 15 models investigated in this study. 2.4 Data collection and data preprocessing Heating load data were obtained from the monitoring system of the heating pipe network in Xi'an University of Architecture and Technology, China (34.24 °N, 108.97 °E). The heating area was 392219.63 square meters, and included the student dormitory, restaurant, teaching building, office building and hospital. The collection period spanned January 2, 2016 and March 2, 2016. The data included the supply and return water temperatures, pressures and flow of the primary and secondary pipe networks. The heating load was calculated from the supply and return water temperatures according to the following equation: (20) Q = c M Δ t = c M t supply - t return where Q is the hourly heating load, kW; c is the specific heat of water, 4.2kj/kg·°C; M is the mass flow rate, in kg/s; t supply and t return are the temperatures of the supply and return water. The hourly heating load calculated using Eq. (13) is shown in Fig. 5 . The fluctuation range of the heating load in the examined period was 3314\u20137519 kW, with an average value of 5398 kW. The hourly outdoor meteorological parameters in the heating period were obtained from the Shaanxi Meteorological Observation Station (34.26 °N, 108.58 °E) and included hourly dry-bulb temperature (T), relative humidity (Rh ), wind speed (Ws ) and solar radiation (SR). Though the meteorological data categories were limited. For example, there is no air pressure, different types of radiation, which may lead to inaccuracy of building energy prediction. However, series researches [3] have illustrated that for meteorological factors, the temperature have the largest impacts on short-term heating load while the other meteorological data have slight impacts. Therefore, these meteorological data are enough for heating load prediction in this paper. Data from January 2 to February 12 were used as the training set, and from February 13 to March 2 as the test set. Table 2 shows the statistical values of the training and test set parameters. 2.5 Evaluation metrics The performance of the models examined in this study was evaluated using the following four evaluation indices: (1) Coefficient of determination (R2) (21) R 2 = ∑ i = 1 n Y i , c - Y - i , c Y i , m - Y - i , m 2 ∑ i = 1 n Y i , c - Y - i , c 2 ∑ i = 1 n Y i , m - Y - i , m 2 where Yi,m are the measured data; Yi,c are the predictions; n is the number of observations [58]. R2 represents the proportion of the sum of squares of regression to the total sum of squares, and larger values are indicative of better model performance. (2) Root mean square error (RMSE) (22) R M S E = ∑ i = 1 n Y i , m - Y i , c 2 n The RMSE mainly describes the short-term performance of the model by comparing the deviation from the true value. (3) Coefficient of variation of the RMSE (CV-RMSE) (23) C V - R M S E = RMSE Y i , m - Different CV-RMSE ranges are indicative of different model performance levels. When the CV-RMSE is less than 10%, the accuracy of the model is considered excellent; If the CV-RMSE is between 10% and 30%, the accuracy of the model is fair; CV-RMSE values greater than 30% reflect poor model performance [59]. (4) Mean absolute error (MAE) (24) M A E = 1 n ∑ i = 1 n Y i , m - Y i , c The MAE reflects the long-term performance of the model. 3 Results and discussion In this study, the short-term heating load prediction accuracy of 15 ML models is studied and compared. First, the ReliefF algorithm is used to select features and determine the input parameters of the models; then, grid search combined with 10-cross validation is used to determine the models\u2019 hyper-parameters; finally, each model is trained and the prediction results are compared and analyzed. All the models were trained on the computer with 8 × Intel (R) Core (TM) i7-10700K CPU @ 3.80 GHz and 32 GB of RAM memory. 3.1 Feature selection Feature selection is a requirement for model-based prediction, as it can eliminate unimportant or redundant information effectively and retain important features, so as to reduce the computational load and alleviate the problem of overfitting. Using the ReliefF algorithm, the importance of different parameters for short-term heating load can be calculated as shown in Table 3 , where higher weights correspond to a stronger positive / negative correlation of the input parameters to the heating load, and vice versa. It is normally understood that, for low-correlated Ws and SR, as Ws increases and SR decreases, the heating load increases. However, due to the low SR values observed during the heating period, the impact of SR on heating load is small. Ws affects the heating load by changing the heat transfer coefficient of the exterior wall surface and the air permeability of doors and windows. However, on the one hand, the change of the heat transfer coefficient of exterior wall surface caused by Ws does not affect the indoor heating load directly. Second, with the enhancement of door and window insulation, as Ws increases, the increase of air permeability is small, which leads to a lower impact of Ws on heating load. And, due to the thermal inertia of buildings, the influence of outdoor temperature to short-term heating load is far less than that of the pipe network operational parameters. Furthermore, the distance between the meteorological stations (34.26 °N, 108.58 °E) and Xi'an University of Architecture and Technology (34.24 °N, 108.97 °E) were too far, as far as nearly 35.9 km, which may further reduce the impacts of these meteorological parameters on heating load. Compared with the supply and return water temperatures, the influence of pressure on the heating load is weak. The main reason is that this is a closed pressure system, so the system pressure changes little, thus its changes are not reflected on the heating load. In contrast, the temperature and historical load of the water supply and return pipe network directly reflect the variation of heating load. Therefore, in this study, the operation parameters, including historical load, primary and secondary pipe network supply and return water temperature and mass flow rate, are used as input parameters. 3.2 Comparison of model performances Taking the system operation parameters as the input parameters, 15 short-term heating load prediction models were established. Using the training dataset, we adopted maximum likelihood estimation for the GPR, and used cross-validation and grid search to obtain the hyper-parameters of the other models, as shown in Table 4 . Once the hyper-parameters of the model were determined, the 15 models in this paper were trained and then the test dataset was used to validate their prediction accuracy. The results are shown in Fig. 6 . Overall, the 15 models can be divided into three categories. The first category includes models with poor prediction accuracy, such as the GRNN model with R2, RMSE, MAE and CV-RMSE values of 0.551, 503.13kW, 332.37kW and 10.61%, respectively, and the RTree model with R2 = 0.656, RMSE = 424.05kW, MAE = 268.71kW and CV-RMSE = 8.94%. The second category comprises models with fair prediction accuracy, and includes the ELM, RF, XGBoost, LightGBM and CatBoost, with R2 between 0.80 and 0.90 and CV-RMSE between 6% and 12%. The third category includes models with excellent prediction accuracy and includes the MLP, RBFNN, SVM, LSSVM, GPR, M5Tree, GBDT and MARS. The R2 values of these models were greater than 0.90, and the CV-RMSE was less than 7%. Overall, the prediction accuracy of the GPR model was the highest. Although the R2 of the GPR and MARS models were both 0.956, which were the largest among all models, the RMSE, MAE and CV-RMSE values of the GPR model were smaller than those of the MARS and other models, which indicates better model performance. In conclusion, the overall prediction accuracy of the GPR model was the highest, followed by that of the MARS, SVM, RBFNN and M5Tree models. To better reveal the difference between the predicted and measured values, Fig. 7 shows a scatter plot of the predicted and measured values for the 15 models. It can be seen that the predicted and measured values of the RTree, GBDT, XGBoost and LightGBM model are discontinuous, which indicates that the four models did not learn the heating load changing trends well. When the heating load was less than about 5000 kW, the prediction accuracy of GRNN was poor, while the heating load was more than about 5000 kW, the distribution of the predicted and the measured value is more concentrated, and the prediction accuracy is better. For the ELM, M5Tree and CatBoost models, when the heating load ranged between 0 and 5500 kW, the prediction effect was fair, and the distribution of the predicted and the measured values is relatively discrete. Fig. 8 demonstrates a comparison of short-term heating load prediction and measured values. Almost all models have acceptable prediction accuracy in the medium term (up to February 27, the middle of the heating period), and the predicted values were in good agreement with the measured ones, except for LightGBM models which shows poor agreement in the whole heating period. However, as the heating period drew to a close, the prediction error gradually began to increase. The similar results were also obtained by nearly all of the models, whose deviation enlarged as time progressed. That is, the models encountered time-dependence problems. The main reason is that the period of the models is too short and it doesn\u2019t cover the entire heating season. As a result, the models have not well learned the feature of the whole heating season. Furthermore, as the heating period ends, the outdoor temperature rises, the heating load gradually begins to decrease, and the change trend of the heating load begins to change. The models were trained mainly using heating load data from the early stage of the heating period (January 2-February 22). The heating load in this period is large and as showed an increasing trend as time passed. After February 27, the heating load gradually decreased with time. Therefore, there was a large difference in the change trends between the training dataset and the test dataset, which led to the poor prediction accuracy of most models at the end of the heating period. Only for the SVM, LSSVM, GPR and MARS models were the predicted values in good agreement with the measured values for the whole heating period. To overcome the problems that the deviation enlarges as time progresses (time-dependence), except for longer duration of dataset for model training, the online ML models may be an alternative. Online ML assumes that the training data continues to arrive, and usually uses a training sample to update the current model, which greatly reduces the spatial complexity and time complexity of the learning algorithm, and has strong real-time performance. Furthermore, seen from Fig. 7 and Fig. 8, it can be easily found that RTree, GBDT, XGBoost and LightGBM seems to be grouped and bounded at specific values. The main reasons may be that for tree-based models, they are developed using classification and regression trees as base model, where the residuals will be allocated to the leaf nodes of each tree, that is, once the allocation is completed, the subsequent result is calculated by the accumulation sum of values that multiplies the value of the previous leaf node and the step size. It perfectly fits the data of the training set, but does not grasp the changing trends brought by the progress of time. As a result, once the changing trends change, the tree-based models will produce the approximate results using the prediction last time. Therefore, the predictions of tree-based models were bounded and seems to be grouped at specific values. In short, the training data used for tree-based modes should be a large dataset and cover the whole changing trends, otherwise, the tree-based models may not well produce excellent predictions in testing phases. Overall, in terms of ANN-based models, the back-propagation algorithm often falls to local optimization, which will lead to overfitting problems. Therefore, ANN-based models in the late stage of heating period performed worse than the middle stage of heating period. For the tree-based models, the feature in the testing phases were failed to be learned due to very series overfitting problems. Thus, almost all of the tree-based models could not well predict the heating load in the late stage of heating period though they performed very well in the middle stage of heating period, which means the generalization ability of tree-based models are much worse. In contrast, as for the kernel-based model, the data which is linearly non-separatable in low dimensional space are transformed into high dimensional where the data is linearly separatable. Thus, it has the advantages of global optimization and slight overfitting problems. Therefore, the kernel-based models performed much better in all stage of heating period, showing the best generalization ability, followed by ANN-based, tree-based models. 3.3 Comparison of model stability Fig. 9 shows a comparison of R2 between the training and testing phases. For the training phase, the R2 values of almost all models were greater than 0.90, which indicates that all models were well trained. However, the R2 values of the GRNN, RTree, RF, ELM, CatBoost and LightGBM models were larger than the corresponding testing phase values by 0.412, 0.294, 0.155, 0.126, 0.100 and 0.099, respectively, which indicates that the six models were over-fitting. For RF, the training phase R2 was the largest in all models at 0.985. This shows that the RF model had the best model performances during training, but its generalization ability was poor. Overall, for the training phases, the average R2 of tree-based models were highest with average R2 = 0.949, followed by ANN-based model with average R2 = 0.947 and kernel-based model with average R2 = 0.939. In training phase, the R2 values of MLP, RBFNN, SVM, LSSVM, GPRS, MTREE and MARS models were less than 0.02 greater than the corresponding test phase values, indicating high model stability. Especially for the LSSVM model, the R2 in the training phase was only 0.005 larger than that of the testing phase, indicating that the model had the best stability and achieved strong generalization. 3.4 Comparison of computation time Fig. 10 shows a comparison of computation time for the training and testing phases of the 15 models. Overall, the calculation speeds in the training phase were generally slower than those in the testing phases. For ANN-based models, because the RBFNN model is a non-sparse model, it generally requires more nodes than the MLP, GRNN and ELM models for same dataset, so its calculation speed was the slowest. For the ELM model, the connection weights of the input and hidden layers and the threshold of the hidden layer are set randomly, and there is no need to adjust after setting, so its calculation speed was the fastest. For kernel-based models, the SVM model had the fastest calculation speed, requiring only needs 0.014 s. Because the LSSVM is a non-sparse model, it usually requires more kernel functions than the SVM model for the same dataset, so its training time was generally slower than that of the SVM. The GPR model is a non-parametric and its training speed, 0.224 s, was the slowest of all the kernel-based models. Among the tree-based models, the LightGBM model has the fastest computing time at 0.005 s. Overall, the LightGBM model was the fastest among all models, followed by SVM, GRNN, while the MARS model was the slowest. 3.5 Comparison of model comprehensive performances Table 5 shows the summary of the 15 models with regard to prediction accuracy, model stability and computational speed. Overall, ANN- and tree-based models yielded higher accuracy in training phases and kernel-based produced better prediction in testing phases, which illustrated that there are sever over-fitting problems for ANN- and tree-based models and the similar conclusions have been proven by [13,26]. Therefore, if the ANN- and tree-based were adopted for building energy consumption prediction, the feature selection should be further studied to improve the over-fitting problems. In addition, larger dataset could be also adopted to improve over-fitting problems. Non-parametric models (including GPR and MARS) have the lowest computational speed, therefore, for large dataset, they are not recommended to be adopted. Kernel-based model performed well both in training and testing phases and it illustrated that they have higher generalization capability. They can be recommended to be used for building energy prediction without any advanced technologies, such as complex feature selection, model combinations. 4 Conclusion and future work In this paper, the importance of input parameters for heating load prediction is determined using the ReliefF algorithm based on historical data, and hyper-parameters for 15 models were determined using cross-validation and grid search. Then, the models\u2019 short-term heating load prediction accuracy was analyzed and compared. The following conclusions were obtained: (1) For short-term heating load prediction, the importance of outdoor meteorological parameters is much lower than that of pipe network operation parameters due to the weak SR of winter, improvements in building air tightness, the continuous enhancement of building envelopes and the thermal inertia of buildings. Thus, for short-term heating load prediction, the operation parameters of the pipe network should be selected first. (2) The kernel-based model performed the best in all models and the GPR model yielded the highest prediction accuracy among the 15 models investigated. Its predicted values were in good agreement with the measured values during the whole heating period, followed by the MARS, SVM, RBF and M5Tree models. Compared with the GPR model, the short-term heating load forecasting accuracy of the other 14 models were significantly lower at the end compared to the middle of the heating period. The main reason is that the change trend of the heating load at the end of the heating period showed greater variation. (3) The R2 of the GRNN, RTree, RF, ELM CatBoost and LightGBM models in the training phases were much larger than those in testing phases, which is indicative of severe over-fitting and poor stability. The R2 of LSSVM in the training and testing phases fluctuated the least, indicating highest model stability among the 15 models. The RF model had the best prediction accuracy in the training phases and can be used to select the model input parameters. (4) Taking into account prediction accuracy and model stability, the GPR model had the best comprehensive performance among the 15 models. SVM had the faster calculation speed and an acceptable calculation accuracy. Therefore, when the dataset of the building load is small, the GPR model can be recommended as the first choice, while the SVM model may be more suitable for large building load datasets. In conclusion, in the field of time series prediction, the over-fitting, under-fitting and time-dependence of a single machine-learning model have been a very important problem for researchers. By comparing the prediction accuracy, stability and calculation time of 15 models, this paper provided a compact guide for model selection and direction for model modification. For ANN-based and tree-based models, the feature selection should be further studied to improve the accuracy. To overcome the time-dependence problems, the online machine-learning models should be further investigated and compared. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements This paper was supported by the National Natural Science Foundation of China (Project No. 52108091), China Postdoctoral Science Foundation Project (Project No. 2020M683431), Basic research program of Natural Science in Shaanxi Province (Project No. 2021JQ-511), Independent Research and Development project of State Key Laboratory of Green Building in Western China (Project No. LSZZ202106). References [1] Na Dong J.-F. Chang Wu Ai-Guo Z.-K. Gao A novel convolutional neural network framework based solar irradiance prediction method Int. J. Electr. Power Energy Syst. 114 2020 105411 Na Dong, Jian-Fang Chang, Ai-Guo Wu, Zhong-Ke Gao. A novel convolutional neural network framework based solar irradiance prediction method. International Journal of Electrical Power & Energy Systems. 114 (2020) 105411. [2] Xi Fang G. Gong G. Li L. Chun W. Li P. Peng A hybrid deep transfer learning strategy for short term cross-building energy prediction Energy. 215 2021 119208 Xi Fang, Guangcai Gong, Guannan Li, Liang Chun, Wenqiang Li, Pei Peng. A hybrid deep transfer learning strategy for short term cross-building energy prediction. Energy. 215 (2021) 119208. [3] Y. Liu Hu Xiaoxue Xi Luo Y. Zhou D. Wang S. Farah Identifying the most significant input parameters for predicting district heating load using an association rule algorithm J. Cleaner Prod. 275 2020 122984 Yanfeng Liu, Xiaoxue Hu, Xi Luo, Yong Zhou, Dengjia Wang, Sleiman Farah. Identifying the most significant input parameters for predicting district heating load using an association rule algorithm. Journal of Cleaner Production. 275 (2020) 122984. [4] M. Bourdeau X.Q. Zhai E. Nefzaoui X. Guo P. Chatellier Modeling and forecasting building energy consumption: a review of datadriven techniques Sustainable Cities Soc. 48 2019 101533 Mathieu Bourdeau, Xiaoqiang Zhai, Elyes Nefzaoui, Xiaofeng Guo, Patrice Chatellier. Modeling and forecasting building energy consumption: A review of datadriven techniques. Sustainable Cities and Society. 48 (2019) 101533. [5] L.u. Yakai Z. Tian R. Zhou W. Liu A general transfer learning-based framework for thermal load prediction in regional energy system Energy. 217 2021 119322 Yakai Lu, Zhe Tian, Ruoyu Zhou, Wenjing Liu. A general transfer learning-based framework for thermal load prediction in regional energy system. Energy. 217 (2021) 119322. [6] Q. Zhang Z. Tian Y. Ding L.u. Yakai J. Niu Development and evaluation of cooling load prediction models for a factory workshop J. Cleaner Prod. 230 2019 622 633 Qiang Zhang, Zhe Tian, Yan Ding, Yakai Lu, Jide Niu. Development and evaluation of cooling load prediction models for a factory workshop. Journal of Cleaner Production. 230 (2019) 622-633. [7] K. Amasyali N.M. El-Gohary A review of data-driven building energy consumption prediction studies Renew. Sustain. Energy Rev. 81 2018 1192 1205 Kadir Amasyali, Nora M. El-Gohary. A review of data-driven building energy consumption prediction studies. Renewable and Sustainable Energy Reviews. 81 (2018) 1192-1205. [8] F. Cheng Fan Y.Z. Xiao A short-term building cooling load prediction method using deep learning algorithms Appl. Energy 195 2017 222 233 Cheng Fan, Fu Xiao, Yang Zhao. A short-term building cooling load prediction method using deep learning algorithms. Applied Energy. 195 (2017) 222-233. [9] Y. Liu Y. Zhou D. Wang Y. Wang Y. Li Y. Zhu Classification of solar radiation zones and general models for estimating the daily global solar radiation on horizontal surfaces in China Energy Convers. Manage. 154 2017 168 179 Yanfeng Liu, Yong Zhou, Dengjia Wang, Yingying Wang, Yong Li, Ying Zhu. Classification of solar radiation zones and general models for estimating the daily global solar radiation on horizontal surfaces in China. Energy Conversion and Management. 154 (2017) 168-179. [10] Y. Ding Q. Zhang T. Yuan Research on short-term and ultra-short-term cooling load prediction models for office buildings Energy Build. 154 2017 254 267 Yan Ding, Qiang Zhang, Tianhao Yuan. Research on short-term and ultra-short-term cooling load prediction models for office buildings. Energy and Buildings. 154 (2017) 254-267. [11] C. Fan Y. Sun Y. Zhao M. Song J. Wang Deep learning-based feature engineering methods for improved building energy prediction Appl. Energy 240 2019 35 45 Cheng Fan, Yongjun Sun, Yang Zhao, Mengjie Song, Jiayuan Wang. Deep learning-based feature engineering methods for improved building energy prediction. Applied Energy. 240 (2019) 35-45. [12] A.S. Ahmad M.Y. Hassan M.P. Abdullah H.A. Rahman F. Hussin H. Abdullah R. Saidur A review on applications of ANN and SVM for building electrical energy consumption forecasting Renew. Sustain. Energy Rev. 33 2014 102 109 A. S. Ahmad, M. Y. Hassan, M. P. Abdullah, H. A. Rahman, F. Hussin, H. Abdullah, R. Saidur. A review on applications of ANN and SVM for building electrical energy consumption forecasting. Renewable and Sustainable Energy Reviews. 33 (2014) 102-109. [13] M.W. Ahmad M. Mourshed Y. Rezgui Trees vs Neurons: comparison between random forest and ANN for high-resolution prediction of building energy consumption Energy Build. 147 2017 77 89 Muhammad Waseem Ahmad, Monjur Mourshed, Yacine Rezgui. Trees vs Neurons: Comparison between random forest and ANN for high-resolution prediction of building energy consumption. Energy and Buildings. 147 (2017) 77-89. [14] Cihan Turhan, Tugce Kazanasmaz, Ilknur Erlalelitepe Uygun, Kenan Evren Ekmen, Gulden Gokcen Akkurt. Comparative study of a building energy performance software (KEP-IYTE-ESS) and ANN-based building heat load estimation. Energy Build. 85 (2014) 115\u2013125. [15] Si Chen Y. Ren D. Friedrich Yu Zhibin Yu James Sensitivity analysis to reduce duplicated features in ANN training for district heat demand prediction Energy AI 2 2020 100028 Si Chen, Yaxing Ren, Daniel Friedrich, Zhibin Yu, James Yu. Sensitivity analysis to reduce duplicated features in ANN training for district heat demand prediction. Energy and AI. 2 (2020) 100028. [16] Z. Dong J. Liu B. Liu K. Li X. Li Hourly energy consumption prediction of an office building based on ensemble learning and energy consumption pattern classification Energy Build. 241 2021 110929 Zhenxiang Dong, Jiangyan Liu, Bin Liu, Kuining Li, Xin Li. Hourly energy consumption prediction of an office building based on ensemble learning and energy consumption pattern classification. Energy and Buildings. 241 (2021) 110929. [17] L. Lei W. Chen Wu Bing C. Chen W. Liu A building energy consumption prediction model based on rough set theory and deep learning algorithms Energy Build. 240 2021 110886 Lei Lei, Wei Chen, Bing Wu, Chao Chen, Wei Liu. A building energy consumption prediction model based on rough set theory and deep learning algorithms. Energy and Buildings. 240 (2021) 110886. [18] Z. Ding W. Chen Hu Ting Xu Xiaoxiao Evolutionary double attention-based long short-term memory model for building energy prediction: case study of a green building Appl. Energy 288 2021 116660 Zhikun Ding, Weilin Chen, Ting Hu, Xiaoxiao Xu. Evolutionary double attention-based long short-term memory model for building energy prediction: Case study of a green building. Applied Energy. 288 (2021) 116660. [19] C. Zhang J. Li Y. Zhao T. Li Qi Chen X. Zhang A hybrid deep learning-based method for short-term building energy load prediction combined with an interpretation process Energy Build. 225 2020 110301 Chaobo Zhang, Junyang Li, Yang Zhao, Tingting Li, Qi Chen, Xuejun Zhang. A hybrid deep learning-based method for short-term building energy load prediction combined with an interpretation process. Energy and Buildings. 225 (2020) 110301. [20] A. Zeng H. Ho Yu Yao Prediction of building electricity usage using Gaussian Process Regression J. Build. Eng. 28 2020 101054 Aaron Zeng, Hodde Ho, Yao Yu. Prediction of building electricity usage using Gaussian Process Regression. Journal of Building Engineering. 28 (2020) 101054. [21] M. Shao X. Wang Bu Zhen X. Chen Y. Wang Prediction of energy consumption in hotel buildings via support vector machines Sustainable Cities Soc. 57 2020 102128 Minglei Shao, Xin Wang, Zhen Bu, Xiaobo Chen, Yuqing Wang. Prediction of energy consumption in hotel buildings via support vector machines. Sustainable Cities and Society. 57 (2020) 102128. [22] E. Kamel S. Sheikh X. Huang Data-driven predictive models for residential building energy use based on the segregation of heating and cooling days Energy 206 2020 118045 Ehsan Kamel, Shaya Sheikh, Xueqing Huang. Data-driven predictive models for residential building energy use based on the segregation of heating and cooling days. Energy. 206 (2020) 118045. [23] L.u. Yan M. Liu A simplified prediction model for energy use of air conditioner in residential buildings based on monitoring data from the cloud platform Sustainable Cities Soc. 60 2020 102194 Lu Yan, Meng Liu. A simplified prediction model for energy use of air conditioner in residential buildings based on monitoring data from the cloud platform. Sustainable Cities and Society. 60 (2020) 102194. [24] H. Deng D. Fannon M.J. Eckelman Predictive modeling for US commercial building energy use: a comparison of existing statistical and machine learning algorithms using CBECS microdata Energy Build. 163 2018 34 43 Hengfang Deng, David Fannon, Matthew J. Eckelman. Predictive modeling for US commercial building energy use: A comparison of existing statistical and machine learning algorithms using CBECS microdata. Energy and Buildings. 163 (2018) 34-43. [25] J. Song L. Zhang G. Xue Y. Ma S. Gao Q. Jiang Predicting hourly heating load in a district heating system based on a hybrid CNN-LSTM model Energy Build. 243 2021 110998 Jiancai Song, Liyi Zhang, Guixiang Xue, YunPeng Ma, Shan Gao, QingLing Jiang. Predicting hourly heating load in a district heating system based on a hybrid CNN-LSTM model. Energy and Buildings. 243 (2021) 110998. [26] Y. Zhou Y. Liu D. Wang X. Liu Y. Wang A review on global solar radiation prediction with machine learning models in a comprehensive perspective Energy Convers. Manage. 235 2021 113960 Yong Zhou, Yanfeng Liu, Dengjia Wang, Xiaojun Liu, Yingying Wang. A review on global solar radiation prediction with machine learning models in a comprehensive perspective. Energy Conversion and Management. 235 (2021) 113960. [27] M. Taki A. Rohani F. Soheili-Fard A. Abdeshahi Assessment of energy consumption and modeling of output energy for wheat production by neural network (MLP and RBF) and Gaussian process regression (GPR) models J. Cleaner Prod. 172 2018 3028 3041 Morteza Taki, Abbas Rohani, Farshad Soheili-Fard, Abbas Abdeshahi. Assessment of energy consumption and modeling of output energy for wheat production by neural network (MLP and RBF) and Gaussian process regression (GPR) models. Journal of Cleaner Production. 172 (2018) 3028-3041. [28] M. Massaoudi S.S. Refaat I. Chihi M. Trabelsi F.S. Oueslati H. Abu-Rub A novel stacked generalization ensemble-based hybrid LGBM-XGB-MLP model for Short-Term Load Forecasting Energy 214 2021 118874 Mohamed Massaoudi, Shady S. Refaat, Ines Chihi, Mohamed Trabelsi, Fakhreddine S. Oueslati, Haitham Abu-Rub. A novel stacked generalization ensemble-based hybrid LGBM-XGB-MLP model for Short-Term Load Forecasting. Energy. 214 (2021) 118874. [29] D.-K. Bui T.N. Nguyen T.D. Ngo H. Nguyen-Xuan An artificial neural network (ANN) expert system enhanced with the electromagnetism-based firefly algorithm (EFA) for predicting the energy consumption in buildings Energy 190 2020 116370 Dac-Khuong Bui, Tuan Ngoc Nguyen, Tuan Duc Ngo, H. Nguyen-Xuan. An artificial neural network (ANN) expert system enhanced with the electromagnetism-based firefly algorithm (EFA) for predicting the energy consumption in buildings. Energy. 190 (2020) 116370. [30] M. Ilbeigi M. Ghomeishi A. Dehghanbanadaki Prediction and optimization of energy consumption in an office building using artificial neural network and a genetic algorithm Sustainable Cit. Soc. 61 2020 102325 Marjan Ilbeigi, Mohammad Ghomeishi, Ali Dehghanbanadaki. Prediction and optimization of energy consumption in an office building using artificial neural network and a genetic algorithm. Sustainable Cities and Society. 61 (2020) 102325. [31] A. Zhang L. Zhang RBF neural networks for the prediction of building interference effects Comput. Struct. 82 2004 2333 2339 Aishe Zhang, Ling Zhang. RBF neural networks for the prediction of building interference effects. Computers & Structures. 82 (2004) 2333-2339. [32] Y. Han C. Fan Z. Geng Bo Ma Di Cong K. Chen Yu Bin Energy efficient building envelope using novel RBF neural network integrated affinity propagation Energy 209 2020 118414 Yongming Han, Chenyu Fan, Zhiqiang Geng, Bo Ma, Di Cong, Kai Chen, Bin Yu. Energy efficient building envelope using novel RBF neural network integrated affinity propagation. Energy. 209 (2020) 118414. [33] Q. Li Q. Meng J. Cai H. Yoshino A. Mochida Predicting hourly cooling load in the building: a comparison of support vector machine and different artificial neural networks Energy Convers. Manage. 50 2009 90 96 Qiong Li, Qinglin Meng, Jiejin Cai, Hiroshi Yoshino, Akashi Mochida. Predicting hourly cooling load in the building: A comparison of support vector machine and different artificial neural networks. Energy Conversion and Management. 50 (2009) 90-96. [34] H. Sanikhani R.C. Deo P. Samui O. Kisi Cihan Mert Rasoul Mirabbasi Siavash Gavili Zaher Mundher Yaseen Survey of different data-intelligent modeling strategies for forecasting air temperature using geographic information as model predictors Comput. Electron. Agric. 152 2018 242 260 Hadi Sanikhani, Ravinesh C. Deo, Pijush Samui, Ozgur Kisi, Cihan Mert, Rasoul Mirabbasi, Siavash Gavili, Zaher Mundher Yaseen. Survey of different data-intelligent modeling strategies for forecasting air temperature using geographic information as model predictors. Computers and Electronics in Agriculture. 152 (2018) 242-260. [35] A.E. Ben-Nakhi M.A. Mahmoud Cooling load prediction for buildings using general regression neural networks Energy Convers. Manage. 45 2004 2127 2141 Abdullatif E. Ben-Nakhi, Mohamed A. Mahmoud. Cooling load prediction for buildings using general regression neural networks. Energy Conversion and Management. 45 (2004) 2127-2141. [36] H. Ye Q. Ren X. Hu T. Lin L. Shi G. Zhang X. Li Modeling energy-related CO2 emissions from office buildings using general regression neural network Resour. Conserv. Recycl. 129 2018 168 174 Hong Ye, Qun Ren, Xinyue Hu, Tao Lin, Longyu Shi, Guoqin Zhang, Xinhu Li. Modeling energy-related CO2 emissions from office buildings using general regression neural network. Resources, Conservation and Recycling. 129 (2018) 168-174. [37] Guiqing Zhang, Chenlu Tian, Chengdong Li, Jun Jason Zhang, Wangda Zuo. Accurate forecasting of building energy consumption via a novel ensembled deep learning method considering the cyclic feature. Energy. 201 (2020) 117531. [38] C. Liu Bo Sun C. Zhang F. Li A hybrid prediction model for residential electricity consumption using holt-winters and extreme learning machine Appl. Energy 275 2020 115383 Che Liu, Bo Sun, Chenghui Zhang, Fan Li. A hybrid prediction model for residential electricity consumption using holt-winters and extreme learning machine. Applied Energy. 275 (2020) 115383. [39] S. Sekhar Roy R. Roy V.E. Balas Estimating heating load in buildings using multivariate adaptive regression splines, extreme learning machine, a hybrid model of MARS and ELM Renew. Sustain. Energy Rev. 82 2018 4256 4268 Sanjiban Sekhar Roy, Reetika Roy, Valentina E. Balas. Estimating heating load in buildings using multivariate adaptive regression splines, extreme learning machine, a hybrid model of MARS and ELM. Renewable and Sustainable Energy Reviews. 82 (2018) 4256-4268. [40] Vladimir Vapnik, Steven E Golowich, Alex J Smola. Support vector method for function approximation, regression estimation and signal processing. Advances in neural information processing systems 1997. pp. 281\u2013287. [41] Z. Tan G. De M. Li H. Lin S. Yang L. Huang Q. Tan Combined electricity-heat-cooling-gas load forecasting model for integrated energy system based on multi-task learning and least square support vector machine J. Cleaner Prod. 248 2020 119252 Zhongfu Tan, Gejirifu De, Menglu Li, Hongyu Lin, Shenbo Yang, Liling Huang, Qinkun Tan. Combined electricity-heat-cooling-gas load forecasting model for integrated energy system based on multi-task learning and least square support vector machine. Journal of Cleaner Production. 248 (2020) 119252. [42] Y. Zhou Y. Liu D. Wang G. De Y. Li X. Liu Y. Wang A novel combined multi-task learning and Gaussian process regression model for the prediction of multi-timescale and multi-component of solar radiation J. Cleaner Prod. 284 2021 124710 Yong Zhou, Yanfeng Liu, Dengjia Wang, Gejirifu De, Yong Li, Xiaojun Liu, Yingying Wang. A novel combined multi-task learning and Gaussian process regression model for the prediction of multi-timescale and multi-component of solar radiation. Journal of Cleaner Production. 284 (2021) 124710. [43] M. Gong J. Wang Y. Bai Bo Li L. Zhang Heat load prediction of residential buildings based on discrete wavelet transform and tree-based ensemble learning J. Build. Eng. 32 2020 101455 Mingju Gong, Jin Wang, Yin Bai, Bo Li, Lei Zhang. Heat load prediction of residential buildings based on discrete wavelet transform and tree-based ensemble learning. Journal of Building Engineering. 32 (2020) 101455. [44] Peng Nie, Michele Roccotelli, Maria Pia Fanti, Zhengfeng Ming, Zhiwu Li. Prediction of home energy consumption based on gradient boosting regression tree. Energy Reports. 7 (2021) 1246\u20131255. [45] Yang Wang, I H Witten. Inducing Model Trees for Continuous Classes. Proceedings of the ninth European conference on machine learning 1997. pp. 128\u2013137. [46] J.R. Quinlan Learning with continuous classes Proceedings of the 5th Australian Joint Conference on Artificial Intelligence 1992 343 348 J R Quinlan. Learning With Continuous Classes. Proceedings of the 5th Australian Joint Conference on Artificial Intelligence1992. pp. 343-348. [47] Z. Wang Y. Wang R. Zeng R.S. Srinivasan S. Ahrentzen Random Forest based hourly building energy prediction Energy Build. 171 2018 11 25 Zeyu Wang, Yueren Wang, Ruochen Zeng, Ravi S. Srinivasan, Sherry Ahrentzen. Random Forest based hourly building energy prediction. Energy and Buildings. 171 (2018) 11-25. [48] W. Zhang Y.u. Junqi A. Zhao X. Zhou Predictive model of cooling load for ice storage air-conditioning system by using GBDT Energy Rep. 7 2021 1588 1597 Wanhu Zhang, Junqi Yu, Anjun Zhao, Xinwei Zhou. Predictive model of cooling load for ice storage air-conditioning system by using GBDT. Energy Reports. 7 (2021) 1588-1597. [49] T. Chen, C. Guestrin. Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. ACM2016. pp. 985\u2013794. [50] H. Mo H. Sun J. Liu S. Wei Developing window behavior models for residential buildings using XGBoost algorithm Energy Build. 205 2019 109564 Hao Mo, Hejiang Sun, Junjie Liu, Shen Wei. Developing window behavior models for residential buildings using XGBoost algorithm. Energy and Buildings. 205 (2019) 109564. [51] S. Liu Y. Sun L. Zhang Su Peng Fault diagnosis of shipboard medium-voltage DC power system based on machine learning Int. J. Electr. Power Energy Syst. 124 2021 106399 Sheng Liu, Yue Sun, Lanyong Zhang, Peng Su. Fault diagnosis of shipboard medium-voltage DC power system based on machine learning. International Journal of Electrical Power & Energy Systems. 124 (2021) 106399. [52] S. Lee T.P. Vo H.-T. Thai J. Lee V. Patel Strength prediction of concrete-filled steel tubular columns using Categorical Gradient Boosting algorithm Eng. Struct. 238 2021 112109 Seunghye Lee, Thuc P. Vo, Huu-Tai Thai, Jaehong Lee, Vipulkumar Patel. Strength prediction of concrete-filled steel tubular columns using Categorical Gradient Boosting algorithm. Engineering Structures. 238 (2021) 112109. [53] A. Prada A. Gasparella P. Baggio On the performance of meta-models in building design optimization Appl. Energy 225 2018 814 826 A. Prada, A. Gasparella, P. Baggio. On the performance of meta-models in building design optimization. Applied Energy. 225 (2018) 814-826. [54] M. Almaraashi Investigating the impact of feature selection on the prediction of solar radiation in different locations in Saudi Arabia Appl. Soft Comput. 66 2018 250 263 Majid Almaraashi. Investigating the impact of feature selection on the prediction of solar radiation in different locations in Saudi Arabia. Applied Soft Computing. 66 (2018) 250-263. [55] N. Spolaôr, E.A. Cherman, M.C. Monard, H. D. Lee. Filter approach feature selection methods to support multi-label learning based on relieff and information gain. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 2012. pp. 72\u201381. [56] I. Kononenko. Estimating attributes: Analysis and extensions of RELIEF. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 1994. pp. 171\u2013182. [57] E. Akarslan R. Doğan A novel approach based on a feature selection procedure for residential load identification Sustainable Energy Grids Networks 27 2021 100488 Emre Akarslan, Rasim Doğan. A novel approach based on a feature selection procedure for residential load identification. Sustainable Energy, Grids and Networks. 27 (2021) 100488. [58] Y. Zhou D. Wang Y. Liu J. Liu Diffuse solar radiation models for different climate zones in China: model evaluation and general model development Energy Convers. Manage. 185 2019 518 536 Yong Zhou, Dengjia Wang, Yanfeng Liu, Jiaping Liu. Diffuse solar radiation models for different climate zones in China: Model evaluation and general model development. Energy Conversion and Management. 185 (2019) 518-536. [59] Y. Liu Y. Zhou Y. Chen D. Wang Y. Wang Y. Zhu Comparison of support vector machine and copula-based nonlinear quantile regression for estimating the daily diffuse solar radiation: a case study in China Renewable Energy 146 2020 1101 1112 Yanfeng Liu, Yong Zhou, Yaowen Chen, Dengjia Wang, Yingying Wang, Ying Zhu. Comparison of support vector machine and copula-based nonlinear quantile regression for estimating the daily diffuse solar radiation: A case study in China. Renewable Energy. 146 (2020) 1101-1112.",
    "scopus-id": "85116036530",
    "coredata": {
        "eid": "1-s2.0-S0378778821007891",
        "dc:description": "Short-term building energy consumption prediction is of great significance to the optimal operation of building energy systems and conservation. Machine-learning models are widely used due to their high prediction accuracy and efficiency in dealing with high-dimensional nonlinear problems. To compare the performance of different machine-learning models in building energy consumption prediction, this paper analyzes 15 machine-learning models, including a multi-layer perception, a radials basis function neural network, a generalized regression neural network, an extreme learning machine, a support vector machine, a least-square support vector machine, a Gaussian process regression, a regression tree, a model five tree, a random forest, a gradient boosting decision tree, an extreme gradient boosting tree, a light gradient boosting machine, a categorical gradient boosting tree and a multi-adaptive regression spline, from the aspects of model prediction accuracy, model stability (over-fitting) and calculation speed. The operation parameters determined by ReliefF algorithm were used as input parameters. The results showed that the prediction accuracy of all models is higher in the training phases, with R2 values greater than 0.90, while the prediction accuracy in testing phases was much lower. In terms of prediction accuracy and model stability, the Gaussian process regression model had the best overall performance among the 15 models, while the support vector machine had the faster calculation speed with acceptable prediction accuracy. For small datasets, the Gaussian process regression model is recommended, and the support vector machine should be preferred for large datasets. The results of this paper can provide a basis for model selection and the establishment of combined models for predicting building energy consumption.",
        "openArchiveArticle": "false",
        "prism:coverDate": "2021-12-15",
        "openaccessUserLicense": null,
        "prism:aggregationType": "Journal",
        "prism:url": "https://api.elsevier.com/content/article/pii/S0378778821007891",
        "dc:creator": [
            {
                "@_fa": "true",
                "$": "Zhou, Yong"
            },
            {
                "@_fa": "true",
                "$": "Liu, Yanfeng"
            },
            {
                "@_fa": "true",
                "$": "Wang, Dengjia"
            },
            {
                "@_fa": "true",
                "$": "Liu, Xiaojun"
            }
        ],
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/article/pii/S0378778821007891"
            },
            {
                "@_fa": "true",
                "@rel": "scidir",
                "@href": "https://www.sciencedirect.com/science/article/pii/S0378778821007891"
            }
        ],
        "dc:format": "application/json",
        "openaccessType": null,
        "pii": "S0378-7788(21)00789-1",
        "prism:volume": "253",
        "articleNumber": "111505",
        "prism:publisher": "Elsevier B.V.",
        "dc:title": "Comparison of machine-learning models for predicting short-term building heating load using operational parameters",
        "prism:copyright": "© 2021 Elsevier B.V. All rights reserved.",
        "openaccess": "0",
        "prism:issn": "03787788",
        "dcterms:subject": [
            {
                "@_fa": "true",
                "$": "Machine-learning model"
            },
            {
                "@_fa": "true",
                "$": "Feature selection"
            },
            {
                "@_fa": "true",
                "$": "Building heating load"
            },
            {
                "@_fa": "true",
                "$": "Building energy prediction"
            }
        ],
        "openaccessArticle": "false",
        "prism:publicationName": "Energy and Buildings",
        "openaccessSponsorType": null,
        "prism:pageRange": "111505",
        "pubType": "fla",
        "prism:coverDisplayDate": "15 December 2021",
        "prism:doi": "10.1016/j.enbuild.2021.111505",
        "prism:startingPage": "111505",
        "dc:identifier": "doi:10.1016/j.enbuild.2021.111505",
        "openaccessSponsorName": null
    },
    "objects": {"object": [
        {
            "@category": "standard",
            "@height": "315",
            "@width": "627",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr10.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "40243",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "179",
            "@width": "373",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr2.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "17370",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "475",
            "@width": "667",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr3.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "72203",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "370",
            "@width": "373",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr4.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "28923",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "354",
            "@width": "667",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr5.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "76616",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "639",
            "@width": "667",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr6.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "133206",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "899",
            "@width": "711",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr7.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "191047",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "724",
            "@width": "711",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr8.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "148382",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "239",
            "@width": "756",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr9.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "54053",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "standard",
            "@height": "544",
            "@width": "667",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr1.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-DOWNSAMPLED",
            "@size": "76720",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@height": "110",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr10.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "6135",
            "@ref": "gr10",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "105",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr2.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "5373",
            "@ref": "gr2",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "156",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr3.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "9779",
            "@ref": "gr3",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "165",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr4.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "6470",
            "@ref": "gr4",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "116",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr5.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "11988",
            "@ref": "gr5",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "171",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr6.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "11160",
            "@ref": "gr6",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "163",
            "@width": "129",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr7.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "9053",
            "@ref": "gr7",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "161",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr8.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "11978",
            "@ref": "gr8",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "69",
            "@width": "219",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr9.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "6755",
            "@ref": "gr9",
            "@mimetype": "image/gif"
        },
        {
            "@category": "thumbnail",
            "@height": "164",
            "@width": "201",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr1.sml?httpAccept=%2A%2F%2A",
            "@multimediatype": "GIF image file",
            "@type": "IMAGE-THUMBNAIL",
            "@size": "10040",
            "@ref": "gr1",
            "@mimetype": "image/gif"
        },
        {
            "@category": "high",
            "@height": "1395",
            "@width": "2776",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr10_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "381876",
            "@ref": "gr10",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "794",
            "@width": "1654",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr2_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "127535",
            "@ref": "gr2",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2105",
            "@width": "2953",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr3_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "515055",
            "@ref": "gr3",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1642",
            "@width": "1654",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr4_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "187245",
            "@ref": "gr4",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1569",
            "@width": "2953",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr5_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "621234",
            "@ref": "gr5",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2829",
            "@width": "2953",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr6_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "1160353",
            "@ref": "gr6",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "3984",
            "@width": "3150",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr7_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "1943451",
            "@ref": "gr7",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "3209",
            "@width": "3150",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr8_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "1290208",
            "@ref": "gr8",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "1060",
            "@width": "3346",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr9_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "493154",
            "@ref": "gr9",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "high",
            "@height": "2409",
            "@width": "2953",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-gr1_lrg.jpg?httpAccept=%2A%2F%2A",
            "@multimediatype": "JPEG image file",
            "@type": "IMAGE-HIGH-RES",
            "@size": "474761",
            "@ref": "gr1",
            "@mimetype": "image/jpeg"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si1.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "13082",
            "@ref": "si1",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si10.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "18460",
            "@ref": "si10",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si11.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7053",
            "@ref": "si11",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si12.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1330",
            "@ref": "si12",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si13.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "13704",
            "@ref": "si13",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si14.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1377",
            "@ref": "si14",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si15.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "10616",
            "@ref": "si15",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si16.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "14659",
            "@ref": "si16",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si17.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "23765",
            "@ref": "si17",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si18.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7924",
            "@ref": "si18",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si19.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2547",
            "@ref": "si19",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si2.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "18600",
            "@ref": "si2",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si20.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "8278",
            "@ref": "si20",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si21.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "13647",
            "@ref": "si21",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si22.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "12369",
            "@ref": "si22",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si23.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "23037",
            "@ref": "si23",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si24.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "8666",
            "@ref": "si24",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si25.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6408",
            "@ref": "si25",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si26.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3419",
            "@ref": "si26",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si27.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "18222",
            "@ref": "si27",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si28.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "19015",
            "@ref": "si28",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si29.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7358",
            "@ref": "si29",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si3.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "1960",
            "@ref": "si3",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si30.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "20101",
            "@ref": "si30",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si31.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "7086",
            "@ref": "si31",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si32.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "22610",
            "@ref": "si32",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si33.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "14707",
            "@ref": "si33",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si34.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "12498",
            "@ref": "si34",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si35.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "20121",
            "@ref": "si35",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si36.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "19622",
            "@ref": "si36",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si37.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "21712",
            "@ref": "si37",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si38.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "15269",
            "@ref": "si38",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si39.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6371",
            "@ref": "si39",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si4.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "17606",
            "@ref": "si4",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si40.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4494",
            "@ref": "si40",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si41.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "4189",
            "@ref": "si41",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si42.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "15803",
            "@ref": "si42",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si43.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "2802",
            "@ref": "si43",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si44.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "3212",
            "@ref": "si44",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si45.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "6314",
            "@ref": "si45",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si46.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "40034",
            "@ref": "si46",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si47.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "18792",
            "@ref": "si47",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si48.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "22920",
            "@ref": "si48",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si49.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "24073",
            "@ref": "si49",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si5.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "18603",
            "@ref": "si5",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si50.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "18444",
            "@ref": "si50",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si51.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "19692",
            "@ref": "si51",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si6.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11763",
            "@ref": "si6",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si7.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11810",
            "@ref": "si7",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si8.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "11038",
            "@ref": "si8",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "thumbnail",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-si9.svg?httpAccept=%2A%2F%2A",
            "@multimediatype": "Scalable Vector Graphics file",
            "@type": "ALTIMG",
            "@size": "5284",
            "@ref": "si9",
            "@mimetype": "image/svg+xml"
        },
        {
            "@category": "standard",
            "@_fa": "true",
            "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0378778821007891-am.pdf?httpAccept=%2A%2F%2A",
            "@multimediatype": "Acrobat PDF file",
            "@type": "AAM-PDF",
            "@size": "1046850",
            "@ref": "am",
            "@mimetype": "application/pdf"
        }
    ]},
    "link": {
        "@rel": "abstract",
        "@href": "https://api.elsevier.com/content/abstract/scopus_id/85116036530"
    }
}}