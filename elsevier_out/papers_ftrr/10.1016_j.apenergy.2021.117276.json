{
  "full-text-retrieval-response": {
    "originalText": "Abstract\nA significant amount of energy can be saved through improving occupant behavior. However, implementing energy-saving behavioral changes requires careful consideration based on real-life data to avoid sacrificing comfort. Towards addressing this need, this paper proposes a real data-driven method to assess the potential of occupant-behavior improvements in simultaneously reducing energy consumption and enhancing comfort. The proposed method consists of two main components: (1) machine learning-based occupant-behavior-sensitive models for real data-driven prediction of cooling and lighting energy consumption and thermal and visual occupant comfort; and (2) a genetic algorithm-based optimization model, which uses the machine-learning models to compute the energy consumption and occupant comfort and accordingly optimizes occupant behavior for reduced energy consumption and improved comfort. The proposed method was tested on real data collected from an office building. The experimental results showed potential behavioral energy savings in the range of 11–22%, with a significant improvement in occupant comfort.\n\nMethods\n3 Methodology A data-driven method to determine the optimal occupant behavior that can simultaneously reduce energy consumption and improve comfort is proposed. The proposed method consists of two components: (1) machine learning-based occupant-behavior-sensitive models for real data-driven prediction of cooling and lighting energy consumption and thermal and visual occupant comfort; and (2) a genetic algorithm-based optimization model, which uses the machine-learning models to compute the projected energy consumption and occupant comfort (for different energy-use behaviors) and accordingly optimizes occupant behavior for reduced energy consumption and improved comfort. To test and evaluate the proposed method, an office building in Philadelphia, PA was instrumented for real data collection. Fig. 1 shows an overview of the research methodology. First, data about energy consumption, outdoor weather conditions, occupant behavior, and occupant comfort were collected. Second, the collected data were preprocessed for downstream machine learning. Third, using the preprocessed data, the machine learning-based occupant-behavior-sensitive prediction models were developed. Finally, using the most accurate prediction models, an occupant-behavior optimization was conducted. To verify that the behavior features are discriminating, and hence that the prediction models can be used to predict the impact of the behavior, the performance of the models were compared to others without occupant-behavior features. To consider the delayed effects of outdoor weather, prediction models with the past one- and two-hour outdoor weather condition features were tested. A set of machine-learning algorithms for classification and regression were also tested to determine the most accurate in energy consumption and comfort prediction. For optimization, a set of occupant-behavior variables were optimized for minimum energy consumption and maximum thermal and visual comfort for each hour. These variables included thermostat setpoints, turning on/off portable heaters, opening/closing doors, opening/closing shading devices, and turning on/off lights. 3.1 Building instrumentation and data collection Data were collected from the Philadelphia Business and Technology Center (PBTC) building for three months. The PBTC is a 6-story masonry office building with an estimated total floor area of 25,269 m 2 (272,000 ft 2 ). The windows of the building are not operable. The west wing of the 4 th floor was already instrumented for empirical data collection as part of an earlier research project by the Consortium for Building Energy Innovation (CBEI) [34] . For this study, the sensors were tested and were fixed/replaced if/as needed. The instrumented area is 929 m 2 (10,000 ft 2 ), which consists of 12 offices and two thermal zones. The instrumented area is occupied on weekdays from 8AM to 5PM, mostly. The data collection methods are summarized in Table 1 . The building uses electricity for cooling and artificial lighting. Cooling and lighting energy consumption was metered in 15-min intervals using power meters installed on the air handling units (AHUs) and panelboards, and monitored using the PI CoreSight web-based application. Outdoor weather condition data were gathered from a weather station at the Philadelphia International Airport [35] and the National Renewable Energy Laboratory’s (NREL) National Solar Radiation Database (NSRDB) [36] in hourly intervals. The outdoor weather data included temperature, dewpoint temperature, relative humidity, wind speed, direct normal irradiance (DNI), diffuse horizontal irradiance (DHI), and global horizontal irradiance (GHI) data. Occupant-behavior and occupant-comfort data were collected from 12 occupants and captured through a preference monitoring application (PMA) [37] . The PMA was developed using an online survey tool to capture the energy-use behavior actions taken by the occupants and solicit feedback on their thermal and visual comfort. The behavior actions included adjusting thermostat, turning on/off a portable heater, opening/closing a door, opening/closing a shading device, and turning on/off a light. These actions were selected based on two criteria. First, the occupants must be able to take the action. For example, the occupants in this study were not allowed, by the building manager, to operate the windows. Therefore, the behavior actions did not include opening/closing a window. Second, the action must have a possible impact on cooling and/or lighting energy consumption. For example, the use of office appliances such as computers and printers has an impact on plug load energy consumption but not on cooling or lighting energy consumption. Therefore, such actions were also excluded. For behavior, feedback was required whenever they have taken an action. For thermal and visual comfort, a 6-point Likert satisfaction scale (1 = very unsatisfied, 2 = unsatisfied, 3 = moderately unsatisfied, 4 = moderately satisfied, 5 = satisfied, 6 = very satisfied) was used and feedback was required at least daily, or as frequent as occupants wish to report (e.g., whenever they feel not satisfied). The use of the PMA was completely voluntary. To minimize the risk of respondent bias, the debriefing [38] and the respondent validation (a.k.a informant feedback) [39] techniques were used. The debriefing technique aims to inform the participants about the intentions of the study. The respondent validation technique aims to verify the participants’ feedback during the data collection phase. As such, prior to, during, and after data collection, a number of meetings with the occupants were held. In these meetings, the importance of their feedback to this research was communicated and their inputs were verified to improve the accuracy and credibility of the study. Also, a reward program was launched to encourage building occupants to give frequent feedback. Each month, a $50 gift card was given to the most frequent feedback-provider of the month. 3.2 Data preprocessing Data preprocessing included four primary steps: data cleaning and outlier filtering, data aggregation, data integration, and data normalization. First, the data instances that have missing and/or outlier values were removed from the dataset. Cook’s distance [40] was used to compute and identify outliers. In statistics, Cook’s distance shows the influence of each data instance on the predicted values. A data instance with Cook’s distance larger than three times the mean Cook’s distance was considered as an outlier. Accordingly, the instances with outliers represent 0.9% of the entire dataset. Second, 15-min data intervals of cooling and lighting energy consumption were aggregated into hourly consumption values using summation. Third, occupant-behavior data from multiple occupants were aggregated using a majority voting strategy. The behavior of an occupant was assumed unchanged until another behavior is reported or until the end of the day. Data from multiple sources including energy consumption data, outdoor weather condition data, and occupant-behavior and occupant-comfort data were integrated using their date and time. Then, unoccupied hours (e.g., weekends and evenings) were removed from the dataset because they do not include any occupant-behavior and occupant-comfort data. Fourth, each variable in the dataset was normalized between 0 and 1 to avoid overflowing of an individual variable. 3.3 Machine-learning model development A set of machine learning-based occupant-behavior-sensitive prediction models for real data-driven prediction of cooling and lighting energy consumption and thermal and visual occupant comfort were developed. The prediction of cooling and lighting energy consumption is a regression problem because cooling and lighting energy consumption data are continuous. The prediction of thermal and visual comfort, on the other hand, is a classification problem, because thermal and visual comfort data are categorical. For cooling energy consumption and thermal comfort prediction, the following features were used: hourly average temperature, hourly average dewpoint temperature, hourly average relative humidity, hourly average wind speed, DNI, DHI, GHI, thermostat setpoint, portable heater status, door status, and window shade status. For lighting energy consumption and visual comfort prediction, the following features were used: DNI, DHI, GHI, window shade status, and light status. For the comfort prediction models, two types of models were developed: group and individual. The group comfort models were used to find optimal group solutions. The individual comfort models are personalized and were used to predict the impact of the optimal group solutions on individual comfort. To verify that the behavior features are discriminating, and hence that the prediction models can be used to predict the impact of the behavior, the performance of the models were compared to others without occupant-behavior features. This included all aforementioned features except thermostat setpoints, portable heater status, door status, window shade status, and light status. To consider the delayed effects of outdoor weather, prediction models with the past one- and two-hour outdoor weather condition features and with no past-hour features were tested and compared. A feature selection was also conducted, using the least absolute shrinkage and selection operator (LASSO), to verify that all the aforementioned behavior and outdoor weather condition features are discriminating. A set of machine-learning algorithms for regression and classification were also tested to determine the most accurate in energy consumption and comfort prediction. For energy consumption prediction, the following regression algorithms were tested: support vector regression (SVR), ANN, classification and regression tree (CART), and multiple linear regression (MLR). For comfort prediction, the following classification algorithms were tested: support vector machines (SVM), ANN, decision tree (DT), and k-nearest neighbors (KNN). These algorithms were selected because they are among the most popular and accurate machine-learning algorithms. For all comparisons, the Welch’s t -test was performed to assess the statistical significance of the differences in the prediction results by the different models. The difference was considered significant when the resulting p -value was less than 0.05 (i.e., p < 0.05). For all prediction models, the parameters of the machine-learning algorithms were individually tuned using grid search for each model to maximize the prediction performance. The models were trained using the MATLAB’s neural network training tool, and the statistical and machine-learning toolbox. In training the models, outdoor weather condition and thermostat setpoint data were represented as continuous variables, whereas occupant-behavior data (except thermostat setpoint) were represented as binary variables. 3.4 Prediction performance evaluation A 10-cross fold validation was utilized to assess the performance, because it minimizes the bias due to the randomness in choosing the testing data [41] . After creating the folds for comfort prediction models, the data instances with minority labels (i.e., very unsatisfied and unsatisfied) in the nine (9) folds that are going to be used for training were oversampled to deal with the data imbalance problem. The following performance metrics were utilized for consumption prediction, which were calculated using Eqs. (1)–(3) : root mean square error (RMSE), coefficient of variation (CV), and coefficient of determination (R 2 ). RMSE is the standard deviation of the residuals between the predicted and the actual energy consumption values. CV is a measure to assess the variability between the predicted and the actual energy consumption values. R 2 is a measure to assess how much of the variance in the actual energy consumption values are explained by the model. The lower the RMSE and CV and the higher the R 2 , the more similar dispersions are between the predicted and the actual consumptions. The RMSE was utilized as the primary performance metric and CV and R 2 were only utilized as tie breakers when the RMSE did not show a significant difference between the models. (1) R M S E k W h = ∑ i = 1 n ( y predict , i - y data , i ) 2 n (2) C V % = ∑ i = 1 n ( y predict , i - y data , i ) 2 n y ¯ data × 100 (3) R 2 ( % ) = ∑ i = 1 n ( y predict , i - y ¯ data ) 2 ∑ i = 1 n ( y data , i - y ¯ data ) 2 × 100 where y predict , i is the predicted energy consumption at hour i , y data , i is the actual energy consumption at hour i , n is the number of hours in the dataset, and y ¯ data is the average energy consumption. The following performance metrics were utilized for comfort prediction, which were calculated using Eq. (4) and Eq. (5) : mean absolute error (MAE) and mean squared error (MSE). (4) M A E = ∑ i = 1 n y predict , i - y data , i n (5) M S E = ∑ i = 1 n ( y predict , i - y data , i ) 2 n where y predict , i is the predicted thermal (or visual) comfort level at hour i , y data , i is the actual thermal (or visual) comfort level at hour i , n is the number of hours in the dataset, and y ¯ data is the average thermal (or visual) comfort level. 3.5 Optimization A genetic algorithm-based optimization model for optimizing occupant behavior was developed. The main purpose of the optimization is to minimize energy consumption while maximizing thermal and visual comfort during occupied hours. The decision variables, objective functions, and optimization computations of the proposed optimization were formulated as follows. The decision variables included thermostat setpoint, portable heater status, door status, window shade status, and light status for each hour. The thermostat setpoint was defined as a continuous variable bounded by 68 F and 80 F. The portable heater status, door status, window shade status, and light status were defined as binary variables. Three objective functions were formulated: (1) minimizing hourly energy consumption (sum of cooling and lighting energy consumptions), (2) maximizing hourly group thermal comfort, and (3) maximizing hourly group visual comfort. The hourly cooling and lighting energy consumptions, and thermal and visual comfort were calculated using the prediction models (see Section 3.4). The NSGA-II [42] was used for conducting the optimization due to the algorithm’s capabilities of fast non-dominated sorting approach, fast crowded distance estimation procedure, and simple crowded comparison operator [43] . Similar to any genetic algorithm, the NSGA-II is based on the evolution of a population of individuals (or chromosomes), each representing a solution for the optimization problem [44] . The optimization was conducted using the MATLAB’s optimization toolbox. A population size of 50 individuals, crossover probability of 90%, mutation probability of 10%, tolerance of 0.0001, and termination criteria of 700 generations were selected as the parameters of the algorithm. In conducting the optimization, four types of optimal solutions were considered: energy-priority, thermal-comfort-priority, and visual-comfort-priority, and balanced solutions. An energy-priority solution places priority on minimizing energy consumption, while a comfort-priority solution places priority on maximizing comfort. These three types of solutions are useful for demonstrating the extreme savings or comfort improvements that are possible, but do not improve all three objectives equally. In a balanced solution, an equal importance is given to all three objectives using the weighted sum method, which turns the three objectives into a single objective by adding each objective pre-multiplied by an equal weight.\n\nMethods\n3.1 Building instrumentation and data collection Data were collected from the Philadelphia Business and Technology Center (PBTC) building for three months. The PBTC is a 6-story masonry office building with an estimated total floor area of 25,269 m 2 (272,000 ft 2 ). The windows of the building are not operable. The west wing of the 4 th floor was already instrumented for empirical data collection as part of an earlier research project by the Consortium for Building Energy Innovation (CBEI) [34] . For this study, the sensors were tested and were fixed/replaced if/as needed. The instrumented area is 929 m 2 (10,000 ft 2 ), which consists of 12 offices and two thermal zones. The instrumented area is occupied on weekdays from 8AM to 5PM, mostly. The data collection methods are summarized in Table 1 . The building uses electricity for cooling and artificial lighting. Cooling and lighting energy consumption was metered in 15-min intervals using power meters installed on the air handling units (AHUs) and panelboards, and monitored using the PI CoreSight web-based application. Outdoor weather condition data were gathered from a weather station at the Philadelphia International Airport [35] and the National Renewable Energy Laboratory’s (NREL) National Solar Radiation Database (NSRDB) [36] in hourly intervals. The outdoor weather data included temperature, dewpoint temperature, relative humidity, wind speed, direct normal irradiance (DNI), diffuse horizontal irradiance (DHI), and global horizontal irradiance (GHI) data. Occupant-behavior and occupant-comfort data were collected from 12 occupants and captured through a preference monitoring application (PMA) [37] . The PMA was developed using an online survey tool to capture the energy-use behavior actions taken by the occupants and solicit feedback on their thermal and visual comfort. The behavior actions included adjusting thermostat, turning on/off a portable heater, opening/closing a door, opening/closing a shading device, and turning on/off a light. These actions were selected based on two criteria. First, the occupants must be able to take the action. For example, the occupants in this study were not allowed, by the building manager, to operate the windows. Therefore, the behavior actions did not include opening/closing a window. Second, the action must have a possible impact on cooling and/or lighting energy consumption. For example, the use of office appliances such as computers and printers has an impact on plug load energy consumption but not on cooling or lighting energy consumption. Therefore, such actions were also excluded. For behavior, feedback was required whenever they have taken an action. For thermal and visual comfort, a 6-point Likert satisfaction scale (1 = very unsatisfied, 2 = unsatisfied, 3 = moderately unsatisfied, 4 = moderately satisfied, 5 = satisfied, 6 = very satisfied) was used and feedback was required at least daily, or as frequent as occupants wish to report (e.g., whenever they feel not satisfied). The use of the PMA was completely voluntary. To minimize the risk of respondent bias, the debriefing [38] and the respondent validation (a.k.a informant feedback) [39] techniques were used. The debriefing technique aims to inform the participants about the intentions of the study. The respondent validation technique aims to verify the participants’ feedback during the data collection phase. As such, prior to, during, and after data collection, a number of meetings with the occupants were held. In these meetings, the importance of their feedback to this research was communicated and their inputs were verified to improve the accuracy and credibility of the study. Also, a reward program was launched to encourage building occupants to give frequent feedback. Each month, a $50 gift card was given to the most frequent feedback-provider of the month.\n\nResults\n3.4 Prediction performance evaluation A 10-cross fold validation was utilized to assess the performance, because it minimizes the bias due to the randomness in choosing the testing data [41] . After creating the folds for comfort prediction models, the data instances with minority labels (i.e., very unsatisfied and unsatisfied) in the nine (9) folds that are going to be used for training were oversampled to deal with the data imbalance problem. The following performance metrics were utilized for consumption prediction, which were calculated using Eqs. (1)–(3) : root mean square error (RMSE), coefficient of variation (CV), and coefficient of determination (R 2 ). RMSE is the standard deviation of the residuals between the predicted and the actual energy consumption values. CV is a measure to assess the variability between the predicted and the actual energy consumption values. R 2 is a measure to assess how much of the variance in the actual energy consumption values are explained by the model. The lower the RMSE and CV and the higher the R 2 , the more similar dispersions are between the predicted and the actual consumptions. The RMSE was utilized as the primary performance metric and CV and R 2 were only utilized as tie breakers when the RMSE did not show a significant difference between the models. (1) R M S E k W h = ∑ i = 1 n ( y predict , i - y data , i ) 2 n (2) C V % = ∑ i = 1 n ( y predict , i - y data , i ) 2 n y ¯ data × 100 (3) R 2 ( % ) = ∑ i = 1 n ( y predict , i - y ¯ data ) 2 ∑ i = 1 n ( y data , i - y ¯ data ) 2 × 100 where y predict , i is the predicted energy consumption at hour i , y data , i is the actual energy consumption at hour i , n is the number of hours in the dataset, and y ¯ data is the average energy consumption. The following performance metrics were utilized for comfort prediction, which were calculated using Eq. (4) and Eq. (5) : mean absolute error (MAE) and mean squared error (MSE). (4) M A E = ∑ i = 1 n y predict , i - y data , i n (5) M S E = ∑ i = 1 n ( y predict , i - y data , i ) 2 n where y predict , i is the predicted thermal (or visual) comfort level at hour i , y data , i is the actual thermal (or visual) comfort level at hour i , n is the number of hours in the dataset, and y ¯ data is the average thermal (or visual) comfort level.\n\nResults and Discussion\n4 Results and discussion 4.1 Cooling and lighting energy consumption prediction 4.1.1 Prediction performance Table 2 summarizes the prediction performance results of the cooling and lighting energy consumption prediction models. For both cooling and lighting energy consumption prediction, SVR models (Models #5 and #29) that predict energy consumption using occupant-behavior features and past two-hour outdoor weather condition features achieved the best performance: 0.98 kWh and 0.26 kWh RMSE, respectively. Fig. 2 shows the regression between the actual and predicted energy consumption values, for Model #5 (cooling) and Model #29 (lighting). The predicted energy consumption values show a good agreement with the actual levels. Models #5 and #29 were, therefore, chosen to be used for the optimization. 4.1.2 Occupant-behavior feature analysis The SVR, ANN, and CART models with occupant-behavior features (i.e., all behavior features mentioned in Section 3.3) achieved more accurate prediction performance than the models without behavior features. For example, for cooling energy consumption prediction, Model #5 achieved 0.98 kWh RMSE, which is the most accurate; while Model #6, which utilized the same features as Model #5 except for behavior features, achieved 1.30 kWh RMSE. For lighting energy consumption prediction, Model #29 achieved 0.26 kWh RMSE, which is the most accurate; while Model #30, which utilized the same features as Model #29 except for behavior features, achieved 0.33 kWh RMSE. The RMSE improvement due to the inclusion of behavior features ranged from 0.1% to 24.6%. Fig. 3 shows the regression between the actual energy consumption values and the predictions by these models, which similarly shows that Models #5 and #29 provided more accurate predictions than Models #6 and #30. The t -test p -values for the comparisons between the predicted energy consumption values by the models with and without occupant-behavior features were less than 0.05, which indicates that these differences in the predictions are significant. Such performance improvement was not seen for the MLR models, which is probably because linear approaches, such as MLR, cannot capture the nonlinear relationships and higher-order interactions between the features and the energy consumption. Overall, these results indicate that the behavior features are discriminating, and hence that the prediction models can be used to predict the impact of the behavior. 4.1.3 Past-timestep feature analysis The use of additional past-timestep features led to some marginal performance improvement. For example, for cooling energy consumption prediction, Model #5, which utilized the past two-hour weather data (i.e., all weather features mentioned in Section 3.3) and occupant-behavior data as features, achieved 0.98 kWh RMSE compared to 1.02kWh RMSE for Model #3 (which utilized the past one-hour data) and 1.09 kWh RMSE for Model #1 (which utilized no past-hour data). Similarly, for lighting energy consumption prediction, Model #29, which utilized the past two-hour data, achieved 0.26 kWh RMSE compared to 0.31 kWh RMSE for Model #27 (which utilized the past one-hour data) and 0.32 kWh RMSE for Model #25 (which utilized no past-hour data). The t -test p -values for the comparisons between the energy consumption values predicted by the models with different past-timestep features were less than 0.05, which shows that although the performance improvement is marginal, the differences in the values are significant. The impact of including more than two past-hour data was, however, not tested, because the performance differences between including two, one, or no past-hour outdoor weather condition features were marginal. 4.1.4 Machine-learning algorithms As per Table 2 , the best prediction performance was achieved by SVR models (Models #5 and #29), with no clear outperformer across the ANN and CART models, and with the MLR models achieving the worst performance. For example, for cooling energy consumption prediction, Model #5, which is an SVR model utilizing the past two-hour weather data and occupant-behavior data, as features, achieved 0.98 RMSE. However, Models #11 and #17, which are ANN and CART models utilizing the same set of features as Model #5, achieved 1.28 RMSE and 1.27 RMSE, respectively. On the other hand, Model #23, an MLR model with the same set of features as others, achieved 2.36 RMSE. These results could be attributed to the fact that SVR is good at solving nonlinear problems even with a relatively small amount of training data [45] , whereas MLR is limited in modelling complex and nonlinear relationships [3] . However, these results do not guarantee that SVR models will always be more accurate than the other algorithms. Given that there is no one-size-fits-all machine-learning algorithm, testing different algorithms for different datasets and for different contexts is essential. 4.2 Thermal and visual comfort prediction 4.2.1 Group comfort prediction Table 3 summarizes the prediction performance results of the thermal and visual comfort prediction models. For thermal comfort prediction, Model #23 – a KNN model that predicts thermal comfort using occupant-behavior features and past two-hour outdoor weather conditions – achieved the best performance, 0.20 MAE. For visual comfort prediction, Model #29 – an SVM model that predicts visual comfort using occupant-behavior features and past two-hour outdoor weather conditions – achieved the best performance, 0.40 MAE. Fig. 4 shows the confusion matrices of thermal and visual comfort prediction by Models #23 and #29. The predicted levels show a good agreement with the actual comfort levels. Models #23 and #29 were, therefore, chosen to be used for the optimization. All comfort prediction models with occupant-behavior features always produced more accurate results than those without behavior features. For example, Model #23 achieved 0.20 MAE, which is the most accurate; while Model #24, which utilized the same features as Model #23 except for behavior features, achieved 0.41 MAE. The MAE improvement due to the inclusion of behavior features ranged from 38.6% to 45.0%. The t -test p -values for the comparisons between the predicted comfort levels by the models with and without occupant-behavior features were less than 0.05, which indicates that these performance differences are significant. The results indicate that the behavior features are discriminating, and hence that the prediction models can be used to predict the impact of the behavior. Same as energy consumption prediction, the use of additional past-timestep features led to some marginal improvement for comfort prediction. For example, for thermal comfort prediction, Model #23, which utilized the past two-hour weather data and occupant-behavior data as features, achieved 0.20 MAE compared to 0.25 MAE for Model #21 (which utilized the past one-hour data), and 0.26 MAE for Model #19 (which utilized no past-hour data). Similarly, for visual comfort prediction, Model #29, which utilized the past two-hour data, achieved 0.40 MAE compared to 0.42 MAE for Model #27 (which utilized the past one-hour data) and 0.41 MAE for Model #25 (which utilized no past-hour data). The t -test p -values for the comparisons were less than 0.05, which indicates that the differences in the comfort levels predicted by these models are significant. For the machine-learning algorithms, as per Table 3 , although, the best prediction performance was achieved by Model #23 (a KNN model) for thermal comfort and Model #29 (an SVM model) for visual comfort, there was no clear outperformer across the SVM, ANN, DT, and KNN models. 4.2.2 Individual comfort prediction A total of 24 individual models were developed, a thermal comfort prediction model and a visual comfort prediction model for each occupant. The same features and algorithms of the group comfort models were used for individual comfort prediction. For the remainder of this paper, the results of three example occupants are shown for illustrative purposes. For example, for thermal comfort prediction, the KNN models with occupant-behavior features and past two-hour outdoor weather conditions achieved 82.2%, 82.6%, and 79.3% accuracies for Occupants #1, #2, and #3, respectively. For visual comfort prediction, the SVM models with occupant-behavior features and past two-hour outdoor weather conditions achieved 81.3%, 77.4%, and 79.3% accuracies for Occupants #1, #2, and #3, respectively. 4.3 Occupant-behavior optimization 4.3.1 Group comfort results The following prediction models were used for the multi-objective occupant-behavior optimization: Model #5 (see Table 2) for cooling energy consumption prediction, Model #29 (see Table 2) for lighting energy consumption prediction, Model #23 (see Table 3) for thermal comfort prediction, and Model #29 (see Table 3) for visual comfort prediction. The optimal occupant-behavior settings were determined, for each hour throughout the three months during which the data were collected. For example, Fig. 5 shows seven optimal solutions at hour 1301, which included energy consumption levels varying from 9.76 kWh to 16.61 kWh, thermal comfort levels varying from very unsatisfied to very satisfied, and visual comfort levels ranging from moderately satisfied to satisfied. The 9.76 kWh solution is the energy-priority-solution, which provides the minimum energy consumption. The 16.61 kWh solution is the balanced solution, which offers the highest weighed sum of the objectives, resulting in satisfied thermal and comfort levels. Fig. 6 shows the cumulative energy consumption of the three extreme and the balanced solutions as well as the actual energy consumption. The energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions consumed 8838 kWh, 10,077 kWh, 9696 kWh, and 9715 kWh, respectively, in comparison to 11,299 kWh actual consumption. Overall, the energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions achieved 21.8%, 10.8%, 14.2%, and 14.0% energy savings, respectively. All solutions consumed less energy relative to the actual energy consumption levels. Fig. 7 shows the thermal and visual comfort distribution of the solutions as well as the actual comfort distributions. Overall, before optimization, 17.7% of the time the actual thermal comfort level was moderately unsatisfied or lower. After the optimization, only 3.4%, 0.0%, 1.1%, and 0.1% of the time the thermal comfort level was moderately unsatisfied or lower for the energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions, respectively. Before optimization, the actual 3-month average thermal comfort level was 3.9 (i.e., moderately unsatisfied to moderately satisfied). After optimization, the average comfort level increased to 5.1 (i.e., satisfied to very satisfied) for the thermal-comfort-priority solution, 4.9 (i.e., moderately satisfied to satisfied) for the visual-comfort-priority and balanced solutions, and 4.4 (i.e., moderately satisfied to satisfied) for the energy-priority solution. For visual comfort, the time when the comfort was moderately unsatisfied or lower was reduced from 60.7% to 17.5%, 18.9%, 11.3%, and 15.3% for the energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions, respectively. The 3-month average visual comfort level was increased from 3.4 (i.e., moderately unsatisfied to moderately satisfied) to 4.4 (i.e., moderately satisfied to satisfied) for the visual-comfort-priority solution, 4.3 (i.e., moderately satisfied to satisfied) for the balanced solution, and 4.2 (i.e., moderately satisfied to satisfied) for the thermal-comfort-priority and energy-priority solutions. The optimal occupant-behavior settings differed for the four optimal solutions. For example, for the balanced solution, the average thermostat setpoint was 69.8F, the portable heaters were on 16.2% of the time, the doors were open 77.3% of the time, the shading devices were open 6.1% of the time, and the lights were on 74.2% of the time. In general, the average thermostat setpoint (70.0F) for the energy-priority solution was higher than the setpoints for other solutions (68.9–69.8F). As expected, higher thermostat setpoints resulted in less cooling energy consumption. Turning on portable heaters was optimal only less than 20% of the time for all solutions. The thermal-comfort-priority solution had the least use of personal heaters due to avoiding over-cooling [46] . Opening doors was optimal 82.4% of the time for the energy-priority solution; while it was only optimal in the range of 70.8–77.3% of the time for other solutions. Rupp and Ghisi [47] showed that less air-conditioning use hours is needed when the internal doors are open. For the visual-comfort-priority solution, the lights were on 77.9% of the time and the shading devices were only open 4.2% of the time. However, for all other solutions, compared to the visual-comfort-priority solution, the lights were on for shorter durations and the shading devices were open for longer durations. For example, for the energy-priority solution, the shading devices were open double the time of that for the thermal-comfort and visual-comfort priority solutions. This shows that opening shading devices can help save energy, although it cannot always fully substitute turning on lights because natural light may not provide sufficient visual comfort. On one hand, opening shading devices lets more natural light in and reduces lighting energy consumption. On the other hand, when there is less artificial lighting, the lighting devices produce less heating and therefore the demand for cooling is also reduced. Lighting is, thus, not only a significant piece of building energy consumption by itself, but it also impacts cooling energy demand. One-third of the cooling energy consumption can be saved if a good balance between natural light and solar heat can be achieved [19,48] . 4.3.2 Individual comfort results For presenting and discussing the individual comfort results, in this paper, three of the 12 occupants were selected for the sake of conciseness. Table 4 summarizes the actual (reported) comfort levels of these occupants. These occupants reported different thermal and visual comfort levels when they were exposed to similar indoor environmental conditions, which indicates that these three occupants have different thermal and visual preferences. Overall, Occupant #2 was the most comfortable, while Occupant #3 was the least comfortable. For example, for thermal comfort, Occupant #2 was satisfied 60.9% of the time, moderately satisfied 19.6% of the time, and moderately unsatisfied or lower 19.5% of the time. Occupant #1 was satisfied 9.1% of the time, moderately satisfied 64.9% of the time, and moderately unsatisfied or lower 26.4% of the time. And, Occupant #3 was satisfied 14.0% of the time, moderately satisfied 41.3% of the time, and moderately unsatisfied or lower 44.6% of the time. For all optimal solutions, the optimal thermal and visual comfort levels of all 12 occupants were higher than their actual comfort levels. Fig. 8 shows the predicted thermal and visual comfort levels of the three selected occupants for the optimal solutions. For example, before the optimization, the actual 3-month average thermal comfort levels of Occupants #1, #2, and #3 were 3.6 (i.e., moderately unsatisfied to moderately satisfied), 4.2 (i.e., moderately satisfied to satisfied), and 3.5 (i.e., moderately unsatisfied to moderately satisfied), respectively. After the optimization, the average comfort levels of these three occupants increased to 5.0 (i.e., satisfied), 5.3 (i.e., satisfied to very satisfied), and 5.0 (i.e., satisfied), respectively, for the thermal-comfort-priority solution. For the energy-priority, visual-comfort-priority, and balanced solutions, the average comfort levels of the three occupants increased to the ranges of 4.3–4.7 (i.e., moderately satisfied to satisfied), 4.6–5.0 (i.e., moderately satisfied to satisfied), and 4.1–4.6 (i.e., moderately satisfied to satisfied), respectively. Similarly, before optimization, the actual 3-month average visual comfort levels of the three occupants were 3.7 (i.e., moderately unsatisfied to moderately satisfied), 4.1 (i.e., moderately satisfied to satisfied), and 2.5 (i.e., unsatisfied to moderately unsatisfied), respectively. These levels increased to 4.2 (i.e., moderately satisfied to satisfied), 4.8 (i.e., moderately satisfied to satisfied), and 3.1 (i.e., moderately unsatisfied to moderately satisfied), respectively, for the visual-comfort-priority solution. For other solutions, these levels increased to the ranges of 4.1–4.2 (i.e., moderately satisfied to satisfied), 4.7–4.8 (i.e., moderately satisfied to satisfied), and 3.0–3.1 (i.e., moderately unsatisfied to moderately satisfied), respectively.\n\nResults\n4.1.1 Prediction performance Table 2 summarizes the prediction performance results of the cooling and lighting energy consumption prediction models. For both cooling and lighting energy consumption prediction, SVR models (Models #5 and #29) that predict energy consumption using occupant-behavior features and past two-hour outdoor weather condition features achieved the best performance: 0.98 kWh and 0.26 kWh RMSE, respectively. Fig. 2 shows the regression between the actual and predicted energy consumption values, for Model #5 (cooling) and Model #29 (lighting). The predicted energy consumption values show a good agreement with the actual levels. Models #5 and #29 were, therefore, chosen to be used for the optimization.\n\nResults\n4.3.1 Group comfort results The following prediction models were used for the multi-objective occupant-behavior optimization: Model #5 (see Table 2) for cooling energy consumption prediction, Model #29 (see Table 2) for lighting energy consumption prediction, Model #23 (see Table 3) for thermal comfort prediction, and Model #29 (see Table 3) for visual comfort prediction. The optimal occupant-behavior settings were determined, for each hour throughout the three months during which the data were collected. For example, Fig. 5 shows seven optimal solutions at hour 1301, which included energy consumption levels varying from 9.76 kWh to 16.61 kWh, thermal comfort levels varying from very unsatisfied to very satisfied, and visual comfort levels ranging from moderately satisfied to satisfied. The 9.76 kWh solution is the energy-priority-solution, which provides the minimum energy consumption. The 16.61 kWh solution is the balanced solution, which offers the highest weighed sum of the objectives, resulting in satisfied thermal and comfort levels. Fig. 6 shows the cumulative energy consumption of the three extreme and the balanced solutions as well as the actual energy consumption. The energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions consumed 8838 kWh, 10,077 kWh, 9696 kWh, and 9715 kWh, respectively, in comparison to 11,299 kWh actual consumption. Overall, the energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions achieved 21.8%, 10.8%, 14.2%, and 14.0% energy savings, respectively. All solutions consumed less energy relative to the actual energy consumption levels. Fig. 7 shows the thermal and visual comfort distribution of the solutions as well as the actual comfort distributions. Overall, before optimization, 17.7% of the time the actual thermal comfort level was moderately unsatisfied or lower. After the optimization, only 3.4%, 0.0%, 1.1%, and 0.1% of the time the thermal comfort level was moderately unsatisfied or lower for the energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions, respectively. Before optimization, the actual 3-month average thermal comfort level was 3.9 (i.e., moderately unsatisfied to moderately satisfied). After optimization, the average comfort level increased to 5.1 (i.e., satisfied to very satisfied) for the thermal-comfort-priority solution, 4.9 (i.e., moderately satisfied to satisfied) for the visual-comfort-priority and balanced solutions, and 4.4 (i.e., moderately satisfied to satisfied) for the energy-priority solution. For visual comfort, the time when the comfort was moderately unsatisfied or lower was reduced from 60.7% to 17.5%, 18.9%, 11.3%, and 15.3% for the energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions, respectively. The 3-month average visual comfort level was increased from 3.4 (i.e., moderately unsatisfied to moderately satisfied) to 4.4 (i.e., moderately satisfied to satisfied) for the visual-comfort-priority solution, 4.3 (i.e., moderately satisfied to satisfied) for the balanced solution, and 4.2 (i.e., moderately satisfied to satisfied) for the thermal-comfort-priority and energy-priority solutions. The optimal occupant-behavior settings differed for the four optimal solutions. For example, for the balanced solution, the average thermostat setpoint was 69.8F, the portable heaters were on 16.2% of the time, the doors were open 77.3% of the time, the shading devices were open 6.1% of the time, and the lights were on 74.2% of the time. In general, the average thermostat setpoint (70.0F) for the energy-priority solution was higher than the setpoints for other solutions (68.9–69.8F). As expected, higher thermostat setpoints resulted in less cooling energy consumption. Turning on portable heaters was optimal only less than 20% of the time for all solutions. The thermal-comfort-priority solution had the least use of personal heaters due to avoiding over-cooling [46] . Opening doors was optimal 82.4% of the time for the energy-priority solution; while it was only optimal in the range of 70.8–77.3% of the time for other solutions. Rupp and Ghisi [47] showed that less air-conditioning use hours is needed when the internal doors are open. For the visual-comfort-priority solution, the lights were on 77.9% of the time and the shading devices were only open 4.2% of the time. However, for all other solutions, compared to the visual-comfort-priority solution, the lights were on for shorter durations and the shading devices were open for longer durations. For example, for the energy-priority solution, the shading devices were open double the time of that for the thermal-comfort and visual-comfort priority solutions. This shows that opening shading devices can help save energy, although it cannot always fully substitute turning on lights because natural light may not provide sufficient visual comfort. On one hand, opening shading devices lets more natural light in and reduces lighting energy consumption. On the other hand, when there is less artificial lighting, the lighting devices produce less heating and therefore the demand for cooling is also reduced. Lighting is, thus, not only a significant piece of building energy consumption by itself, but it also impacts cooling energy demand. One-third of the cooling energy consumption can be saved if a good balance between natural light and solar heat can be achieved [19,48] .\n\nResults\n4.3.2 Individual comfort results For presenting and discussing the individual comfort results, in this paper, three of the 12 occupants were selected for the sake of conciseness. Table 4 summarizes the actual (reported) comfort levels of these occupants. These occupants reported different thermal and visual comfort levels when they were exposed to similar indoor environmental conditions, which indicates that these three occupants have different thermal and visual preferences. Overall, Occupant #2 was the most comfortable, while Occupant #3 was the least comfortable. For example, for thermal comfort, Occupant #2 was satisfied 60.9% of the time, moderately satisfied 19.6% of the time, and moderately unsatisfied or lower 19.5% of the time. Occupant #1 was satisfied 9.1% of the time, moderately satisfied 64.9% of the time, and moderately unsatisfied or lower 26.4% of the time. And, Occupant #3 was satisfied 14.0% of the time, moderately satisfied 41.3% of the time, and moderately unsatisfied or lower 44.6% of the time. For all optimal solutions, the optimal thermal and visual comfort levels of all 12 occupants were higher than their actual comfort levels. Fig. 8 shows the predicted thermal and visual comfort levels of the three selected occupants for the optimal solutions. For example, before the optimization, the actual 3-month average thermal comfort levels of Occupants #1, #2, and #3 were 3.6 (i.e., moderately unsatisfied to moderately satisfied), 4.2 (i.e., moderately satisfied to satisfied), and 3.5 (i.e., moderately unsatisfied to moderately satisfied), respectively. After the optimization, the average comfort levels of these three occupants increased to 5.0 (i.e., satisfied), 5.3 (i.e., satisfied to very satisfied), and 5.0 (i.e., satisfied), respectively, for the thermal-comfort-priority solution. For the energy-priority, visual-comfort-priority, and balanced solutions, the average comfort levels of the three occupants increased to the ranges of 4.3–4.7 (i.e., moderately satisfied to satisfied), 4.6–5.0 (i.e., moderately satisfied to satisfied), and 4.1–4.6 (i.e., moderately satisfied to satisfied), respectively. Similarly, before optimization, the actual 3-month average visual comfort levels of the three occupants were 3.7 (i.e., moderately unsatisfied to moderately satisfied), 4.1 (i.e., moderately satisfied to satisfied), and 2.5 (i.e., unsatisfied to moderately unsatisfied), respectively. These levels increased to 4.2 (i.e., moderately satisfied to satisfied), 4.8 (i.e., moderately satisfied to satisfied), and 3.1 (i.e., moderately unsatisfied to moderately satisfied), respectively, for the visual-comfort-priority solution. For other solutions, these levels increased to the ranges of 4.1–4.2 (i.e., moderately satisfied to satisfied), 4.7–4.8 (i.e., moderately satisfied to satisfied), and 3.0–3.1 (i.e., moderately unsatisfied to moderately satisfied), respectively.\n\nConclusion\n6 Conclusions, contributions, and future work This paper proposed a real data-driven method to assess the potential of occupant behavior in simultaneously reducing energy consumption and improving comfort. The proposed method consists of two components: a set of machine learning-based occupant-behavior-sensitive models for predicting energy consumption and thermal and visual comfort, and a genetic algorithm-based optimization model for optimizing occupant behavior. To test and evaluate the proposed method, an office building was instrumented and data about energy consumption, outdoor weather conditions, occupant behavior, and occupant comfort were collected for about three months. Using the collected data, a set of machine learning-based occupant-behavior-sensitive prediction models for data-driven prediction of cooling and lighting energy consumption and thermal and visual occupant comfort were developed. Then, using the most accurate prediction models an occupant-behavior optimization for reduced energy consumption and improved comfort was conducted. To verify that the behavior features are discriminating, the performance of the models were compared to others without occupant-behavior features. The results showed that the most accurate cooling and lighting energy consumption prediction models achieved 0.98 and 0.26 RMSE, respectively, and the thermal and visual comfort prediction models achieved 0.20 and 0.40 MAE, respectively. Also, the prediction models with behavior features always outperformed those without behavior features. The experimental results, thus, indicate that data-driven models can accurately predict energy consumption and occupant comfort, taking occupant behavior into account, when such data are available. For optimization, the energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions achieved 21.8%, 10.8%, 14.2%, and 14.0% energy savings, respectively. Also, the thermal discomfort time (i.e., moderately unsatisfied or lower) decreased from 17.7% (actual level reported by occupants) to only 3.4%, 0.0%, 1.1%, and 0.1% of the time for the energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions, respectively. And, the visual discomfort decreased from 60.7% to 17.5%, 18.9%, 11.3%, and 15.3% for the energy-priority, thermal-comfort-priority, visual-comfort-priority, and balanced solutions, respectively. The optimization results, therefore, show that occupant behavior has a great potential for simultaneously reducing energy consumption and improving comfort. This research contributes to the body of knowledge in two primary ways. First, this research offers a real-data-driven approach for occupant-behavior-sensitive hourly energy consumption and comfort prediction. The resulting models learn from real building sensor data and real occupant feedback to help capture the real-life complexity of occupant behavior and their impact on occupant comfort and energy usage. Compared to existing data-driven machine-learning approaches, this method can better capture and model the real-life behavior and comfort of occupants and the real-life energy-consumption patterns of buildings. Second, this research offers a data-driven approach to incorporate occupant behavior into building energy optimization. Combining the prediction models with optimization offers a powerful tool for finding the right energy-use behavioral changes that can achieve, both, energy saving and comfort improvement. In practice, it can empower multiple stakeholders including property owners, facility managers, building occupants, and energy consultants to find the right energy-saving behavioral improvements. The proposed method paves the way for machine-learning-assisted behavioral energy efficiency and occupant engagement approaches that can incentivize occupants to save energy while improving their comfort and quality of life. And, with the growing use of advanced sensing and metering technologies and smart building systems, we foresee such real-data-driven approach becoming increasingly feasible and desirable with time. In their future work, the authors will explore how to further improve, validate, and extend the proposed method. These efforts will go into six main directions. First, exploring the use of advanced sensing technologies and wearable devices to facilitate the collection of additional amounts and types of data – including additional data collection from a larger number of real buildings, as well as collection of additional types of data about the characteristics, behavior, and comfort of the occupants such as clothing, activities, and physiological parameters for improved monitoring, prediction, and understanding of occupant behavior and comfort. Second, identifying additional potential energy-saving behavioral changes, as well as validating the impact of these changes using real-life field studies. Third, identifying the correlations among occupant-behavior features (e.g., identify if opening windows is correlated with switching off lights, and vice versa) and studying the impact of such correlations, if they exist, on the feature analysis and machine-learning models. Fourth, understanding how group comfort can be optimized even in the presence of large individual variations. Fifth, understanding attitudes towards behavioral changes and how to incentivize, sustain, and reward behavior changes related to energy saving and sustainability. Sixth, better understanding how contextual factors – such as work settings and occupant characteristics – influence behavior, comfort expectations, and attitudes towards behavioral changes.\n"
  }
}